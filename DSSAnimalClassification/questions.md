ğŸ¯ 1. Learning Curve Analysis Questions


### Is the model still improving or has it plateaued?

Based on the graph the model has plateaued at 4 epoches.The validation stopped around 87% accuracy.

### Is there a large gap between train and val curves?

After 4 epoches there is a significant gap between train and val accuracy curves and loss. 

Large gap â†’ Overfitting (need regularization: dropout, weight decay, data augmentation)
Small gap â†’ Good generalization (can potentially reduce regularization)

### Does validation loss start increasing while train loss decreases?

The validation loss increases while the training loss continues to drop after 7 epoches

Yes â†’ Classic overfitting, stop training earlier


### Are the curves smooth or erratic?

THe curves are smooothing, showing agood learning rate.

Erratic â†’ Learning rate too high, reduce it
Smooth â†’ Good learning rate

ğŸ” 2. Per-Class Performance Questions

### Which classes have consistently low F1 scores (<0.7)?

The only class which has consistent low f1 scores in blank.

These are your problem classes â†’ Need targeted fixes


### Do certain classes improve slowly or not at all?

Antelope_duker, monkey_prosimian, bird, hog, and rodent improve significantly. Lepord and civet_genet improved a little bit. Blank improved a medium amount.

Overall after 4 epochs the classes didn't improve at all.

Slow improvement â†’ Class needs more/better training data
No improvement â†’ Features don't distinguish this class wel

Classes that improved significantly means model CAN learn them given enough data.


### Are low-performing classes also rare (low support)?


No, the number of blank images are relativly high from the eight choices. Also performed a significant increase in performance when training, with an f1 score of 0.8 to 0.95 in 4 epochs

Yes â†’ Class imbalance problem â†’ Use weighted loss, oversampling, or focal loss
No â†’ Visual similarity problem â†’ Need better features or data augmentation


ğŸ­ 3. Confusion Matrix Questions

### What are the top 3 most confused class pairs?

These pairs are visually similar to your model

â“ Are confusions symmetric (Aâ†’B and Bâ†’A) or one-way (Aâ†’B but not Bâ†’A)?




Symmetric â†’ Classes genuinely look similar (antelope â†” rodent?)
One-way â†’ One class is "default" when model is uncertain
â“ Does the model confuse many classes with "blank"?
Yes â†’ "Blank" is becoming a dumping ground â†’ Need clearer definition or better training
â“ Are related animals confused more (e.g., monkey vs rodent vs antelope)?
Yes â†’ Model needs better fine-grained features (try larger input size 384â†’512, or attention mechanisms)
â“ Did confusions decrease from epoch 0 to epoch 9?
Decreased â†’ Model is learning discriminative features âœ…
Same or increased â†’ Model can't distinguish these classes â†’ Need architectural change
Model Improvement Actions:
Persistent Aâ†”B confusion â†’ Use hard negative mining or siamese network to learn differences
Many classes â†’ blank â†’ Remove blank class or use it only for truly empty images
Systematic confusion pattern â†’ Add attention mechanism to focus on distinguishing features