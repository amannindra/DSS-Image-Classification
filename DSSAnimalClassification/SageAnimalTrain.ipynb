{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4ec31aff",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
            "sagemaker.config INFO - Not applying SDK defaults from location: /Users/amannindra/Library/Application Support/sagemaker/config.yaml\n"
          ]
        }
      ],
      "source": [
        "import boto3\n",
        "import sagemaker\n",
        "\n",
        "from sagemaker.pytorch import PyTorch\n",
        "from sagemaker.pytorch.processing import PyTorchProcessor\n",
        "from sagemaker.processing import ProcessingInput, ProcessingOutput"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4423240b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "REGION = 'us-east-1'\n",
        "ROLE_ARN = \"arn:aws:iam::253490779227:role/service-role/AmazonSageMakerAdminIAMExecutionRole\"\n",
        "BUCKET = 'animal-classification-dss-works'\n",
        "BUCKET_VIRGINIA = 'animal-classification-virgina'\n",
        "S3_INPUT_DATA = f's3://{BUCKET}/data/'\n",
        "S3_PREPROCESSED = f's3://{BUCKET_VIRGINIA}/processed'\n",
        "S3_SHORT_PREPROCESSED = f's3://{BUCKET}/short_processed'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f2986b6d",
      "metadata": {},
      "outputs": [],
      "source": [
        "boto_session = boto3.Session(region_name=REGION)\n",
        "sagemaker_session = sagemaker.Session(boto_session=boto_session)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "581e7c9b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !python manage_sagemaker_jobs.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3598b6ad",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Estimator configured:\n",
            "  Models ‚Üí s3://amazon-sagemaker-253490779227-us-east-1-cnizlxa57lpnon/animal-classification-swinb-test-4\n",
            "  Metrics ‚Üí s3://animal-classification-virgina/swinb-test-4_output\n"
          ]
        }
      ],
      "source": [
        "train_file = \"dss_new_train.py\"\n",
        "\n",
        "# üìÅ Storage Configuration:\n",
        "# - Models (.pth files) ‚Üí output_path (automatically uploaded by SageMaker)\n",
        "# - Metrics (JSON/CSV) ‚Üí output_data_config (training logs and metrics)\n",
        "\n",
        "\n",
        "models = [\"swinb\", \"swinb-test-1\", \"swinb-test-2\", \"swinb-test-3\", \"swinb-test-4\"]\n",
        "\n",
        "model_output_path = f\"s3://amazon-sagemaker-253490779227-us-east-1-cnizlxa57lpnon/animal-classification-{models[-1]}\"\n",
        "metrics_output_path = f\"s3://animal-classification-virgina/{models[-1]}_output\"\n",
        "\n",
        "estimator_3 = PyTorch(\n",
        "    entry_point=train_file,\n",
        "    dependencies=[\"requirements.txt\"],\n",
        "    role=ROLE_ARN,\n",
        "    framework_version='2.1',\n",
        "    py_version='py310',\n",
        "    output_data_config={\n",
        "        'S3OutputPath': metrics_output_path\n",
        "    },\n",
        "    instance_count=1,\n",
        "    instance_type='ml.g4dn.2xlarge',  \n",
        "    # model_data = model_location,    \n",
        "    hyperparameters={\n",
        "        'epochs': 10,                \n",
        "        'batch-size': 32,            \n",
        "        'learning-rate': 1e-4,       \n",
        "        'use-cuda': True,\n",
        "        \"image-size\": 224,            \n",
        "        \"weight-decay\": 1e-8,   \n",
        "        \"stochastic-depth\": 0.1,      \n",
        "        \"num-cpu\": 4,\n",
        "        \"save-file\": f\"{models[-1]}Weights.pth\"\n",
        "    },\n",
        "    sagemaker_session=sagemaker_session,\n",
        "    base_job_name=models[-1],\n",
        ")\n",
        "\n",
        "print(f\"‚úì Estimator configured:\")\n",
        "print(f\"  Models ‚Üí {model_output_path}\")\n",
        "print(f\"  Metrics ‚Üí {metrics_output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a761ca07",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
            "INFO:sagemaker:Creating training-job with name: swinb-test-4-2026-02-01-08-37-16-188\n"
          ]
        }
      ],
      "source": [
        "estimator_3.fit(\n",
        "    {'training': S3_PREPROCESSED},\n",
        "    wait=False,      # ‚úÖ Wait for job to complete\n",
        "    # logs='All'      # ‚úÖ Stream ALL logs to notebook (shows all print statements!)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "964cd10b",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# print(f\"Region: {sagemaker_session.boto_region_name}\")\n",
        "# print(f\"S3 Bucket: {BUCKET}\")\n",
        "# print(f\"Input data: {S3_INPUT_DATA}\")\n",
        "# print(f\"Preprocessed output: {S3_PREPROCESSED}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c98a32a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# processor = PyTorchProcessor(\n",
        "#     framework_version='2.1',\n",
        "#     py_version='py310',\n",
        "#     role=ROLE_ARN,\n",
        "#     instance_type='ml.m5.2xlarge',  # CPU instance: $0.23/hour\n",
        "#     instance_count=1,\n",
        "#     sagemaker_session=sagemaker_session,\n",
        "#     base_job_name='animal-preprocessing'\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "355fc9ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "# processor.latest_job.stop()\n",
        "\n",
        "# ##### RUN THIS CELL ONLY ONCE ######\n",
        "\n",
        "# processor.run(\n",
        "#     code='preprocess.py',\n",
        "#     # inputs=[\n",
        "#     #     ProcessingInput(\n",
        "#     #         source=S3_INPUT_DATA,           # Your S3 data folder\n",
        "#     #         destination='/opt/ml/processing/input'  # Where it appears in container\n",
        "#     #     )\n",
        "#     # ],\n",
        "#     # outputs=[\n",
        "#     #     ProcessingOutput(\n",
        "#     #         source='/opt/ml/processing/output',     # Where script saves results\n",
        "#     #         destination=S3_PREPROCESSED              # Upload results here\n",
        "#     #     )\n",
        "#     # ],\n",
        "#     # arguments=[\n",
        "#     #     '--input-dir', '/opt/ml/processing/input',\n",
        "#     #     '--output-dir', '/opt/ml/processing/output'\n",
        "#     # ]\n",
        "# )\n",
        "# print(f\"Preprocessed data saved to: {S3_PREPROCESSED}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "fc85ee86",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<sagemaker.pytorch.estimator.PyTorch object at 0x11f543550>\n"
          ]
        }
      ],
      "source": [
        "train_file = \"dss_transformer_train.py\"\n",
        "part1_my_output_path = \"s3://sagemaker-us-west-1-253490779227/animal-classification-resnet18\"\n",
        "gpu = \"ml.g4dn.2xlarge\"\n",
        "estimator = PyTorch(\n",
        "    entry_point=train_file,\n",
        "    output_path=part1_my_output_path,\n",
        "    dependencies=[\"requirements.txt\"],\n",
        "    role=ROLE_ARN,\n",
        "    framework_version='2.1',\n",
        "    py_version='py310',\n",
        "    instance_count=1,\n",
        "    instance_type=gpu,  # GPU instance with NVIDIA T4\n",
        "    hyperparameters={\n",
        "        'epochs': 10,\n",
        "        'batch-size': 64,  \n",
        "        'learning-rate': 1e-5, \n",
        "        'use-cuda': True, \n",
        "        \"image-size\": 224,\n",
        "        \"weight-decay\": 1e-8,\n",
        "        \"stochastic-depth\": 0.2,\n",
        "        \"num-cpu\": 4,\n",
        "        \"save-file\": \"resnet18_model.pth\"\n",
        "    },\n",
        "    sagemaker_session=sagemaker_session,\n",
        "    base_job_name='resnet18',    \n",
        "    # max_run=3600,   \n",
        ")\n",
        "# estimator.latest_training_job.stop()\n",
        "print(estimator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae786a91",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<sagemaker.pytorch.estimator.PyTorch object at 0x128411010>\n"
          ]
        }
      ],
      "source": [
        "train_file = \"dss_transformer_train.py\"\n",
        "part1_my_output_path = \"s3://sagemaker-us-west-1-253490779227/animal-classification-models_part1\"\n",
        "\n",
        "estimator = PyTorch(\n",
        "    entry_point=train_file,\n",
        "    output_path=part1_my_output_path,\n",
        "    dependencies=[\"requirements.txt\"],\n",
        "    role=ROLE_ARN,\n",
        "    framework_version='2.1',\n",
        "    py_version='py310',\n",
        "    instance_count=1,\n",
        "    instance_type='ml.g4dn.xlarge',  # GPU instance with NVIDIA T4\n",
        "    hyperparameters={\n",
        "        'epochs': 10,\n",
        "        'batch-size': 64,  \n",
        "        'learning-rate': 1e-5, \n",
        "        'use-cuda': True, \n",
        "        \"image-size\": 224,\n",
        "        \"weight-decay\": 1e-8,\n",
        "        \"stochastic-depth\": 0.2,\n",
        "        \"num-cpu\": 4,\n",
        "        \"save-file\": \"final_swin_t_model_part1.pth\"\n",
        "    },\n",
        "    sagemaker_session=sagemaker_session,\n",
        "    base_job_name='swin-stage1',    \n",
        "    # max_run=3600,   \n",
        ")\n",
        "# estimator.latest_training_job.stop()\n",
        "print(estimator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b5b92d6c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We are training using this file:  dss_transformer_train.py  with this data:  s3://animal-classification-dss-works/processed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
            "INFO:sagemaker:Creating training-job with name: swin-stage1-2026-01-06-11-36-42-433\n"
          ]
        }
      ],
      "source": [
        "print(\"We are training using this file: \", train_file, \" with this data: \", S3_PREPROCESSED)\n",
        "\n",
        "estimator.fit(\n",
        "    {'training': S3_PREPROCESSED},\n",
        "    wait=True,      # ‚úÖ Wait for job to complete\n",
        "    logs='All'      # ‚úÖ Stream ALL logs to notebook (shows all print statements!)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63a55d5b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Traceback </span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>1 <span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"font-weight: bold; text-decoration: underline\">estimator.model_data</span>)                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/sagemaker</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">estimator.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1938</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">model_data</span>                                                                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1935 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>job_details = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sagemaker_session.sagemaker_client.describe_training_job(  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1936 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>TrainingJobName=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.latest_training_job.name                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1937 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>)                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>1938 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>model_uri = <span style=\"font-weight: bold; text-decoration: underline\">job_details[</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">\"ModelArtifacts\"</span><span style=\"font-weight: bold; text-decoration: underline\">]</span>[<span style=\"color: #808000; text-decoration-color: #808000\">\"S3ModelArtifacts\"</span>]                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1939 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>compression_type = job_details.get(<span style=\"color: #808000; text-decoration-color: #808000\">\"OutputDataConfig\"</span>, {}).get(               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1940 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"CompressionType\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"GZIP\"</span>                                                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1941 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>)                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyError: </span><span style=\"color: #008700; text-decoration-color: #008700\">'ModelArtifacts'</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[38;2;255;0;0m‚ï≠‚îÄ\u001b[0m\u001b[38;2;255;0;0m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[1;38;2;255;0;0mTraceback \u001b[0m\u001b[1;2;38;2;255;0;0m(most recent call last)\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[38;2;255;0;0m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[38;2;255;0;0m‚îÄ‚ïÆ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m1 \u001b[96mprint\u001b[0m(\u001b[1;4mestimator.model_data\u001b[0m)                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2;33m/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/sagemaker\u001b[0m \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2;33m/\u001b[0m\u001b[1;33mestimator.py\u001b[0m:\u001b[94m1938\u001b[0m in \u001b[92mmodel_data\u001b[0m                                                                 \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1935 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mjob_details = \u001b[96mself\u001b[0m.sagemaker_session.sagemaker_client.describe_training_job(  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1936 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mTrainingJobName=\u001b[96mself\u001b[0m.latest_training_job.name                             \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1937 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m)                                                                             \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m1938 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mmodel_uri = \u001b[1;4mjob_details[\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33mModelArtifacts\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4m]\u001b[0m[\u001b[33m\"\u001b[0m\u001b[33mS3ModelArtifacts\u001b[0m\u001b[33m\"\u001b[0m]                 \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1939 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mcompression_type = job_details.get(\u001b[33m\"\u001b[0m\u001b[33mOutputDataConfig\u001b[0m\u001b[33m\"\u001b[0m, {}).get(               \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1940 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mCompressionType\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mGZIP\u001b[0m\u001b[33m\"\u001b[0m                                                 \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1941 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m)                                                                             \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n",
              "\u001b[1;91mKeyError: \u001b[0m\u001b[38;2;0;135;0m'ModelArtifacts'\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(estimator.model_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d52f0e8b",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_location = \"s3://sagemaker-us-west-1-253490779227/animal-classification-training-2026-01-01-08-24-58-245/output/model.tar.gz\"\n",
        "\n",
        "part2_my_output_path = \"s3://sagemaker-us-west-1-253490779227/animal-classification-models_part2\"\n",
        "\n",
        "estimator_2 = PyTorch(\n",
        "    entry_point=train_file,\n",
        "    source_dir='.',\n",
        "    role=ROLE_ARN,\n",
        "    framework_version='2.1',\n",
        "    py_version='py310',\n",
        "    output_path=part2_my_output_path,\n",
        "    instance_count=1,\n",
        "    instance_type='ml.g4dn.2xlarge',  \n",
        "    model_data = model_location,    \n",
        "    hyperparameters={\n",
        "        'epochs': 10,                \n",
        "        'batch-size': 16,            \n",
        "        'learning-rate': 1e-5,       \n",
        "        'use-cuda': True, \n",
        "        \"image-size\": 384,            \n",
        "        \"weight-decay\": 1e-8,   \n",
        "        \"stochastic-depth\": 0.1,      \n",
        "        \"num-cpu\": 4,\n",
        "        \"save-file\": \"final_swin_t_model_384.pth\"\n",
        "    },\n",
        "    sagemaker_session=sagemaker_session,\n",
        "    base_job_name='swin-stage2-again',    \n",
        "# Use Spot instances to save 70% (optional)\n",
        "    # use_spot_instances=True,\n",
        "    # max_wait=7200,  # 2 hours\n",
        "    max_run=3600,   # 1 hour\n",
        "    \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "33aad295",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
            "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n"
          ]
        }
      ],
      "source": [
        "estimator_2.fit(\n",
        "    {'training': S3_PREPROCESSED,\n",
        "     'model': model_location},\n",
        "    wait=False,      # ‚úÖ Wait for job to complete\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24e4d1db",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66cd9413",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'PyTorch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m model_output_path = \u001b[33m\"\u001b[39m\u001b[33ms3://amazon-sagemaker-253490779227-us-east-1-cnizlxa57lpnon/animal-classification-swinb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m metrics_output_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33ms3://animal-classification-virgina/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodels[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_output\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m estimator_3 = \u001b[43mPyTorch\u001b[49m(\n\u001b[32m     14\u001b[39m     entry_point=train_file,\n\u001b[32m     15\u001b[39m     dependencies=[\u001b[33m\"\u001b[39m\u001b[33mrequirements.txt\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     16\u001b[39m     role=ROLE_ARN,\n\u001b[32m     17\u001b[39m     framework_version=\u001b[33m'\u001b[39m\u001b[33m2.1\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     18\u001b[39m     py_version=\u001b[33m'\u001b[39m\u001b[33mpy310\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     19\u001b[39m     output_data_config={\n\u001b[32m     20\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mS3OutputPath\u001b[39m\u001b[33m'\u001b[39m: metrics_output_path\n\u001b[32m     21\u001b[39m     },\n\u001b[32m     22\u001b[39m \n\u001b[32m     23\u001b[39m     instance_count=\u001b[32m1\u001b[39m,\n\u001b[32m     24\u001b[39m     instance_type=\u001b[33m'\u001b[39m\u001b[33mml.g4dn.2xlarge\u001b[39m\u001b[33m'\u001b[39m,  \n\u001b[32m     25\u001b[39m     \u001b[38;5;66;03m# model_data = model_location,    \u001b[39;00m\n\u001b[32m     26\u001b[39m     hyperparameters={\n\u001b[32m     27\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mepochs\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m10\u001b[39m,                \n\u001b[32m     28\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mbatch-size\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m32\u001b[39m,            \n\u001b[32m     29\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mlearning-rate\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1e-4\u001b[39m,       \n\u001b[32m     30\u001b[39m         \u001b[33m'\u001b[39m\u001b[33muse-cuda\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[32m     31\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mimage-size\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m224\u001b[39m,            \n\u001b[32m     32\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mweight-decay\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1e-8\u001b[39m,   \n\u001b[32m     33\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstochastic-depth\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0.1\u001b[39m,      \n\u001b[32m     34\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mnum-cpu\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m4\u001b[39m,\n\u001b[32m     35\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msave-file\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodels[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mWeights.pth\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     36\u001b[39m     },\n\u001b[32m     37\u001b[39m     sagemaker_session=sagemaker_session,\n\u001b[32m     38\u001b[39m     base_job_name=models[\u001b[32m0\u001b[39m],\n\u001b[32m     39\u001b[39m \n\u001b[32m     40\u001b[39m )\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úì Estimator configured:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     43\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Models ‚Üí \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_output_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'PyTorch' is not defined"
          ]
        }
      ],
      "source": [
        "train_file = \"dss_new_train.py\"\n",
        "\n",
        "# üìÅ Storage Configuration:\n",
        "# - Models (.pth files) ‚Üí output_path (automatically uploaded by SageMaker)\n",
        "# - Metrics (JSON/CSV) ‚Üí output_data_config (training logs and metrics)\n",
        "\n",
        "\n",
        "models = [\"swinb\"]\n",
        "\n",
        "model_output_path = \"s3://amazon-sagemaker-253490779227-us-east-1-cnizlxa57lpnon/animal-classification-swinb\"\n",
        "metrics_output_path = f\"s3://animal-classification-virgina/{models[0]}_output\"\n",
        "\n",
        "estimator_3 = PyTorch(\n",
        "    entry_point=train_file,\n",
        "    dependencies=[\"requirements.txt\"],\n",
        "    role=ROLE_ARN,\n",
        "    framework_version='2.1',\n",
        "    py_version='py310',\n",
        "    output_data_config={\n",
        "        'S3OutputPath': metrics_output_path\n",
        "    },\n",
        "    \n",
        "    instance_count=1,\n",
        "    instance_type='ml.g4dn.2xlarge',  \n",
        "    # model_data = model_location,    \n",
        "    hyperparameters={\n",
        "        'epochs': 10,                \n",
        "        'batch-size': 32,            \n",
        "        'learning-rate': 1e-4,       \n",
        "        'use-cuda': True, \n",
        "        \"image-size\": 224,            \n",
        "        \"weight-decay\": 1e-8,   \n",
        "        \"stochastic-depth\": 0.1,      \n",
        "        \"num-cpu\": 4,\n",
        "        \"save-file\": f\"{models[0]}Weights.pth\"\n",
        "    },\n",
        "    sagemaker_session=sagemaker_session,\n",
        "    base_job_name=models[0],\n",
        "\n",
        ")\n",
        "\n",
        "print(f\"‚úì Estimator configured:\")\n",
        "print(f\"  Models ‚Üí {model_output_path}\")\n",
        "print(f\"  Metrics ‚Üí {metrics_output_path}\")\n",
        "estimator_3.fit(\n",
        "    {'training': S3_PREPROCESSED},\n",
        "    wait=True,      # ‚úÖ Wait for job to complete\n",
        "    logs='All'      # ‚úÖ Stream ALL logs to notebook (shows all print statements!)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce9ba14a",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "152da467",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1a883bd0",
      "metadata": {},
      "source": [
        "# üìã View Training Logs Anytime\n",
        "\n",
        "**Use the cells below to view logs after closing/reopening your computer**\n",
        "\n",
        "- **Cell below**: List all recent training jobs\n",
        "- **Next cell**: View complete logs from any job\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6e6b9532",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "RECENT TRAINING JOBS\n",
            "================================================================================\n",
            "\n",
            "#    Job Name                                           Status         \n",
            "--------------------------------------------------------------------------------\n",
            "0    resnet18-2026-01-28-21-16-25-472                   ‚ùå Failed\n",
            "1    resnet18-2026-01-28-20-57-35-354                   ‚ùå Failed\n",
            "2    resnet18-2026-01-26-02-48-02-281                   ‚úÖ Completed\n",
            "3    resnet18-2026-01-26-02-06-38-221                   ‚ùå Failed\n",
            "\n",
            "================================================================================\n",
            "üí° Copy a job name above and paste it in the next cell to view its logs\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# RUN THIS CELL TO LIST ALL RECENT JOBS\n",
        "# ========================================\n",
        "\n",
        "import boto3\n",
        "from datetime import datetime\n",
        "\n",
        "sagemaker_client = boto3.client('sagemaker', region_name=REGION)\n",
        "\n",
        "# Get recent training jobs\n",
        "jobs = sagemaker_client.list_training_jobs(\n",
        "    MaxResults=10, \n",
        "    SortBy='CreationTime', \n",
        "    SortOrder='Descending'\n",
        ")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"RECENT TRAINING JOBS\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\n{'#':<4} {'Job Name':<50} {'Status':<15}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for i, job in enumerate(jobs['TrainingJobSummaries']):\n",
        "    job_name = job['TrainingJobName']\n",
        "    status = job['TrainingJobStatus']\n",
        "    created = job['CreationTime'].strftime('%Y-%m-%d %H:%M')\n",
        "    \n",
        "    # Color code status\n",
        "    status_symbol = {\n",
        "        'InProgress': 'üîÑ',\n",
        "        'Completed': '‚úÖ',\n",
        "        'Failed': '‚ùå',\n",
        "        'Stopped': '‚è∏Ô∏è'\n",
        "    }.get(status, '‚ùì')\n",
        "    \n",
        "    print(f\"{i:<4} {job_name:<50} {status_symbol} {status}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üí° Copy a job name above and paste it in the next cell to view its logs\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "85c6869b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ÑπÔ∏è  No job name specified, using most recent: animal-classification-training-2025-12-28-01-43-07-396\n",
            "\n",
            "================================================================================\n",
            "üìã TRAINING LOGS: animal-classification-training-2025-12-28-01-43-07-396\n",
            "================================================================================\n",
            "Total log lines: 2583\n",
            "Showing first 500 lines (set max_lines=None for all)\n",
            "================================================================================\n",
            "\n",
            "bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
            "bash: no job control in this shell\n",
            "/opt/conda/lib/python3.10/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
            "  \"cipher\": algorithms.TripleDES,\n",
            "/opt/conda/lib/python3.10/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
            "  \"class\": algorithms.TripleDES,\n",
            "2025-12-28 01:48:40,138 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
            "2025-12-28 01:48:40,157 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
            "2025-12-28 01:48:40,168 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
            "2025-12-28 01:48:40,174 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
            "2025-12-28 01:48:42,199 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
            "2025-12-28 01:48:42,230 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
            "2025-12-28 01:48:42,260 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
            "2025-12-28 01:48:42,271 sagemaker-training-toolkit INFO     Invoking user script\n",
            "Training Env:\n",
            "{\n",
            "    \"additional_framework_parameters\": {},\n",
            "    \"channel_input_dirs\": {\n",
            "        \"training\": \"/opt/ml/input/data/training\"\n",
            "    },\n",
            "    \"current_host\": \"algo-1\",\n",
            "    \"current_instance_group\": \"homogeneousCluster\",\n",
            "    \"current_instance_group_hosts\": [\n",
            "        \"algo-1\"\n",
            "    ],\n",
            "    \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
            "    \"distribution_hosts\": [],\n",
            "    \"distribution_instance_groups\": [],\n",
            "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
            "    \"hosts\": [\n",
            "        \"algo-1\"\n",
            "    ],\n",
            "    \"hyperparameters\": {\n",
            "        \"batch-size\": 64,\n",
            "        \"epochs\": 5,\n",
            "        \"learning-rate\": 0.001,\n",
            "        \"use-cuda\": true\n",
            "    },\n",
            "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
            "    \"input_data_config\": {\n",
            "        \"training\": {\n",
            "            \"TrainingInputMode\": \"File\",\n",
            "            \"S3DistributionType\": \"FullyReplicated\",\n",
            "            \"RecordWrapperType\": \"None\"\n",
            "        }\n",
            "    },\n",
            "    \"input_dir\": \"/opt/ml/input\",\n",
            "    \"instance_groups\": [\n",
            "        \"homogeneousCluster\"\n",
            "    ],\n",
            "    \"instance_groups_dict\": {\n",
            "        \"homogeneousCluster\": {\n",
            "            \"instance_group_name\": \"homogeneousCluster\",\n",
            "            \"instance_type\": \"ml.g4dn.xlarge\",\n",
            "            \"hosts\": [\n",
            "                \"algo-1\"\n",
            "            ]\n",
            "        }\n",
            "    },\n",
            "    \"is_hetero\": false,\n",
            "    \"is_master\": true,\n",
            "    \"is_modelparallel_enabled\": null,\n",
            "    \"is_smddpmprun_installed\": false,\n",
            "    \"is_smddprun_installed\": true,\n",
            "    \"job_name\": \"animal-classification-training-2025-12-28-01-43-07-396\",\n",
            "    \"log_level\": 20,\n",
            "    \"master_hostname\": \"algo-1\",\n",
            "    \"model_dir\": \"/opt/ml/model\",\n",
            "    \"module_dir\": \"s3://sagemaker-us-west-1-253490779227/animal-classification-training-2025-12-28-01-43-07-396/source/sourcedir.tar.gz\",\n",
            "    \"module_name\": \"dss_train\",\n",
            "    \"network_interface_name\": \"eth0\",\n",
            "    \"num_cpus\": 4,\n",
            "    \"num_gpus\": 1,\n",
            "    \"num_neurons\": 0,\n",
            "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
            "    \"output_dir\": \"/opt/ml/output\",\n",
            "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
            "    \"resource_config\": {\n",
            "        \"current_host\": \"algo-1\",\n",
            "        \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
            "        \"current_group_name\": \"homogeneousCluster\",\n",
            "        \"hosts\": [\n",
            "            \"algo-1\"\n",
            "        ],\n",
            "        \"instance_groups\": [\n",
            "            {\n",
            "                \"instance_group_name\": \"homogeneousCluster\",\n",
            "                \"instance_type\": \"ml.g4dn.xlarge\",\n",
            "                \"hosts\": [\n",
            "                    \"algo-1\"\n",
            "                ]\n",
            "            }\n",
            "        ],\n",
            "        \"network_interface_name\": \"eth0\",\n",
            "        \"topology\": null\n",
            "    },\n",
            "    \"user_entry_point\": \"dss_train.py\"\n",
            "}\n",
            "Environment variables:\n",
            "SM_HOSTS=[\"algo-1\"]\n",
            "SM_NETWORK_INTERFACE_NAME=eth0\n",
            "SM_HPS={\"batch-size\":64,\"epochs\":5,\"learning-rate\":0.001,\"use-cuda\":true}\n",
            "SM_USER_ENTRY_POINT=dss_train.py\n",
            "SM_FRAMEWORK_PARAMS={}\n",
            "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\n",
            "SM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
            "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
            "SM_CHANNELS=[\"training\"]\n",
            "SM_CURRENT_HOST=algo-1\n",
            "SM_CURRENT_INSTANCE_TYPE=ml.g4dn.xlarge\n",
            "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
            "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\n",
            "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
            "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}}\n",
            "SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
            "SM_IS_HETERO=false\n",
            "SM_MODULE_NAME=dss_train\n",
            "SM_LOG_LEVEL=20\n",
            "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
            "SM_INPUT_DIR=/opt/ml/input\n",
            "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
            "SM_OUTPUT_DIR=/opt/ml/output\n",
            "SM_NUM_CPUS=4\n",
            "SM_NUM_GPUS=1\n",
            "SM_NUM_NEURONS=0\n",
            "SM_MODEL_DIR=/opt/ml/model\n",
            "SM_MODULE_DIR=s3://sagemaker-us-west-1-253490779227/animal-classification-training-2025-12-28-01-43-07-396/source/sourcedir.tar.gz\n",
            "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g4dn.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":64,\"epochs\":5,\"learning-rate\":0.001,\"use-cuda\":true},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":true,\"job_name\":\"animal-classification-training-2025-12-28-01-43-07-396\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-1-253490779227/animal-classification-training-2025-12-28-01-43-07-396/source/sourcedir.tar.gz\",\"module_name\":\"dss_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"user_entry_point\":\"dss_train.py\"}\n",
            "SM_USER_ARGS=[\"--batch-size\",\"64\",\"--epochs\",\"5\",\"--learning-rate\",\"0.001\",\"--use-cuda\",\"True\"]\n",
            "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
            "SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
            "SM_HP_BATCH-SIZE=64\n",
            "SM_HP_EPOCHS=5\n",
            "SM_HP_LEARNING-RATE=0.001\n",
            "SM_HP_USE-CUDA=true\n",
            "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\n",
            "Invoking script with the following command:\n",
            "/opt/conda/bin/python3.10 dss_train.py --batch-size 64 --epochs 5 --learning-rate 0.001 --use-cuda True\n",
            "2025-12-28 01:48:42,272 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\n",
            "2025-12-28 01:48:42,272 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\n",
            "Starting training...\n",
            "Arguments: Namespace(epochs=5, batch_size=64, learning_rate=0.001, use_cuda=True, model_dir='/opt/ml/model', data_dir='/opt/ml/input/data/training')\n",
            "Initial RAM usage: 527.82 MB\n",
            "Using device: cuda\n",
            "Base path: /opt/ml/input/data/training\n",
            "After loading data RAM usage: 536.33 MB\n",
            "DataframeLoaded 16488 training samples\n",
            "Dataframe Columns: ['id', 'antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent']\n",
            "Dataframe sample:\n",
            "         id  antelope_duiker  bird  ...  leopard  monkey_prosimian  rodent\n",
            "0  ZJ000000              0.0   1.0  ...      0.0               0.0     0.0\n",
            "1  ZJ000001              0.0   0.0  ...      0.0               1.0     0.0\n",
            "2  ZJ000002              0.0   1.0  ...      0.0               0.0     0.0\n",
            "3  ZJ000003              0.0   0.0  ...      0.0               1.0     0.0\n",
            "4  ZJ000004              0.0   0.0  ...      1.0               0.0     0.0\n",
            "[5 rows x 9 columns]\n",
            "Dataframe shape: (16488, 9)\n",
            "Train DataFrame sample:\n",
            "             id  antelope_duiker  bird  ...  leopard  monkey_prosimian  rodent\n",
            "16129  ZJ016129              0.0   0.0  ...      1.0               0.0     0.0\n",
            "12284  ZJ012284              0.0   0.0  ...      0.0               0.0     1.0\n",
            "16416  ZJ016416              0.0   0.0  ...      0.0               0.0     1.0\n",
            "7487   ZJ007487              0.0   0.0  ...      0.0               0.0     0.0\n",
            "13491  ZJ013491              0.0   0.0  ...      0.0               0.0     0.0\n",
            "[5 rows x 9 columns]\n",
            "Train DataFrame shape: (12366, 9)\n",
            "Validation DataFrame sample:\n",
            "             id  antelope_duiker  bird  ...  leopard  monkey_prosimian  rodent\n",
            "2537   ZJ002537              0.0   0.0  ...      0.0               0.0     0.0\n",
            "284    ZJ000284              0.0   1.0  ...      0.0               0.0     0.0\n",
            "14561  ZJ014561              0.0   0.0  ...      0.0               0.0     0.0\n",
            "14723  ZJ014723              0.0   0.0  ...      0.0               0.0     0.0\n",
            "2950   ZJ002950              0.0   0.0  ...      0.0               1.0     0.0\n",
            "[5 rows x 9 columns]\n",
            "Validation DataFrame shape: (4122, 9)\n",
            "Training samples: 12366\n",
            "Validation samples: 4122\n",
            "Batch size: 64\n",
            "Train batches: 194\n",
            "Val batches: 65\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "0%|          | 0.00/44.7M [00:00<?, ?B/s]\n",
            "48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 21.2M/44.7M [00:00<00:00, 223MB/s]\n",
            "97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 43.2M/44.7M [00:00<00:00, 227MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44.7M/44.7M [00:00<00:00, 226MB/s]\n",
            "Model: ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=8, bias=True)\n",
            ")\n",
            "Epoch 1/5\n",
            "Training:   0%|          | 0/194 [00:00<?, ?it/s]\n",
            "Training:   0%|          | 0/194 [00:01<?, ?it/s, acc=0.0625, loss=2.2790]\n",
            "Training:   1%|          | 1/194 [00:01<03:56,  1.23s/it, acc=0.0625, loss=2.2790]\n",
            "Training:   1%|          | 1/194 [00:01<03:56,  1.23s/it, acc=0.2188, loss=1.8882]\n",
            "Training:   1%|          | 2/194 [00:01<01:56,  1.65it/s, acc=0.2188, loss=1.8882]\n",
            "Training:   1%|          | 2/194 [00:01<01:56,  1.65it/s, acc=0.2448, loss=2.0964]\n",
            "Training:   2%|‚ñè         | 3/194 [00:01<01:18,  2.42it/s, acc=0.2448, loss=2.0964]\n",
            "Training:   2%|‚ñè         | 3/194 [00:01<01:18,  2.42it/s, acc=0.2539, loss=2.0979]\n",
            "Training:   2%|‚ñè         | 4/194 [00:01<01:00,  3.12it/s, acc=0.2539, loss=2.0979]\n",
            "Training:   2%|‚ñè         | 4/194 [00:01<01:00,  3.12it/s, acc=0.2687, loss=1.8275]\n",
            "Training:   3%|‚ñé         | 5/194 [00:01<00:51,  3.70it/s, acc=0.2687, loss=1.8275]\n",
            "Training:   3%|‚ñé         | 5/194 [00:02<00:51,  3.70it/s, acc=0.2708, loss=2.0057]\n",
            "Training:   3%|‚ñé         | 6/194 [00:02<00:44,  4.18it/s, acc=0.2708, loss=2.0057]\n",
            "Training:   3%|‚ñé         | 6/194 [00:02<00:44,  4.18it/s, acc=0.2857, loss=1.6518]\n",
            "Training:   4%|‚ñé         | 7/194 [00:02<00:55,  3.39it/s, acc=0.2857, loss=1.6518]\n",
            "Training:   4%|‚ñé         | 7/194 [00:02<00:55,  3.39it/s, acc=0.3027, loss=1.6673]\n",
            "Training:   4%|‚ñç         | 8/194 [00:02<00:47,  3.88it/s, acc=0.3027, loss=1.6673]\n",
            "Training:   4%|‚ñç         | 8/194 [00:03<00:47,  3.88it/s, acc=0.3073, loss=1.7010]\n",
            "Training:   5%|‚ñç         | 9/194 [00:03<00:50,  3.64it/s, acc=0.3073, loss=1.7010]\n",
            "Training:   5%|‚ñç         | 9/194 [00:03<00:50,  3.64it/s, acc=0.3109, loss=2.0589]\n",
            "Training:   5%|‚ñå         | 10/194 [00:03<00:45,  4.07it/s, acc=0.3109, loss=2.0589]\n",
            "Training:   5%|‚ñå         | 10/194 [00:03<00:45,  4.07it/s, acc=0.3026, loss=1.7232]\n",
            "Training:   6%|‚ñå         | 11/194 [00:03<00:48,  3.75it/s, acc=0.3026, loss=1.7232]\n",
            "Training:   6%|‚ñå         | 11/194 [00:03<00:48,  3.75it/s, acc=0.2995, loss=1.9317]\n",
            "Training:   6%|‚ñå         | 12/194 [00:03<00:47,  3.84it/s, acc=0.2995, loss=1.9317]\n",
            "Training:   6%|‚ñå         | 12/194 [00:04<00:47,  3.84it/s, acc=0.2993, loss=1.8916]\n",
            "Training:   7%|‚ñã         | 13/194 [00:04<00:46,  3.90it/s, acc=0.2993, loss=1.8916]\n",
            "Training:   7%|‚ñã         | 13/194 [00:04<00:46,  3.90it/s, acc=0.3069, loss=1.5777]\n",
            "Training:   7%|‚ñã         | 14/194 [00:04<00:49,  3.66it/s, acc=0.3069, loss=1.5777]\n",
            "Training:   7%|‚ñã         | 14/194 [00:04<00:49,  3.66it/s, acc=0.3083, loss=1.6522]\n",
            "Training:   8%|‚ñä         | 15/194 [00:04<00:50,  3.56it/s, acc=0.3083, loss=1.6522]\n",
            "Training:   8%|‚ñä         | 15/194 [00:04<00:50,  3.56it/s, acc=0.3037, loss=1.7447]\n",
            "Training:   8%|‚ñä         | 16/194 [00:04<00:48,  3.64it/s, acc=0.3037, loss=1.7447]\n",
            "Training:   8%|‚ñä         | 16/194 [00:05<00:48,  3.64it/s, acc=0.3079, loss=1.6370]\n",
            "Training:   9%|‚ñâ         | 17/194 [00:05<00:46,  3.81it/s, acc=0.3079, loss=1.6370]\n",
            "Training:   9%|‚ñâ         | 17/194 [00:05<00:46,  3.81it/s, acc=0.3160, loss=1.6171]\n",
            "Training:   9%|‚ñâ         | 18/194 [00:05<00:49,  3.57it/s, acc=0.3160, loss=1.6171]\n",
            "Training:   9%|‚ñâ         | 18/194 [00:05<00:49,  3.57it/s, acc=0.3183, loss=1.7535]\n",
            "Training:  10%|‚ñâ         | 19/194 [00:05<00:45,  3.81it/s, acc=0.3183, loss=1.7535]\n",
            "Training:  10%|‚ñâ         | 19/194 [00:06<00:45,  3.81it/s, acc=0.3187, loss=1.7791]\n",
            "Training:  10%|‚ñà         | 20/194 [00:06<00:50,  3.42it/s, acc=0.3187, loss=1.7791]\n",
            "Training:  10%|‚ñà         | 20/194 [00:06<00:50,  3.42it/s, acc=0.3229, loss=1.7792]\n",
            "Training:  11%|‚ñà         | 21/194 [00:06<00:49,  3.53it/s, acc=0.3229, loss=1.7792]\n",
            "Training:  11%|‚ñà         | 21/194 [00:06<00:49,  3.53it/s, acc=0.3246, loss=1.6728]\n",
            "Training:  11%|‚ñà‚ñè        | 22/194 [00:06<00:47,  3.66it/s, acc=0.3246, loss=1.6728]\n",
            "Training:  11%|‚ñà‚ñè        | 22/194 [00:06<00:47,  3.66it/s, acc=0.3179, loss=1.8376]\n",
            "Training:  12%|‚ñà‚ñè        | 23/194 [00:06<00:48,  3.55it/s, acc=0.3179, loss=1.8376]\n",
            "Training:  12%|‚ñà‚ñè        | 23/194 [00:07<00:48,  3.55it/s, acc=0.3190, loss=1.6313]\n",
            "Training:  12%|‚ñà‚ñè        | 24/194 [00:07<00:45,  3.74it/s, acc=0.3190, loss=1.6313]\n",
            "Training:  12%|‚ñà‚ñè        | 24/194 [00:07<00:45,  3.74it/s, acc=0.3250, loss=1.4881]\n",
            "Training:  13%|‚ñà‚ñé        | 25/194 [00:07<00:50,  3.36it/s, acc=0.3250, loss=1.4881]\n",
            "Training:  13%|‚ñà‚ñé        | 25/194 [00:07<00:50,  3.36it/s, acc=0.3263, loss=1.6169]\n",
            "Training:  13%|‚ñà‚ñé        | 26/194 [00:07<00:44,  3.81it/s, acc=0.3263, loss=1.6169]\n",
            "Training:  13%|‚ñà‚ñé        | 26/194 [00:08<00:44,  3.81it/s, acc=0.3310, loss=1.5193]\n",
            "Training:  14%|‚ñà‚ñç        | 27/194 [00:08<00:51,  3.23it/s, acc=0.3310, loss=1.5193]\n",
            "Training:  14%|‚ñà‚ñç        | 27/194 [00:08<00:51,  3.23it/s, acc=0.3315, loss=1.7164]\n",
            "Training:  14%|‚ñà‚ñç        | 28/194 [00:08<00:44,  3.69it/s, acc=0.3315, loss=1.7164]\n",
            "Training:  14%|‚ñà‚ñç        | 28/194 [00:08<00:44,  3.69it/s, acc=0.3314, loss=1.5855]\n",
            "Training:  15%|‚ñà‚ñç        | 29/194 [00:08<00:51,  3.18it/s, acc=0.3314, loss=1.5855]\n",
            "Training:  15%|‚ñà‚ñç        | 29/194 [00:08<00:51,  3.18it/s, acc=0.3276, loss=1.7397]#015Training:  15%|‚ñà‚ñå        | 30/194 [00:08<00:44,  3.67it/s, acc=0.3276, loss=1.7397]\n",
            "Training:  15%|‚ñà‚ñå        | 30/194 [00:09<00:44,  3.67it/s, acc=0.3296, loss=1.5832]\n",
            "Training:  16%|‚ñà‚ñå        | 31/194 [00:09<00:53,  3.03it/s, acc=0.3296, loss=1.5832]\n",
            "Training:  16%|‚ñà‚ñå        | 31/194 [00:09<00:53,  3.03it/s, acc=0.3320, loss=1.4210]\n",
            "Training:  16%|‚ñà‚ñã        | 32/194 [00:09<00:45,  3.53it/s, acc=0.3320, loss=1.4210]\n",
            "Training:  16%|‚ñà‚ñã        | 32/194 [00:09<00:45,  3.53it/s, acc=0.3314, loss=1.4979]\n",
            "Training:  17%|‚ñà‚ñã        | 33/194 [00:09<00:54,  2.96it/s, acc=0.3314, loss=1.4979]\n",
            "Training:  17%|‚ñà‚ñã        | 33/194 [00:10<00:54,  2.96it/s, acc=0.3323, loss=1.4249]\n",
            "Training:  18%|‚ñà‚ñä        | 34/194 [00:10<00:46,  3.45it/s, acc=0.3323, loss=1.4249]\n",
            "Training:  18%|‚ñà‚ñä        | 34/194 [00:10<00:46,  3.45it/s, acc=0.3362, loss=1.4199]\n",
            "Training:  18%|‚ñà‚ñä        | 35/194 [00:10<00:52,  3.04it/s, acc=0.3362, loss=1.4199]\n",
            "Training:  18%|‚ñà‚ñä        | 35/194 [00:10<00:52,  3.04it/s, acc=0.3372, loss=1.4591]\n",
            "Training:  19%|‚ñà‚ñä        | 36/194 [00:10<00:44,  3.55it/s, acc=0.3372, loss=1.4591]\n",
            "Training:  19%|‚ñà‚ñä        | 36/194 [00:11<00:44,  3.55it/s, acc=0.3366, loss=1.6521]\n",
            "Training:  19%|‚ñà‚ñâ        | 37/194 [00:11<00:52,  3.01it/s, acc=0.3366, loss=1.6521]\n",
            "Training:  19%|‚ñà‚ñâ        | 37/194 [00:11<00:52,  3.01it/s, acc=0.3372, loss=1.5945]\n",
            "Training:  20%|‚ñà‚ñâ        | 38/194 [00:11<00:44,  3.49it/s, acc=0.3372, loss=1.5945]\n",
            "Training:  20%|‚ñà‚ñâ        | 38/194 [00:11<00:44,  3.49it/s, acc=0.3373, loss=1.6520]\n",
            "Training:  20%|‚ñà‚ñà        | 39/194 [00:11<00:49,  3.14it/s, acc=0.3373, loss=1.6520]\n",
            "Training:  20%|‚ñà‚ñà        | 39/194 [00:11<00:49,  3.14it/s, acc=0.3402, loss=1.4759]\n",
            "Training:  21%|‚ñà‚ñà        | 40/194 [00:11<00:42,  3.62it/s, acc=0.3402, loss=1.4759]\n",
            "Training:  21%|‚ñà‚ñà        | 40/194 [00:12<00:42,  3.62it/s, acc=0.3399, loss=1.5520]\n",
            "Training:  21%|‚ñà‚ñà        | 41/194 [00:12<00:49,  3.06it/s, acc=0.3399, loss=1.5520]\n",
            "Training:  21%|‚ñà‚ñà        | 41/194 [00:12<00:49,  3.06it/s, acc=0.3415, loss=1.5048]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 42/194 [00:12<00:42,  3.55it/s, acc=0.3415, loss=1.5048]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 42/194 [00:12<00:42,  3.55it/s, acc=0.3412, loss=1.5745]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 43/194 [00:12<00:46,  3.23it/s, acc=0.3412, loss=1.5745]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 43/194 [00:13<00:46,  3.23it/s, acc=0.3420, loss=1.6822]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 44/194 [00:13<00:40,  3.69it/s, acc=0.3420, loss=1.6822]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 44/194 [00:13<00:40,  3.69it/s, acc=0.3451, loss=1.4059]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 45/194 [00:13<00:48,  3.09it/s, acc=0.3451, loss=1.4059]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 45/194 [00:13<00:48,  3.09it/s, acc=0.3451, loss=1.6987]\n",
            "Training:  24%|‚ñà‚ñà‚ñé       | 46/194 [00:13<00:41,  3.57it/s, acc=0.3451, loss=1.6987]\n",
            "Training:  24%|‚ñà‚ñà‚ñé       | 46/194 [00:14<00:41,  3.57it/s, acc=0.3431, loss=1.6536]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 47/194 [00:14<00:44,  3.33it/s, acc=0.3431, loss=1.6536]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 47/194 [00:14<00:44,  3.33it/s, acc=0.3447, loss=1.4496]\n",
            "Training:  25%|‚ñà‚ñà‚ñç       | 48/194 [00:14<00:38,  3.79it/s, acc=0.3447, loss=1.4496]\n",
            "Training:  25%|‚ñà‚ñà‚ñç       | 48/194 [00:14<00:38,  3.79it/s, acc=0.3460, loss=1.4337]\n",
            "Training:  25%|‚ñà‚ñà‚ñå       | 49/194 [00:14<00:48,  3.00it/s, acc=0.3460, loss=1.4337]\n",
            "Training:  25%|‚ñà‚ñà‚ñå       | 49/194 [00:14<00:48,  3.00it/s, acc=0.3488, loss=1.5158]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 50/194 [00:14<00:41,  3.50it/s, acc=0.3488, loss=1.5158]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 50/194 [00:15<00:41,  3.50it/s, acc=0.3487, loss=1.6052]\n",
            "Training:  26%|‚ñà‚ñà‚ñã       | 51/194 [00:15<00:48,  2.94it/s, acc=0.3487, loss=1.6052]\n",
            "Training:  26%|‚ñà‚ñà‚ñã       | 51/194 [00:15<00:48,  2.94it/s, acc=0.3495, loss=1.5067]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 52/194 [00:15<00:41,  3.43it/s, acc=0.3495, loss=1.5067]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 52/194 [00:15<00:41,  3.43it/s, acc=0.3488, loss=1.5918]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 53/194 [00:15<00:45,  3.07it/s, acc=0.3488, loss=1.5918]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 53/194 [00:16<00:45,  3.07it/s, acc=0.3510, loss=1.4117]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 54/194 [00:16<00:39,  3.55it/s, acc=0.3510, loss=1.4117]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 54/194 [00:16<00:39,  3.55it/s, acc=0.3531, loss=1.5658]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 55/194 [00:16<00:43,  3.18it/s, acc=0.3531, loss=1.5658]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 55/194 [00:16<00:43,  3.18it/s, acc=0.3541, loss=1.5161]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 56/194 [00:16<00:37,  3.65it/s, acc=0.3541, loss=1.5161]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 56/194 [00:17<00:37,  3.65it/s, acc=0.3547, loss=1.5252]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 57/194 [00:17<00:42,  3.21it/s, acc=0.3547, loss=1.5252]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 57/194 [00:17<00:42,  3.21it/s, acc=0.3561, loss=1.5180]\n",
            "Training:  30%|‚ñà‚ñà‚ñâ       | 58/194 [00:17<00:36,  3.68it/s, acc=0.3561, loss=1.5180]\n",
            "Training:  30%|‚ñà‚ñà‚ñâ       | 58/194 [00:17<00:36,  3.68it/s, acc=0.3567, loss=1.5405]\n",
            "Training:  30%|‚ñà‚ñà‚ñà       | 59/194 [00:17<00:41,  3.23it/s, acc=0.3567, loss=1.5405]\n",
            "Training:  30%|‚ñà‚ñà‚ñà       | 59/194 [00:17<00:41,  3.23it/s, acc=0.3591, loss=1.4116]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 60/194 [00:17<00:36,  3.72it/s, acc=0.3591, loss=1.4116]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 60/194 [00:18<00:36,  3.72it/s, acc=0.3622, loss=1.3768]\n",
            "Training:  31%|‚ñà‚ñà‚ñà‚ñè      | 61/194 [00:18<00:42,  3.16it/s, acc=0.3622, loss=1.3768]\n",
            "Training:  31%|‚ñà‚ñà‚ñà‚ñè      | 61/194 [00:18<00:42,  3.16it/s, acc=0.3616, loss=1.5909]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 62/194 [00:18<00:36,  3.63it/s, acc=0.3616, loss=1.5909]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 62/194 [00:18<00:36,  3.63it/s, acc=0.3586, loss=1.8926]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 63/194 [00:18<00:38,  3.43it/s, acc=0.3586, loss=1.8926]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 63/194 [00:18<00:38,  3.43it/s, acc=0.3591, loss=1.5116]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 64/194 [00:18<00:33,  3.88it/s, acc=0.3591, loss=1.5116]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 64/194 [00:19<00:33,  3.88it/s, acc=0.3601, loss=1.4385]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñé      | 65/194 [00:19<00:35,  3.60it/s, acc=0.3601, loss=1.4385]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñé      | 65/194 [00:19<00:35,  3.60it/s, acc=0.3603, loss=1.4242]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 66/194 [00:19<00:31,  4.03it/s, acc=0.3603, loss=1.4242]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 66/194 [00:19<00:31,  4.03it/s, acc=0.3617, loss=1.4617]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñç      | 67/194 [00:19<00:33,  3.74it/s, acc=0.3617, loss=1.4617]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñç      | 67/194 [00:19<00:33,  3.74it/s, acc=0.3633, loss=1.3308]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñå      | 68/194 [00:19<00:30,  4.14it/s, acc=0.3633, loss=1.3308]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñå      | 68/194 [00:20<00:30,  4.14it/s, acc=0.3650, loss=1.3223]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 69/194 [00:20<00:32,  3.80it/s, acc=0.3650, loss=1.3223]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 69/194 [00:20<00:32,  3.80it/s, acc=0.3654, loss=1.4794]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 70/194 [00:20<00:32,  3.84it/s, acc=0.3654, loss=1.4794]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 70/194 [00:20<00:32,  3.84it/s, acc=0.3662, loss=1.4739]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 71/194 [00:20<00:31,  3.85it/s, acc=0.3662, loss=1.4739]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 71/194 [00:21<00:31,  3.85it/s, acc=0.3663, loss=1.5031]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 72/194 [00:21<00:34,  3.56it/s, acc=0.3663, loss=1.5031]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 72/194 [00:21<00:34,  3.56it/s, acc=0.3669, loss=1.5538]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 73/194 [00:21<00:30,  3.98it/s, acc=0.3669, loss=1.5538]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 73/194 [00:21<00:30,  3.98it/s, acc=0.3676, loss=1.5520]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 74/194 [00:21<00:34,  3.45it/s, acc=0.3676, loss=1.5520]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 74/194 [00:21<00:34,  3.45it/s, acc=0.3683, loss=1.5681]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñä      | 75/194 [00:21<00:30,  3.89it/s, acc=0.3683, loss=1.5681]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñä      | 75/194 [00:22<00:30,  3.89it/s, acc=0.3692, loss=1.4616]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 76/194 [00:22<00:34,  3.39it/s, acc=0.3692, loss=1.4616]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 76/194 [00:22<00:34,  3.39it/s, acc=0.3699, loss=1.4351]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñâ      | 77/194 [00:22<00:30,  3.83it/s, acc=0.3699, loss=1.4351]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñâ      | 77/194 [00:22<00:30,  3.83it/s, acc=0.3720, loss=1.3007]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñà      | 78/194 [00:22<00:36,  3.20it/s, acc=0.3720, loss=1.3007]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñà      | 78/194 [00:23<00:36,  3.20it/s, acc=0.3736, loss=1.2829]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 79/194 [00:23<00:31,  3.67it/s, acc=0.3736, loss=1.2829]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 79/194 [00:23<00:31,  3.67it/s, acc=0.3750, loss=1.3961]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 80/194 [00:23<00:36,  3.14it/s, acc=0.3750, loss=1.3961]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 80/194 [00:23<00:36,  3.14it/s, acc=0.3767, loss=1.3519]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 81/194 [00:23<00:31,  3.61it/s, acc=0.3767, loss=1.3519]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 81/194 [00:24<00:31,  3.61it/s, acc=0.3775, loss=1.5235]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 82/194 [00:24<00:36,  3.08it/s, acc=0.3775, loss=1.5235]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 82/194 [00:24<00:36,  3.08it/s, acc=0.3788, loss=1.3465]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 83/194 [00:24<00:31,  3.56it/s, acc=0.3788, loss=1.3465]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 83/194 [00:24<00:31,  3.56it/s, acc=0.3800, loss=1.1850]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 84/194 [00:24<00:36,  2.98it/s, acc=0.3800, loss=1.1850]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 84/194 [00:24<00:36,  2.98it/s, acc=0.3809, loss=1.3872]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 85/194 [00:24<00:31,  3.47it/s, acc=0.3809, loss=1.3872]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 85/194 [00:25<00:31,  3.47it/s, acc=0.3823, loss=1.3150]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 86/194 [00:25<00:32,  3.30it/s, acc=0.3823, loss=1.3150]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 86/194 [00:25<00:32,  3.30it/s, acc=0.3833, loss=1.3029]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 87/194 [00:25<00:28,  3.76it/s, acc=0.3833, loss=1.3029]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 87/194 [00:25<00:28,  3.76it/s, acc=0.3833, loss=1.5694]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 88/194 [00:25<00:29,  3.65it/s, acc=0.3833, loss=1.5694]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 88/194 [00:25<00:29,  3.65it/s, acc=0.3841, loss=1.4383]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 89/194 [00:25<00:25,  4.08it/s, acc=0.3841, loss=1.4383]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 89/194 [00:26<00:25,  4.08it/s, acc=0.3844, loss=1.4522]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 90/194 [00:26<00:29,  3.50it/s, acc=0.3844, loss=1.4522]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 90/194 [00:26<00:29,  3.50it/s, acc=0.3843, loss=1.6913]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 91/194 [00:26<00:26,  3.93it/s, acc=0.3843, loss=1.6913]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 91/194 [00:26<00:26,  3.93it/s, acc=0.3854, loss=1.3144]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 92/194 [00:26<00:31,  3.22it/s, acc=0.3854, loss=1.3144]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 92/194 [00:27<00:31,  3.22it/s, acc=0.3866, loss=1.2573]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 93/194 [00:27<00:27,  3.70it/s, acc=0.3866, loss=1.2573]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 93/194 [00:27<00:27,  3.70it/s, acc=0.3878, loss=1.3033]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 94/194 [00:27<00:33,  3.01it/s, acc=0.3878, loss=1.3033]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 94/194 [00:27<00:33,  3.01it/s, acc=0.3891, loss=1.0970]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 95/194 [00:27<00:28,  3.48it/s, acc=0.3891, loss=1.0970]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 95/194 [00:28<00:28,  3.48it/s, acc=0.3900, loss=1.2681]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 96/194 [00:28<00:28,  3.39it/s, acc=0.3900, loss=1.2681]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 96/194 [00:28<00:28,  3.39it/s, acc=0.3908, loss=1.4501]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 97/194 [00:28<00:25,  3.84it/s, acc=0.3908, loss=1.4501]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 97/194 [00:28<00:25,  3.84it/s, acc=0.3916, loss=1.3848]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 98/194 [00:28<00:26,  3.66it/s, acc=0.3916, loss=1.3848]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 98/194 [00:28<00:26,  3.66it/s, acc=0.3924, loss=1.2897]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 99/194 [00:28<00:23,  4.08it/s, acc=0.3924, loss=1.2897]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 99/194 [00:28<00:23,  4.08it/s, acc=0.3934, loss=1.3610]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 100/194 [00:28<00:25,  3.72it/s, acc=0.3934, loss=1.3610]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 100/194 [00:29<00:25,  3.72it/s, acc=0.3945, loss=1.3004]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 101/194 [00:29<00:22,  4.12it/s, acc=0.3945, loss=1.3004]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 101/194 [00:29<00:22,  4.12it/s, acc=0.3948, loss=1.5936]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 102/194 [00:29<00:25,  3.61it/s, acc=0.3948, loss=1.5936]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 102/194 [00:29<00:25,  3.61it/s, acc=0.3947, loss=1.5205]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 103/194 [00:29<00:22,  4.03it/s, acc=0.3947, loss=1.5205]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 103/194 [00:30<00:22,  4.03it/s, acc=0.3956, loss=1.3361]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 104/194 [00:30<00:24,  3.73it/s, acc=0.3956, loss=1.3361]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 104/194 [00:30<00:24,  3.73it/s, acc=0.3960, loss=1.5428]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 105/194 [00:30<00:22,  4.02it/s, acc=0.3960, loss=1.5428]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 105/194 [00:30<00:22,  4.02it/s, acc=0.3962, loss=1.4006]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 106/194 [00:30<00:26,  3.27it/s, acc=0.3962, loss=1.4006]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 106/194 [00:30<00:26,  3.27it/s, acc=0.3969, loss=1.4430]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 107/194 [00:30<00:23,  3.69it/s, acc=0.3969, loss=1.4430]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 107/194 [00:31<00:23,  3.69it/s, acc=0.3979, loss=1.3038]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 108/194 [00:31<00:25,  3.38it/s, acc=0.3979, loss=1.3038]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 108/194 [00:31<00:25,  3.38it/s, acc=0.3978, loss=1.4191]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 109/194 [00:31<00:22,  3.77it/s, acc=0.3978, loss=1.4191]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 109/194 [00:31<00:22,  3.77it/s, acc=0.3986, loss=1.3371]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 110/194 [00:31<00:26,  3.20it/s, acc=0.3986, loss=1.3371]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 110/194 [00:32<00:26,  3.20it/s, acc=0.3986, loss=1.5871]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 111/194 [00:32<00:22,  3.68it/s, acc=0.3986, loss=1.5871]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 111/194 [00:32<00:22,  3.68it/s, acc=0.4001, loss=1.2969]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 112/194 [00:32<00:25,  3.27it/s, acc=0.4001, loss=1.2969]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 112/194 [00:32<00:25,  3.27it/s, acc=0.4004, loss=1.4734]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 113/194 [00:32<00:21,  3.74it/s, acc=0.4004, loss=1.4734]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 113/194 [00:33<00:21,  3.74it/s, acc=0.4017, loss=1.2105]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 114/194 [00:33<00:25,  3.08it/s, acc=0.4017, loss=1.2105]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 114/194 [00:33<00:25,  3.08it/s, acc=0.4019, loss=1.3386]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 115/194 [00:33<00:22,  3.55it/s, acc=0.4019, loss=1.3386]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 115/194 [00:33<00:22,  3.55it/s, acc=0.4032, loss=1.3493]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 116/194 [00:33<00:22,  3.39it/s, acc=0.4032, loss=1.3493]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 116/194 [00:33<00:22,  3.39it/s, acc=0.4041, loss=1.1829]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 117/194 [00:33<00:20,  3.83it/s, acc=0.4041, loss=1.1829]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 117/194 [00:34<00:20,  3.83it/s, acc=0.4049, loss=1.3063]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 118/194 [00:34<00:23,  3.25it/s, acc=0.4049, loss=1.3063]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 118/194 [00:34<00:23,  3.25it/s, acc=0.4061, loss=1.3394]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 119/194 [00:34<00:20,  3.71it/s, acc=0.4061, loss=1.3394]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 119/194 [00:34<00:20,  3.71it/s, acc=0.4065, loss=1.5777]#015Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 120/194 [00:34<00:24,  3.00it/s, acc=0.4065, loss=1.5777]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 120/194 [00:34<00:24,  3.00it/s, acc=0.4062, loss=1.4048]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 121/194 [00:34<00:21,  3.47it/s, acc=0.4062, loss=1.4048]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 121/194 [00:35<00:21,  3.47it/s, acc=0.4071, loss=1.5080]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 122/194 [00:35<00:23,  3.04it/s, acc=0.4071, loss=1.5080]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 122/194 [00:35<00:23,  3.04it/s, acc=0.4088, loss=1.1507]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 123/194 [00:35<00:20,  3.53it/s, acc=0.4088, loss=1.1507]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 123/194 [00:36<00:20,  3.53it/s, acc=0.4091, loss=1.4062]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 124/194 [00:36<00:23,  2.95it/s, acc=0.4091, loss=1.4062]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 124/194 [00:36<00:23,  2.95it/s, acc=0.4090, loss=1.5240]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 125/194 [00:36<00:20,  3.43it/s, acc=0.4090, loss=1.5240]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 125/194 [00:36<00:20,  3.43it/s, acc=0.4086, loss=1.6075]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 126/194 [00:36<00:22,  2.97it/s, acc=0.4086, loss=1.6075]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 126/194 [00:36<00:22,  2.97it/s, acc=0.4088, loss=1.4309]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 127/194 [00:36<00:19,  3.45it/s, acc=0.4088, loss=1.4309]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 127/194 [00:37<00:19,  3.45it/s, acc=0.4089, loss=1.5838]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 128/194 [00:37<00:21,  3.03it/s, acc=0.4089, loss=1.5838]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 128/194 [00:37<00:21,  3.03it/s, acc=0.4100, loss=1.2003]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 129/194 [00:37<00:18,  3.50it/s, acc=0.4100, loss=1.2003]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 129/194 [00:37<00:18,  3.50it/s, acc=0.4102, loss=1.4157]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 130/194 [00:37<00:21,  3.02it/s, acc=0.4102, loss=1.4157]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 130/194 [00:38<00:21,  3.02it/s, acc=0.4107, loss=1.3291]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 131/194 [00:38<00:17,  3.50it/s, acc=0.4107, loss=1.3291]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 131/194 [00:38<00:17,  3.50it/s, acc=0.4116, loss=1.3210]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 132/194 [00:38<00:18,  3.41it/s, acc=0.4116, loss=1.3210]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 132/194 [00:38<00:18,  3.41it/s, acc=0.4124, loss=1.3147]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 133/194 [00:38<00:15,  3.88it/s, acc=0.4124, loss=1.3147]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 133/194 [00:38<00:15,  3.88it/s, acc=0.4127, loss=1.5362]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 134/194 [00:38<00:18,  3.29it/s, acc=0.4127, loss=1.5362]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 134/194 [00:39<00:18,  3.29it/s, acc=0.4127, loss=1.5291]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 135/194 [00:39<00:15,  3.75it/s, acc=0.4127, loss=1.5291]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 135/194 [00:39<00:15,  3.75it/s, acc=0.4134, loss=1.2516]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 136/194 [00:39<00:16,  3.51it/s, acc=0.4134, loss=1.2516]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 136/194 [00:39<00:16,  3.51it/s, acc=0.4142, loss=1.1636]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 137/194 [00:39<00:14,  3.95it/s, acc=0.4142, loss=1.1636]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 137/194 [00:40<00:14,  3.95it/s, acc=0.4150, loss=1.3289]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 138/194 [00:40<00:17,  3.24it/s, acc=0.4150, loss=1.3289]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 138/194 [00:40<00:17,  3.24it/s, acc=0.4155, loss=1.2622]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 139/194 [00:40<00:14,  3.72it/s, acc=0.4155, loss=1.2622]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 139/194 [00:40<00:14,  3.72it/s, acc=0.4164, loss=1.2131]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 140/194 [00:40<00:19,  2.74it/s, acc=0.4164, loss=1.2131]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 140/194 [00:41<00:19,  2.74it/s, acc=0.4170, loss=1.2944]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 141/194 [00:41<00:16,  3.24it/s, acc=0.4170, loss=1.2944]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 141/194 [00:41<00:16,  3.24it/s, acc=0.4179, loss=1.2354]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 142/194 [00:41<00:18,  2.79it/s, acc=0.4179, loss=1.2354]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 142/194 [00:41<00:18,  2.79it/s, acc=0.4182, loss=1.2592]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 143/194 [00:41<00:15,  3.28it/s, acc=0.4182, loss=1.2592]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 143/194 [00:41<00:15,  3.28it/s, acc=0.4192, loss=1.2333]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 144/194 [00:41<00:15,  3.29it/s, acc=0.4192, loss=1.2333]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 144/194 [00:42<00:15,  3.29it/s, acc=0.4200, loss=1.2513]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 145/194 [00:42<00:13,  3.75it/s, acc=0.4200, loss=1.2513]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 145/194 [00:42<00:13,  3.75it/s, acc=0.4210, loss=1.1883]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 146/194 [00:42<00:13,  3.60it/s, acc=0.4210, loss=1.1883]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 146/194 [00:42<00:13,  3.60it/s, acc=0.4212, loss=1.4645]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 147/194 [00:42<00:11,  4.02it/s, acc=0.4212, loss=1.4645]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 147/194 [00:43<00:11,  4.02it/s, acc=0.4221, loss=1.2036]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 148/194 [00:43<00:14,  3.25it/s, acc=0.4221, loss=1.2036]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 148/194 [00:43<00:14,  3.25it/s, acc=0.4227, loss=1.3962]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 149/194 [00:43<00:12,  3.71it/s, acc=0.4227, loss=1.3962]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 149/194 [00:43<00:12,  3.71it/s, acc=0.4234, loss=1.3031]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 150/194 [00:43<00:12,  3.49it/s, acc=0.4234, loss=1.3031]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 150/194 [00:43<00:12,  3.49it/s, acc=0.4229, loss=1.5671]#015Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 151/194 [00:43<00:10,  3.93it/s, acc=0.4229, loss=1.5671]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 151/194 [00:44<00:10,  3.93it/s, acc=0.4227, loss=1.4410]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 152/194 [00:44<00:11,  3.75it/s, acc=0.4227, loss=1.4410]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 152/194 [00:44<00:11,  3.75it/s, acc=0.4227, loss=1.3963]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 153/194 [00:44<00:09,  4.17it/s, acc=0.4227, loss=1.3963]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 153/194 [00:44<00:09,  4.17it/s, acc=0.4238, loss=1.1325]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 154/194 [00:44<00:12,  3.23it/s, acc=0.4238, loss=1.1325]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 154/194 [00:44<00:12,  3.23it/s, acc=0.4245, loss=1.2920]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 155/194 [00:44<00:10,  3.69it/s, acc=0.4245, loss=1.2920]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 155/194 [00:45<00:10,  3.69it/s, acc=0.4247, loss=1.2348]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 156/194 [00:45<00:10,  3.49it/s, acc=0.4247, loss=1.2348]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 156/194 [00:45<00:10,  3.49it/s, acc=0.4255, loss=1.2993]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 157/194 [00:45<00:09,  3.92it/s, acc=0.4255, loss=1.2993]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 157/194 [00:45<00:09,  3.92it/s, acc=0.4253, loss=1.4898]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 158/194 [00:45<00:09,  3.67it/s, acc=0.4253, loss=1.4898]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 158/194 [00:46<00:09,  3.67it/s, acc=0.4248, loss=1.5373]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 159/194 [00:46<00:09,  3.70it/s, acc=0.4248, loss=1.5373]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 159/194 [00:46<00:09,  3.70it/s, acc=0.4254, loss=1.2995]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 160/194 [00:46<00:08,  3.90it/s, acc=0.4254, loss=1.2995]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 160/194 [00:46<00:08,  3.90it/s, acc=0.4260, loss=1.3297]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 161/194 [00:46<00:09,  3.47it/s, acc=0.4260, loss=1.3297]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 161/194 [00:46<00:09,  3.47it/s, acc=0.4260, loss=1.4570]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 162/194 [00:46<00:08,  3.89it/s, acc=0.4260, loss=1.4570]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 162/194 [00:47<00:08,  3.89it/s, acc=0.4266, loss=1.3096]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 163/194 [00:47<00:09,  3.38it/s, acc=0.4266, loss=1.3096]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 163/194 [00:47<00:09,  3.38it/s, acc=0.4273, loss=1.2159]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 164/194 [00:47<00:07,  3.81it/s, acc=0.4273, loss=1.2159]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 164/194 [00:47<00:07,  3.81it/s, acc=0.4279, loss=1.1980]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 165/194 [00:47<00:08,  3.26it/s, acc=0.4279, loss=1.1980]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 165/194 [00:47<00:08,  3.26it/s, acc=0.4280, loss=1.2858]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 166/194 [00:47<00:07,  3.70it/s, acc=0.4280, loss=1.2858]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 166/194 [00:48<00:07,  3.70it/s, acc=0.4286, loss=1.2398]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 167/194 [00:48<00:08,  3.25it/s, acc=0.4286, loss=1.2398]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 167/194 [00:48<00:08,  3.25it/s, acc=0.4295, loss=1.1210]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 168/194 [00:48<00:07,  3.70it/s, acc=0.4295, loss=1.1210]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 168/194 [00:48<00:07,  3.70it/s, acc=0.4302, loss=1.1698]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 169/194 [00:48<00:07,  3.34it/s, acc=0.4302, loss=1.1698]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 169/194 [00:49<00:07,  3.34it/s, acc=0.4302, loss=1.4734]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 170/194 [00:49<00:06,  3.78it/s, acc=0.4302, loss=1.4734]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 170/194 [00:49<00:06,  3.78it/s, acc=0.4306, loss=1.3471]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 171/194 [00:49<00:07,  3.24it/s, acc=0.4306, loss=1.3471]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 171/194 [00:49<00:07,  3.24it/s, acc=0.4304, loss=1.5746]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 172/194 [00:49<00:05,  3.70it/s, acc=0.4304, loss=1.5746]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 172/194 [00:50<00:05,  3.70it/s, acc=0.4309, loss=1.1276]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 173/194 [00:50<00:06,  3.20it/s, acc=0.4309, loss=1.1276]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 173/194 [00:50<00:06,  3.20it/s, acc=0.4315, loss=1.3726]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 174/194 [00:50<00:05,  3.68it/s, acc=0.4315, loss=1.3726]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 174/194 [00:50<00:05,  3.68it/s, acc=0.4321, loss=1.1435]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 175/194 [00:50<00:06,  3.00it/s, acc=0.4321, loss=1.1435]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 175/194 [00:50<00:06,  3.00it/s, acc=0.4329, loss=1.2699]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 176/194 [00:50<00:05,  3.50it/s, acc=0.4329, loss=1.2699]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 176/194 [00:51<00:05,  3.50it/s, acc=0.4334, loss=1.1538]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 177/194 [00:51<00:05,  3.02it/s, acc=0.4334, loss=1.1538]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 177/194 [00:51<00:05,  3.02it/s, acc=0.4342, loss=1.2243]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 178/194 [00:51<00:04,  3.49it/s, acc=0.4342, loss=1.2243]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 178/194 [00:51<00:04,  3.49it/s, acc=0.4353, loss=1.1525]#015Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 179/194 [00:51<00:04,  3.50it/s, acc=0.4353, loss=1.1525]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 179/194 [00:51<00:04,  3.50it/s, acc=0.4359, loss=1.2372]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 180/194 [00:51<00:03,  3.90it/s, acc=0.4359, loss=1.2372]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 180/194 [00:52<00:03,  3.90it/s, acc=0.4366, loss=1.1928]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 181/194 [00:52<00:03,  3.43it/s, acc=0.4366, loss=1.1928]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 181/194 [00:52<00:03,  3.43it/s, acc=0.4369, loss=1.3874]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 182/194 [00:52<00:03,  3.86it/s, acc=0.4369, loss=1.3874]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 182/194 [00:52<00:03,  3.86it/s, acc=0.4368, loss=1.3145]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 183/194 [00:52<00:03,  3.32it/s, acc=0.4368, loss=1.3145]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 183/194 [00:53<00:03,  3.32it/s, acc=0.4372, loss=1.2307]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 184/194 [00:53<00:02,  3.76it/s, acc=0.4372, loss=1.2307]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 184/194 [00:53<00:02,  3.76it/s, acc=0.4383, loss=1.1042]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 185/194 [00:53<00:02,  3.17it/s, acc=0.4383, loss=1.1042]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 185/194 [00:53<00:02,  3.17it/s, acc=0.4384, loss=1.3515]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 186/194 [00:53<00:02,  3.65it/s, acc=0.4384, loss=1.3515]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 186/194 [00:54<00:02,  3.65it/s, acc=0.4388, loss=1.2969]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 187/194 [00:54<00:02,  3.15it/s, acc=0.4388, loss=1.2969]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 187/194 [00:54<00:02,  3.15it/s, acc=0.4392, loss=1.2532]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 188/194 [00:54<00:01,  3.61it/s, acc=0.4392, loss=1.2532]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 188/194 [00:54<00:01,  3.61it/s, acc=0.4397, loss=1.2361]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 189/194 [00:54<00:01,  3.27it/s, acc=0.4397, loss=1.2361]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 189/194 [00:54<00:01,  3.27it/s, acc=0.4396, loss=1.4313]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 190/194 [00:54<00:01,  3.72it/s, acc=0.4396, loss=1.4313]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 190/194 [00:55<00:01,  3.72it/s, acc=0.4397, loss=1.3151]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 191/194 [00:55<00:00,  3.14it/s, acc=0.4397, loss=1.3151]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 191/194 [00:55<00:00,  3.14it/s, acc=0.4405, loss=1.1736]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 192/194 [00:55<00:00,  3.63it/s, acc=0.4405, loss=1.1736]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 192/194 [00:55<00:00,  3.63it/s, acc=0.4410, loss=1.2829]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 193/194 [00:55<00:00,  3.55it/s, acc=0.4410, loss=1.2829]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 193/194 [00:55<00:00,  3.55it/s, acc=0.4413, loss=1.3295]\n",
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 194/194 [00:55<00:00,  3.47it/s, acc=0.4413, loss=1.3295]\n",
            "Train Loss: 1.4480, Train Acc: 0.4413\n",
            "Validating:   0%|          | 0/65 [00:00<?, ?it/s]\n",
            "Validating:   0%|          | 0/65 [00:00<?, ?it/s, acc=0.4688, loss=1.5879]\n",
            "Validating:   2%|‚ñè         | 1/65 [00:00<00:32,  1.98it/s, acc=0.4688, loss=1.5879]\n",
            "Validating:   2%|‚ñè         | 1/65 [00:00<00:32,  1.98it/s, acc=0.4609, loss=1.4040]\n",
            "Validating:   2%|‚ñè         | 1/65 [00:00<00:32,  1.98it/s, acc=0.4167, loss=1.6490]\n",
            "Validating:   5%|‚ñç         | 3/65 [00:00<00:17,  3.54it/s, acc=0.4167, loss=1.6490]\n",
            "Validating:   5%|‚ñç         | 3/65 [00:00<00:17,  3.54it/s, acc=0.4570, loss=1.3650]\n",
            "Validating:   5%|‚ñç         | 3/65 [00:01<00:17,  3.54it/s, acc=0.4844, loss=1.1109]\n",
            "Validating:   8%|‚ñä         | 5/65 [00:01<00:13,  4.34it/s, acc=0.4844, loss=1.1109]\n",
            "Validating:   8%|‚ñä         | 5/65 [00:01<00:13,  4.34it/s, acc=0.4792, loss=1.6423]\n",
            "Validating:   8%|‚ñä         | 5/65 [00:01<00:13,  4.34it/s, acc=0.4643, loss=1.6700]\n",
            "Validating:  11%|‚ñà         | 7/65 [00:01<00:12,  4.70it/s, acc=0.4643, loss=1.6700]\n",
            "\n",
            "================================================================================\n",
            "‚ö†Ô∏è  Showing 500 of 2583 total lines\n",
            "   Run: get_training_logs('animal-classification-training-2025-12-28-01-43-07-396', max_lines=None) to see all\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# RUN THIS CELL TO VIEW LOGS FROM A JOB\n",
        "# Paste the job name from above, or it will use the most recent job\n",
        "# ========================================\n",
        "\n",
        "import boto3\n",
        "\n",
        "def get_training_logs(job_name, region='us-west-1', max_lines=None):\n",
        "    \"\"\"\n",
        "    Get all CloudWatch logs for a SageMaker training job\n",
        "    \n",
        "    Args:\n",
        "        job_name: Name of the training job\n",
        "        region: AWS region\n",
        "        max_lines: Maximum number of log lines to show (None = all)\n",
        "    \"\"\"\n",
        "    logs_client = boto3.client('logs', region_name=region)\n",
        "    \n",
        "    log_group = '/aws/sagemaker/TrainingJobs'\n",
        "    \n",
        "    try:\n",
        "        # List all log streams for this job\n",
        "        streams = logs_client.describe_log_streams(\n",
        "            logGroupName=log_group,\n",
        "            logStreamNamePrefix=job_name,\n",
        "            orderBy='LogStreamName'\n",
        "        )\n",
        "        \n",
        "        if not streams['logStreams']:\n",
        "            print(f\"‚ùå No logs found for job: {job_name}\")\n",
        "            print(\"   Job might still be starting, or name is incorrect\")\n",
        "            return\n",
        "        \n",
        "        all_logs = []\n",
        "        for stream in streams['logStreams']:\n",
        "            stream_name = stream['logStreamName']\n",
        "            \n",
        "            # Get all events from this stream\n",
        "            next_token = None\n",
        "            while True:\n",
        "                kwargs = {\n",
        "                    'logGroupName': log_group,\n",
        "                    'logStreamName': stream_name,\n",
        "                    'startFromHead': True\n",
        "                }\n",
        "                if next_token:\n",
        "                    kwargs['nextToken'] = next_token\n",
        "                \n",
        "                response = logs_client.get_log_events(**kwargs)\n",
        "                \n",
        "                for event in response['events']:\n",
        "                    all_logs.append(event['message'])\n",
        "                \n",
        "                # Check if there are more logs\n",
        "                next_token = response.get('nextForwardToken')\n",
        "                if not response['events'] or next_token == kwargs.get('nextToken'):\n",
        "                    break\n",
        "        \n",
        "        # Print logs\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"üìã TRAINING LOGS: {job_name}\")\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"Total log lines: {len(all_logs)}\")\n",
        "        if max_lines:\n",
        "            print(f\"Showing first {max_lines} lines (set max_lines=None for all)\")\n",
        "        print(\"=\" * 80)\n",
        "        print()\n",
        "        \n",
        "        logs_to_show = all_logs[:max_lines] if max_lines else all_logs\n",
        "        for log in logs_to_show:\n",
        "            print(log)\n",
        "        \n",
        "        if max_lines and len(all_logs) > max_lines:\n",
        "            print()\n",
        "            print(\"=\" * 80)\n",
        "            print(f\"‚ö†Ô∏è  Showing {max_lines} of {len(all_logs)} total lines\")\n",
        "            print(f\"   Run: get_training_logs('{job_name}', max_lines=None) to see all\")\n",
        "            print(\"=\" * 80)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error retrieving logs: {e}\")\n",
        "        print(f\"   Make sure the job name is correct\")\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# PASTE JOB NAME HERE (or leave empty for most recent)\n",
        "# ========================================\n",
        "JOB_NAME = ''  # Example: 'animal-classification-training-2024-12-21-12-34-56-789'\n",
        "\n",
        "# If no job name provided, use most recent\n",
        "if not JOB_NAME:\n",
        "    sagemaker_client = boto3.client('sagemaker', region_name=REGION)\n",
        "    jobs = sagemaker_client.list_training_jobs(MaxResults=1, SortBy='CreationTime', SortOrder='Descending')\n",
        "    if jobs['TrainingJobSummaries']:\n",
        "        JOB_NAME = jobs['TrainingJobSummaries'][0]['TrainingJobName']\n",
        "        print(f\"‚ÑπÔ∏è  No job name specified, using most recent: {JOB_NAME}\\n\")\n",
        "    else:\n",
        "        print(\"‚ùå No training jobs found\")\n",
        "\n",
        "# View logs (showing first 500 lines by default)\n",
        "if JOB_NAME:\n",
        "    get_training_logs(JOB_NAME, REGION, max_lines=500)\n",
        "    \n",
        "# üí° To see ALL logs without limit:\n",
        "# get_training_logs(JOB_NAME, REGION, max_lines=None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9480565",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìñ Quick Reference: Which Cells to Run\n",
        "\n",
        "### **To Start Training (First Time):**\n",
        "1. ‚úÖ Run **Cells 0-3** (Setup & Config)\n",
        "2. ‚úÖ Run **Cell 4-5** (Preprocessing) - Only once needed\n",
        "3. ‚úÖ Run **Cell 6** (Create Estimator)\n",
        "4. ‚úÖ Run **Cell 7** (Start Training) - **SEE ALL LOGS HERE!**\n",
        "\n",
        "### **To View Logs After Closing Computer:**\n",
        "1. ‚úÖ Run **Cells 0-3** (Setup & Config)\n",
        "2. ‚úÖ Run **Cell 9** (List all recent jobs)\n",
        "3. ‚úÖ Run **Cell 10** (View logs fromselected job)\n",
        "\n",
        "### **Tips:**\n",
        "- **Cell 7** shows ALL your `print()` statements from `dss_train.py` in real-time\n",
        "- Logs are automatically saved to CloudWatch (accessible anytime!)\n",
        "- Safe to close computer during training - logs persist in CloudWatch\n",
        "- **Cell 10** retrieves logs from CloudWatch whenever you need them\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e08dd06d",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.11.6)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
