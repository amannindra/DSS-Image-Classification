{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ec31aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/amannindra/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.pytorch.processing import PyTorchProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4423240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "REGION = 'us-west-1'\n",
    "ROLE_ARN = \"arn:aws:iam::253490779227:role/service-role/AmazonSageMakerAdminIAMExecutionRole\"\n",
    "BUCKET = 'animal-classification-dss-works'\n",
    "S3_INPUT_DATA = f's3://{BUCKET}/data/'\n",
    "S3_PREPROCESSED = f's3://{BUCKET}/processed'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2986b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "boto_session = boto3.Session(region_name=REGION)\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto_session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "964cd10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region: us-west-1\n",
      "S3 Bucket: animal-classification-dss-works\n",
      "Input data: s3://animal-classification-dss-works/data/\n",
      "Preprocessed output: s3://animal-classification-dss-works/processed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Region: {sagemaker_session.boto_region_name}\")\n",
    "print(f\"S3 Bucket: {BUCKET}\")\n",
    "print(f\"Input data: {S3_INPUT_DATA}\")\n",
    "print(f\"Preprocessed output: {S3_PREPROCESSED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c98a32a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processor = PyTorchProcessor(\n",
    "#     framework_version='2.1',\n",
    "#     py_version='py310',\n",
    "#     role=ROLE_ARN,\n",
    "#     instance_type='ml.m5.2xlarge',  # CPU instance: $0.23/hour\n",
    "#     instance_count=1,\n",
    "#     sagemaker_session=sagemaker_session,\n",
    "#     base_job_name='animal-preprocessing'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "355fc9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processor.latest_job.stop()\n",
    "\n",
    "###### RUN THIS CELL ONLY ONCE ######\n",
    "\n",
    "# processor.run(\n",
    "#     code='preprocess.py',\n",
    "#     # inputs=[\n",
    "#     #     ProcessingInput(\n",
    "#     #         source=S3_INPUT_DATA,           # Your S3 data folder\n",
    "#     #         destination='/opt/ml/processing/input'  # Where it appears in container\n",
    "#     #     )\n",
    "#     # ],\n",
    "#     # outputs=[\n",
    "#     #     ProcessingOutput(\n",
    "#     #         source='/opt/ml/processing/output',     # Where script saves results\n",
    "#     #         destination=S3_PREPROCESSED              # Upload results here\n",
    "#     #     )\n",
    "#     # ],\n",
    "#     # arguments=[\n",
    "#     #     '--input-dir', '/opt/ml/processing/input',\n",
    "#     #     '--output-dir', '/opt/ml/processing/output'\n",
    "#     # ]\n",
    "# )\n",
    "# print(f\"Preprocessed data saved to: {S3_PREPROCESSED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc85ee86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SAGEMAKER RUNNING JOBS\n",
      "================================================================================\n",
      "\n",
      "‚úì No running jobs found!\n"
     ]
    }
   ],
   "source": [
    "!python manage_sagemaker_jobs.py --action stop-all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae786a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point='dss_train.py',\n",
    "    source_dir='.',\n",
    "    role=ROLE_ARN,\n",
    "    framework_version='2.1',\n",
    "    py_version='py310',\n",
    "    instance_count=1,\n",
    "    instance_type='ml.g4dn.xlarge',  # GPU instance with NVIDIA T4\n",
    "    hyperparameters={\n",
    "        'epochs': 10,\n",
    "        'batch-size': 64,  # Larger batch size with GPU\n",
    "        'learning-rate': 0.001,\n",
    "        'use-cuda': True\n",
    "    },\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    base_job_name='animal-classification-training',\n",
    "    # Use Spot instances to save 70% (optional)\n",
    "    # use_spot_instances=True,\n",
    "    # max_wait=7200,  # 2 hours\n",
    "    # max_run=3600,   # 1 hour\n",
    ")\n",
    "# estimator.latest_training_job.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5b92d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: animal-classification-training-2025-12-26-04-25-52-717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-26 04:26:01 Starting - Starting the training job\n",
      "2025-12-26 04:26:01 Pending - Training job waiting for capacity...\n",
      "2025-12-26 04:26:39 Pending - Preparing the instances for training...\n",
      "2025-12-26 04:27:05 Downloading - Downloading input data...."
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# RUN THIS CELL TO START TRAINING\n",
    "# You'll see ALL logs stream in real-time\n",
    "# ========================================\n",
    "\n",
    "# print(\"Created PyTorch Estimator:\")\n",
    "# print(f\"  Instance: ml.g4dn.xlarge (4 vCPUs, 16GB RAM, 1x NVIDIA T4 GPU)\")\n",
    "# print(f\"  Cost: ~$0.94/hour (~$2 for full training)\")\n",
    "# print(f\"  Expected time: 1-2 hours\")\n",
    "# print(f\"  Speed: 10-50x faster than CPU!\")\n",
    "\n",
    "# # Start training with PREPROCESSED data\n",
    "# print(\"\\nüöÄ Starting training job with GPU...\")\n",
    "# print(\"All print statements from dss_train.py will stream below...\")\n",
    "# print(\"(Safe to close computer - logs saved to CloudWatch)\")\n",
    "# print(\"=\"*70)\n",
    "\n",
    "estimator.fit(\n",
    "    {'training': S3_PREPROCESSED},\n",
    "    wait=True,      # ‚úÖ Wait for job to complete\n",
    "    logs='All'      # ‚úÖ Stream ALL logs to notebook (shows all print statements!)\n",
    ")\n",
    "\n",
    "# print(\"\\n\" + \"=\"*70)\n",
    "# print(\"‚úÖ PIPELINE COMPLETE!\")\n",
    "# print(\"=\"*70)\n",
    "# print(f\"\\nJob Name: {estimator.latest_training_job.name}\")\n",
    "# print(f\"Model saved to: {estimator.model_data}\")\n",
    "# print(f\"\\nTotal cost estimate:\")\n",
    "# print(f\"  Preprocessing (ml.m5.xlarge): ~$0.50\")\n",
    "# print(f\"  Training (ml.g4dn.xlarge):    ~$2.00\")\n",
    "# print(f\"  TOTAL:                        ~$2.50\")\n",
    "# print(f\"\\nVs running on CPU locally: 20-30 hours!\")\n",
    "# print(\"\\nüìã To view logs again later, run the cells below ‚¨áÔ∏è\")\n",
    "# print(\"=\"*70)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a883bd0",
   "metadata": {},
   "source": [
    "# üìã View Training Logs Anytime\n",
    "\n",
    "**Use the cells below to view logs after closing/reopening your computer**\n",
    "\n",
    "- **Cell below**: List all recent training jobs\n",
    "- **Next cell**: View complete logs from any job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6e6b9532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RECENT TRAINING JOBS\n",
      "================================================================================\n",
      "\n",
      "#    Job Name                                           Status         \n",
      "--------------------------------------------------------------------------------\n",
      "0    animal-classification-training-2025-12-25-04-41-08-092 ‚ùå Failed\n",
      "1    animal-classification-training-2025-12-25-00-41-45-217 ‚ùå Failed\n",
      "2    pytorch-training-2025-12-19-20-27-45-421           ‚úÖ Completed\n",
      "3    pytorch-training-2025-11-25-03-12-35-197           ‚úÖ Completed\n",
      "4    pytorch-training-2025-11-25-02-50-20-903           ‚è∏Ô∏è Stopped\n",
      "5    pytorch-training-2025-11-25-01-20-24-073           ‚ùå Failed\n",
      "6    pytorch-training-2025-11-24-19-02-47-655           ‚ùå Failed\n",
      "\n",
      "================================================================================\n",
      "üí° Copy a job name above and paste it in the next cell to view its logs\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# RUN THIS CELL TO LIST ALL RECENT JOBS\n",
    "# ========================================\n",
    "\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "\n",
    "sagemaker_client = boto3.client('sagemaker', region_name=REGION)\n",
    "\n",
    "# Get recent training jobs\n",
    "jobs = sagemaker_client.list_training_jobs(\n",
    "    MaxResults=10, \n",
    "    SortBy='CreationTime', \n",
    "    SortOrder='Descending'\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RECENT TRAINING JOBS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n{'#':<4} {'Job Name':<50} {'Status':<15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, job in enumerate(jobs['TrainingJobSummaries']):\n",
    "    job_name = job['TrainingJobName']\n",
    "    status = job['TrainingJobStatus']\n",
    "    created = job['CreationTime'].strftime('%Y-%m-%d %H:%M')\n",
    "    \n",
    "    # Color code status\n",
    "    status_symbol = {\n",
    "        'InProgress': 'üîÑ',\n",
    "        'Completed': '‚úÖ',\n",
    "        'Failed': '‚ùå',\n",
    "        'Stopped': '‚è∏Ô∏è'\n",
    "    }.get(status, '‚ùì')\n",
    "    \n",
    "    print(f\"{i:<4} {job_name:<50} {status_symbol} {status}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üí° Copy a job name above and paste it in the next cell to view its logs\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c6869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# RUN THIS CELL TO VIEW LOGS FROM A JOB\n",
    "# Paste the job name from above, or it will use the most recent job\n",
    "# ========================================\n",
    "\n",
    "import boto3\n",
    "\n",
    "def get_training_logs(job_name, region='us-west-1', max_lines=None):\n",
    "    \"\"\"\n",
    "    Get all CloudWatch logs for a SageMaker training job\n",
    "    \n",
    "    Args:\n",
    "        job_name: Name of the training job\n",
    "        region: AWS region\n",
    "        max_lines: Maximum number of log lines to show (None = all)\n",
    "    \"\"\"\n",
    "    logs_client = boto3.client('logs', region_name=region)\n",
    "    \n",
    "    log_group = '/aws/sagemaker/TrainingJobs'\n",
    "    \n",
    "    try:\n",
    "        # List all log streams for this job\n",
    "        streams = logs_client.describe_log_streams(\n",
    "            logGroupName=log_group,\n",
    "            logStreamNamePrefix=job_name,\n",
    "            orderBy='LogStreamName'\n",
    "        )\n",
    "        \n",
    "        if not streams['logStreams']:\n",
    "            print(f\"‚ùå No logs found for job: {job_name}\")\n",
    "            print(\"   Job might still be starting, or name is incorrect\")\n",
    "            return\n",
    "        \n",
    "        all_logs = []\n",
    "        for stream in streams['logStreams']:\n",
    "            stream_name = stream['logStreamName']\n",
    "            \n",
    "            # Get all events from this stream\n",
    "            next_token = None\n",
    "            while True:\n",
    "                kwargs = {\n",
    "                    'logGroupName': log_group,\n",
    "                    'logStreamName': stream_name,\n",
    "                    'startFromHead': True\n",
    "                }\n",
    "                if next_token:\n",
    "                    kwargs['nextToken'] = next_token\n",
    "                \n",
    "                response = logs_client.get_log_events(**kwargs)\n",
    "                \n",
    "                for event in response['events']:\n",
    "                    all_logs.append(event['message'])\n",
    "                \n",
    "                # Check if there are more logs\n",
    "                next_token = response.get('nextForwardToken')\n",
    "                if not response['events'] or next_token == kwargs.get('nextToken'):\n",
    "                    break\n",
    "        \n",
    "        # Print logs\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"üìã TRAINING LOGS: {job_name}\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"Total log lines: {len(all_logs)}\")\n",
    "        if max_lines:\n",
    "            print(f\"Showing first {max_lines} lines (set max_lines=None for all)\")\n",
    "        print(\"=\" * 80)\n",
    "        print()\n",
    "        \n",
    "        logs_to_show = all_logs[:max_lines] if max_lines else all_logs\n",
    "        for log in logs_to_show:\n",
    "            print(log)\n",
    "        \n",
    "        if max_lines and len(all_logs) > max_lines:\n",
    "            print()\n",
    "            print(\"=\" * 80)\n",
    "            print(f\"‚ö†Ô∏è  Showing {max_lines} of {len(all_logs)} total lines\")\n",
    "            print(f\"   Run: get_training_logs('{job_name}', max_lines=None) to see all\")\n",
    "            print(\"=\" * 80)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error retrieving logs: {e}\")\n",
    "        print(f\"   Make sure the job name is correct\")\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# PASTE JOB NAME HERE (or leave empty for most recent)\n",
    "# ========================================\n",
    "JOB_NAME = ''  # Example: 'animal-classification-training-2024-12-21-12-34-56-789'\n",
    "\n",
    "# If no job name provided, use most recent\n",
    "if not JOB_NAME:\n",
    "    sagemaker_client = boto3.client('sagemaker', region_name=REGION)\n",
    "    jobs = sagemaker_client.list_training_jobs(MaxResults=1, SortBy='CreationTime', SortOrder='Descending')\n",
    "    if jobs['TrainingJobSummaries']:\n",
    "        JOB_NAME = jobs['TrainingJobSummaries'][0]['TrainingJobName']\n",
    "        print(f\"‚ÑπÔ∏è  No job name specified, using most recent: {JOB_NAME}\\n\")\n",
    "    else:\n",
    "        print(\"‚ùå No training jobs found\")\n",
    "\n",
    "# View logs (showing first 500 lines by default)\n",
    "if JOB_NAME:\n",
    "    get_training_logs(JOB_NAME, REGION, max_lines=500)\n",
    "    \n",
    "# üí° To see ALL logs without limit:\n",
    "# get_training_logs(JOB_NAME, REGION, max_lines=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9480565",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìñ Quick Reference: Which Cells to Run\n",
    "\n",
    "### **To Start Training (First Time):**\n",
    "1. ‚úÖ Run **Cells 0-3** (Setup & Config)\n",
    "2. ‚úÖ Run **Cell 4-5** (Preprocessing) - Only once needed\n",
    "3. ‚úÖ Run **Cell 6** (Create Estimator)\n",
    "4. ‚úÖ Run **Cell 7** (Start Training) - **SEE ALL LOGS HERE!**\n",
    "\n",
    "### **To View Logs After Closing Computer:**\n",
    "1. ‚úÖ Run **Cells 0-3** (Setup & Config)\n",
    "2. ‚úÖ Run **Cell 9** (List all recent jobs)\n",
    "3. ‚úÖ Run **Cell 10** (View logs fromselected job)\n",
    "\n",
    "### **Tips:**\n",
    "- **Cell 7** shows ALL your `print()` statements from `dss_train.py` in real-time\n",
    "- Logs are automatically saved to CloudWatch (accessible anytime!)\n",
    "- Safe to close computer during training - logs persist in CloudWatch\n",
    "- **Cell 10** retrieves logs from CloudWatch whenever you need them\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08dd06d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
