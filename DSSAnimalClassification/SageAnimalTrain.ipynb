{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4ec31aff",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
            "sagemaker.config INFO - Not applying SDK defaults from location: /Users/amannindra/Library/Application Support/sagemaker/config.yaml\n"
          ]
        }
      ],
      "source": [
        "import boto3\n",
        "import sagemaker\n",
        "\n",
        "from sagemaker.pytorch import PyTorch\n",
        "from sagemaker.pytorch.processing import PyTorchProcessor\n",
        "from sagemaker.processing import ProcessingInput, ProcessingOutput"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4423240b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "REGION = 'us-east-1'\n",
        "ROLE_ARN = \"arn:aws:iam::253490779227:role/service-role/AmazonSageMakerAdminIAMExecutionRole\"\n",
        "BUCKET = 'animal-classification-dss-works'\n",
        "BUCKET_VIRGINIA = 'animal-classification-virgina'\n",
        "S3_INPUT_DATA = f's3://{BUCKET}/data/'\n",
        "S3_PREPROCESSED = f's3://{BUCKET_VIRGINIA}/processed'\n",
        "S3_SHORT_PREPROCESSED = f's3://{BUCKET}/short_processed'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f2986b6d",
      "metadata": {},
      "outputs": [],
      "source": [
        "boto_session = boto3.Session(region_name=REGION)\n",
        "sagemaker_session = sagemaker.Session(boto_session=boto_session)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "581e7c9b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "SAGEMAKER RUNNING JOBS\n",
            "(All job types: Training, Processing, Transform, HyperparameterTuning,\n",
            " AutoML, Compilation, EdgePackaging, Labeling, Monitoring)\n",
            "================================================================================\n",
            "Scanning job types...\n",
            "Error listing compilation jobs with status InProgress: An error occurred (ValidationException) when calling the ListCompilationJobs operation: 1 validation error detected: Value 'InProgress' at 'statusEquals' failed to satisfy constraint: Member must satisfy enum value set: [STARTING, COMPLETED, STOPPED, INPROGRESS, STOPPING, FAILED]\n",
            "Error listing compilation jobs with status Stopping: An error occurred (ValidationException) when calling the ListCompilationJobs operation: 1 validation error detected: Value 'Stopping' at 'statusEquals' failed to satisfy constraint: Member must satisfy enum value set: [STARTING, COMPLETED, STOPPED, INPROGRESS, STOPPING, FAILED]\n",
            "Error listing edge packaging jobs with status InProgress: An error occurred (ThrottlingException) when calling the ListEdgePackagingJobs operation (reached max retries: 4): Rate exceeded\n",
            "Error listing edge packaging jobs with status Stopping: An error occurred (ThrottlingException) when calling the ListEdgePackagingJobs operation (reached max retries: 4): Rate exceeded\n",
            "Error listing labeling jobs with status InProgress: An error occurred (UnknownOperationException) when calling the ListLabelingJobs operation: The requested operation is not supported in the called region.\n",
            "Error listing labeling jobs with status Stopping: An error occurred (UnknownOperationException) when calling the ListLabelingJobs operation: The requested operation is not supported in the called region.\n",
            "\n",
            "‚úì No running jobs found!\n"
          ]
        }
      ],
      "source": [
        "!python manage_sagemaker_jobs.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3598b6ad",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Estimator configured:\n",
            "  Models ‚Üí s3://amazon-sagemaker-253490779227-us-east-1-cnizlxa57lpnon/animal-classification-convnext-large\n",
            "  Metrics ‚Üí s3://animal-classification-virgina/convnext-large_output\n"
          ]
        }
      ],
      "source": [
        "train_file = \"dss_new_train.py\"\n",
        "\n",
        "# üìÅ Storage Configuration:\n",
        "# - Models (.pth files) ‚Üí output_path (automatically uploaded by SageMaker)\n",
        "# - Metrics (JSON/CSV) ‚Üí output_data_config (training logs and metrics)\n",
        "\n",
        "models = [\"swinb\", \"swinb-test-1\", \"swinb-test-2\", \"swinb-test-3\", \"swinb-test-4\", \"swinb-final\", \"swinb-final-2\", \"swinb-final-3\", \"convnext-large\"]\n",
        "\n",
        "model_output_path = f\"s3://amazon-sagemaker-253490779227-us-east-1-cnizlxa57lpnon/animal-classification-{models[-1]}\"\n",
        "metrics_output_path = f\"s3://animal-classification-virgina/{models[-1]}_output\"\n",
        "\n",
        "estimator_3 = PyTorch(\n",
        "    entry_point=train_file,\n",
        "    dependencies=[\"requirements.txt\"],\n",
        "    role=ROLE_ARN,\n",
        "    framework_version='2.1',\n",
        "    py_version='py310',\n",
        "    output_data_config={\n",
        "        'S3OutputPath': metrics_output_path\n",
        "    },\n",
        "    instance_count=1,\n",
        "    instance_type='ml.g4dn.2xlarge',  \n",
        "    # model_data = model_location,    \n",
        "    hyperparameters={\n",
        "        'epochs': 5,                \n",
        "        'batch-size': 64,            \n",
        "        'learning-rate': 1e-4,       \n",
        "        'use-cuda': True,\n",
        "        \"image-size\": 224,            \n",
        "        \"weight-decay\": 1e-8,   \n",
        "        \"stochastic-depth\": 0.1,      \n",
        "        \"num-cpu\": 4,\n",
        "        \"save-file\": f\"{models[-1]}Weights.pth\"\n",
        "    },\n",
        "    sagemaker_session=sagemaker_session,\n",
        "    base_job_name=models[-1],\n",
        ")\n",
        "\n",
        "print(f\"‚úì Estimator configured:\")\n",
        "print(f\"  Models ‚Üí {model_output_path}\")\n",
        "print(f\"  Metrics ‚Üí {metrics_output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a761ca07",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
            "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
            "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
            "INFO:sagemaker:Creating training-job with name: convnext-large-2026-02-03-18-50-08-651\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-03 18:50:12 Starting - Starting the training job\n",
            "2026-02-03 18:50:12 Pending - Training job waiting for capacity......\n",
            "2026-02-03 18:50:59 Pending - Preparing the instances for training...\n",
            "2026-02-03 18:51:26 Downloading - Downloading input data...\n",
            "2026-02-03 18:51:56 Downloading - Downloading the training image...............\n",
            "2026-02-03 18:54:48 Training - Training image download completed. Training in progress...bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
            "bash: no job control in this shell\n",
            "/opt/conda/lib/python3.10/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
            "  \"cipher\": algorithms.TripleDES,\n",
            "/opt/conda/lib/python3.10/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
            "  \"class\": algorithms.TripleDES,\n",
            "2026-02-03 18:55:06,029 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
            "2026-02-03 18:55:06,050 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
            "2026-02-03 18:55:06,061 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
            "2026-02-03 18:55:06,063 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
            "2026-02-03 18:55:07,766 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt\n",
            "Requirement already satisfied: pandas>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2.2.2)\n",
            "Collecting timm (from -r requirements.txt (line 4))\n",
            "Downloading timm-1.0.24-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas>=2.0.0->-r requirements.txt (line 3)) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=2.0.0->-r requirements.txt (line 3)) (2.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=2.0.0->-r requirements.txt (line 3)) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=2.0.0->-r requirements.txt (line 3)) (2024.1)\n",
            "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from timm->-r requirements.txt (line 4)) (2.1.0)\n",
            "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm->-r requirements.txt (line 4)) (0.16.0)\n",
            "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm->-r requirements.txt (line 4)) (6.0.2)\n",
            "Collecting huggingface_hub (from timm->-r requirements.txt (line 4))\n",
            "Downloading huggingface_hub-1.3.7-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting safetensors (from timm->-r requirements.txt (line 4))\n",
            "Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->-r requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm->-r requirements.txt (line 4)) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm->-r requirements.txt (line 4)) (2024.6.1)\n",
            "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface_hub->timm->-r requirements.txt (line 4))\n",
            "Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from huggingface_hub->timm->-r requirements.txt (line 4))\n",
            "Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm->-r requirements.txt (line 4)) (23.1)\n",
            "Requirement already satisfied: shellingham in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm->-r requirements.txt (line 4)) (1.5.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm->-r requirements.txt (line 4)) (4.66.5)\n",
            "Requirement already satisfied: typer-slim in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm->-r requirements.txt (line 4)) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm->-r requirements.txt (line 4)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->timm->-r requirements.txt (line 4)) (1.13.0)\n",
            "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->timm->-r requirements.txt (line 4)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->timm->-r requirements.txt (line 4)) (3.1.4)\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision->timm->-r requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm->-r requirements.txt (line 4)) (10.3.0)\n",
            "Collecting anyio (from httpx<1,>=0.23.0->huggingface_hub->timm->-r requirements.txt (line 4))\n",
            "Downloading anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm->-r requirements.txt (line 4)) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->huggingface_hub->timm->-r requirements.txt (line 4))\n",
            "Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm->-r requirements.txt (line 4)) (3.7)\n",
            "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub->timm->-r requirements.txt (line 4))\n",
            "Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->timm->-r requirements.txt (line 4)) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->timm->-r requirements.txt (line 4)) (3.2.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->timm->-r requirements.txt (line 4)) (1.26.19)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->timm->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer-slim->huggingface_hub->timm->-r requirements.txt (line 4)) (8.1.7)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->huggingface_hub->timm->-r requirements.txt (line 4)) (1.2.2)\n",
            "Downloading timm-1.0.24-py3-none-any.whl (2.6 MB)\n",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2.6/2.6 MB 88.0 MB/s eta 0:00:00\n",
            "Downloading huggingface_hub-1.3.7-py3-none-any.whl (536 kB)\n",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 536.7/536.7 kB 49.5 MB/s eta 0:00:00\n",
            "Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 507.2/507.2 kB 52.4 MB/s eta 0:00:00\n",
            "Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3.3/3.3 MB 129.9 MB/s eta 0:00:00\n",
            "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 73.5/73.5 kB 11.1 MB/s eta 0:00:00\n",
            "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 78.8/78.8 kB 12.1 MB/s eta 0:00:00\n",
            "Downloading anyio-4.12.1-py3-none-any.whl (113 kB)\n",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 113.6/113.6 kB 16.9 MB/s eta 0:00:00\n",
            "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: safetensors, hf-xet, h11, anyio, httpcore, httpx, huggingface_hub, timm\n",
            "Successfully installed anyio-4.12.1 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface_hub-1.3.7 safetensors-0.7.0 timm-1.0.24\n",
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
            "[notice] A new release of pip is available: 24.1.2 -> 26.0\n",
            "[notice] To update, run: pip install --upgrade pip\n",
            "2026-02-03 18:55:11,240 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
            "2026-02-03 18:55:11,241 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
            "2026-02-03 18:55:11,286 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
            "2026-02-03 18:55:11,319 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
            "2026-02-03 18:55:11,351 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
            "2026-02-03 18:55:11,363 sagemaker-training-toolkit INFO     Invoking user script\n",
            "Training Env:\n",
            "{\n",
            "    \"additional_framework_parameters\": {},\n",
            "    \"channel_input_dirs\": {\n",
            "        \"training\": \"/opt/ml/input/data/training\"\n",
            "    },\n",
            "    \"current_host\": \"algo-1\",\n",
            "    \"current_instance_group\": \"homogeneousCluster\",\n",
            "    \"current_instance_group_hosts\": [\n",
            "        \"algo-1\"\n",
            "    ],\n",
            "    \"current_instance_type\": \"ml.g4dn.2xlarge\",\n",
            "    \"distribution_hosts\": [],\n",
            "    \"distribution_instance_groups\": [],\n",
            "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
            "    \"hosts\": [\n",
            "        \"algo-1\"\n",
            "    ],\n",
            "    \"hyperparameters\": {\n",
            "        \"batch-size\": 32,\n",
            "        \"epochs\": 10,\n",
            "        \"image-size\": 224,\n",
            "        \"learning-rate\": 0.0001,\n",
            "        \"num-cpu\": 4,\n",
            "        \"save-file\": \"convnext-largeWeights.pth\",\n",
            "        \"stochastic-depth\": 0.1,\n",
            "        \"use-cuda\": true,\n",
            "        \"weight-decay\": 1e-08\n",
            "    },\n",
            "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
            "    \"input_data_config\": {\n",
            "        \"training\": {\n",
            "            \"TrainingInputMode\": \"File\",\n",
            "            \"S3DistributionType\": \"FullyReplicated\",\n",
            "            \"RecordWrapperType\": \"None\"\n",
            "        }\n",
            "    },\n",
            "    \"input_dir\": \"/opt/ml/input\",\n",
            "    \"instance_groups\": [\n",
            "        \"homogeneousCluster\"\n",
            "    ],\n",
            "    \"instance_groups_dict\": {\n",
            "        \"homogeneousCluster\": {\n",
            "            \"instance_group_name\": \"homogeneousCluster\",\n",
            "            \"instance_type\": \"ml.g4dn.2xlarge\",\n",
            "            \"hosts\": [\n",
            "                \"algo-1\"\n",
            "            ]\n",
            "        }\n",
            "    },\n",
            "    \"is_hetero\": false,\n",
            "    \"is_master\": true,\n",
            "    \"is_modelparallel_enabled\": null,\n",
            "    \"is_smddpmprun_installed\": false,\n",
            "    \"is_smddprun_installed\": true,\n",
            "    \"job_name\": \"convnext-large-2026-02-03-18-50-08-651\",\n",
            "    \"log_level\": 20,\n",
            "    \"master_hostname\": \"algo-1\",\n",
            "    \"model_dir\": \"/opt/ml/model\",\n",
            "    \"module_dir\": \"s3://sagemaker-us-east-1-253490779227/convnext-large-2026-02-03-18-50-08-651/source/sourcedir.tar.gz\",\n",
            "    \"module_name\": \"dss_new_train\",\n",
            "    \"network_interface_name\": \"eth0\",\n",
            "    \"num_cpus\": 8,\n",
            "    \"num_gpus\": 1,\n",
            "    \"num_neurons\": 0,\n",
            "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
            "    \"output_dir\": \"/opt/ml/output\",\n",
            "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
            "    \"resource_config\": {\n",
            "        \"current_host\": \"algo-1\",\n",
            "        \"current_instance_type\": \"ml.g4dn.2xlarge\",\n",
            "        \"current_group_name\": \"homogeneousCluster\",\n",
            "        \"hosts\": [\n",
            "            \"algo-1\"\n",
            "        ],\n",
            "        \"instance_groups\": [\n",
            "            {\n",
            "                \"instance_group_name\": \"homogeneousCluster\",\n",
            "                \"instance_type\": \"ml.g4dn.2xlarge\",\n",
            "                \"hosts\": [\n",
            "                    \"algo-1\"\n",
            "                ]\n",
            "            }\n",
            "        ],\n",
            "        \"network_interface_name\": \"eth0\",\n",
            "        \"topology\": null\n",
            "    },\n",
            "    \"user_entry_point\": \"dss_new_train.py\"\n",
            "}\n",
            "Environment variables:\n",
            "SM_HOSTS=[\"algo-1\"]\n",
            "SM_NETWORK_INTERFACE_NAME=eth0\n",
            "SM_HPS={\"batch-size\":32,\"epochs\":10,\"image-size\":224,\"learning-rate\":0.0001,\"num-cpu\":4,\"save-file\":\"convnext-largeWeights.pth\",\"stochastic-depth\":0.1,\"use-cuda\":true,\"weight-decay\":1e-08}\n",
            "SM_USER_ENTRY_POINT=dss_new_train.py\n",
            "SM_FRAMEWORK_PARAMS={}\n",
            "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.2xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\n",
            "SM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
            "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
            "SM_CHANNELS=[\"training\"]\n",
            "SM_CURRENT_HOST=algo-1\n",
            "SM_CURRENT_INSTANCE_TYPE=ml.g4dn.2xlarge\n",
            "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
            "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\n",
            "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
            "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.2xlarge\"}}\n",
            "SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
            "SM_IS_HETERO=false\n",
            "SM_MODULE_NAME=dss_new_train\n",
            "SM_LOG_LEVEL=20\n",
            "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
            "SM_INPUT_DIR=/opt/ml/input\n",
            "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
            "SM_OUTPUT_DIR=/opt/ml/output\n",
            "SM_NUM_CPUS=8\n",
            "SM_NUM_GPUS=1\n",
            "SM_NUM_NEURONS=0\n",
            "SM_MODEL_DIR=/opt/ml/model\n",
            "SM_MODULE_DIR=s3://sagemaker-us-east-1-253490779227/convnext-large-2026-02-03-18-50-08-651/source/sourcedir.tar.gz\n",
            "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g4dn.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":32,\"epochs\":10,\"image-size\":224,\"learning-rate\":0.0001,\"num-cpu\":4,\"save-file\":\"convnext-largeWeights.pth\",\"stochastic-depth\":0.1,\"use-cuda\":true,\"weight-decay\":1e-08},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":true,\"job_name\":\"convnext-large-2026-02-03-18-50-08-651\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-253490779227/convnext-large-2026-02-03-18-50-08-651/source/sourcedir.tar.gz\",\"module_name\":\"dss_new_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.2xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"user_entry_point\":\"dss_new_train.py\"}\n",
            "SM_USER_ARGS=[\"--batch-size\",\"32\",\"--epochs\",\"10\",\"--image-size\",\"224\",\"--learning-rate\",\"0.0001\",\"--num-cpu\",\"4\",\"--save-file\",\"convnext-largeWeights.pth\",\"--stochastic-depth\",\"0.1\",\"--use-cuda\",\"True\",\"--weight-decay\",\"1e-08\"]\n",
            "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
            "SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
            "SM_HP_BATCH-SIZE=32\n",
            "SM_HP_EPOCHS=10\n",
            "SM_HP_IMAGE-SIZE=224\n",
            "SM_HP_LEARNING-RATE=0.0001\n",
            "SM_HP_NUM-CPU=4\n",
            "SM_HP_SAVE-FILE=convnext-largeWeights.pth\n",
            "SM_HP_STOCHASTIC-DEPTH=0.1\n",
            "SM_HP_USE-CUDA=true\n",
            "SM_HP_WEIGHT-DECAY=1e-08\n",
            "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\n",
            "Invoking script with the following command:\n",
            "/opt/conda/bin/python3.10 dss_new_train.py --batch-size 32 --epochs 10 --image-size 224 --learning-rate 0.0001 --num-cpu 4 --save-file convnext-largeWeights.pth --stochastic-depth 0.1 --use-cuda True --weight-decay 1e-08\n",
            "2026-02-03 18:55:11,365 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\n",
            "2026-02-03 18:55:11,365 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\n",
            "Starting training...\n",
            "Arguments: Namespace(epochs=10, batch_size=32, learning_rate=0.0001, weight_decay=1e-08, image_size=224, stochastic_depth=0.1, use_cuda=True, num_cpu=4, data_dir='/opt/ml/input/data/training', model_dir='/opt/ml/model', output_dir='/opt/ml/output/data', save_file='convnext-largeWeights.pth')\n",
            "Initial RAM usage: 561.09 MB\n",
            "SM_MODEL_DIR: /opt/ml/model\n",
            "SM_OUTPUT_DATA_DIR: /opt/ml/output/data\n",
            "üìÅ Directory Configuration:\n",
            "   Environment: üöÄ SageMaker\n",
            "   Data directory: /opt/ml/input/data/training\n",
            "   Model directory: /opt/ml/model\n",
            "   Output directory: /opt/ml/output/data\n",
            "Using device: cuda\n",
            "CUDA device: Tesla T4\n",
            "CUDA memory: 14.74 GB\n",
            "Class names: ['antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent']\n",
            "Number of classes: 8\n",
            "Output channels: 3\n",
            "Image size: 224 (optimized for Swin Transformer memory usage)\n",
            "Initial RAM usage: 578.05 MB\n",
            "Initial GPU memory - Allocated: 0.00 MB, Reserved: 0.00 MB\n",
            "Val transform: Compose(\n",
            "    Resize(size=(244, 244), interpolation=bilinear, max_size=None, antialias=warn)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")\n",
            "Base path: /opt/ml/input/data/training\n",
            "Dataframe train:          id  antelope_duiker  bird  ...  leopard  monkey_prosimian  rodent\n",
            "0  ZJ000000              0.0   1.0  ...      0.0               0.0     0.0\n",
            "1  ZJ000001              0.0   0.0  ...      0.0               1.0     0.0\n",
            "2  ZJ000002              0.0   1.0  ...      0.0               0.0     0.0\n",
            "3  ZJ000003              0.0   0.0  ...      0.0               1.0     0.0\n",
            "4  ZJ000004              0.0   0.0  ...      1.0               0.0     0.0\n",
            "[5 rows x 9 columns]\n",
            "After loading CSV RAM usage: 584.89 MB\n",
            "After loading CSV GPU memory - Allocated: 0.00 MB, Reserved: 0.00 MB\n",
            "DataframeLoaded 16488 training samples\n",
            "Dataframe Columns: ['id', 'antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent']\n",
            "Dataframe sample:\n",
            "         id  antelope_duiker  bird  ...  leopard  monkey_prosimian  rodent\n",
            "0  ZJ000000              0.0   1.0  ...      0.0               0.0     0.0\n",
            "1  ZJ000001              0.0   0.0  ...      0.0               1.0     0.0\n",
            "2  ZJ000002              0.0   1.0  ...      0.0               0.0     0.0\n",
            "3  ZJ000003              0.0   0.0  ...      0.0               1.0     0.0\n",
            "4  ZJ000004              0.0   0.0  ...      1.0               0.0     0.0\n",
            "[5 rows x 9 columns]\n",
            "Dataframe shape: (16488, 9)\n",
            "After creating datasets RAM usage: 589.48 MB\n",
            "After creating datasets GPU memory - Allocated: 0.00 MB, Reserved: 0.00 MB\n",
            "Batch size: 32\n",
            "Train batches: 490\n",
            "Val batches: 26\n",
            "convnext_large Model\n",
            "Model head: NormMlpClassifierHead(\n",
            "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
            "  (norm): LayerNorm2d((1536,), eps=1e-06, elementwise_affine=True)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (pre_logits): Identity()\n",
            "  (drop): Dropout(p=0.0, inplace=False)\n",
            "  (fc): Linear(in_features=1536, out_features=8, bias=True)\n",
            ")\n",
            "After moving model to GPU RAM usage: 990.79 MB\n",
            "After moving to GPU - Allocated: 749.49 MB, Reserved: 804.00 MB\n",
            "Optimizer: AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0.01\n",
            ")\n",
            "Criterion: CrossEntropyLoss()\n",
            "Total Epochs: 10\n",
            "Scheduler: <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f6784460550>\n",
            "After loading model RAM usage: 990.79 MB\n",
            "Epoch 1/10\n",
            "Start of epoch GPU memory - Allocated: 749.49 MB, Reserved: 804.00 MB\n",
            "Training...\n",
            "Training:   0%|          | 0/490 [00:00<?, ?it/s]\n",
            "Training:   0%|          | 0/490 [00:03<?, ?it/s, acc=0.0938, loss=2.2789]\n",
            "Training:   0%|          | 1/490 [00:03<25:49,  3.17s/it, acc=0.0938, loss=2.2789]\n",
            "Training:   0%|          | 1/490 [00:05<25:49,  3.17s/it, acc=0.1406, loss=2.1473]\n",
            "Training:   0%|          | 2/490 [00:05<22:14,  2.74s/it, acc=0.1406, loss=2.1473]\n",
            "Training:   0%|          | 2/490 [00:08<22:14,  2.74s/it, acc=0.1667, loss=1.9844]\n",
            "Training:   1%|          | 3/490 [00:08<21:05,  2.60s/it, acc=0.1667, loss=1.9844]\n",
            "Training:   1%|          | 3/490 [00:10<21:05,  2.60s/it, acc=0.1875, loss=1.7753]\n",
            "Training:   1%|          | 4/490 [00:10<20:31,  2.53s/it, acc=0.1875, loss=1.7753]\n",
            "Training:   1%|          | 4/490 [00:12<20:31,  2.53s/it, acc=0.2000, loss=2.1126]\n",
            "Training:   1%|          | 5/490 [00:12<20:12,  2.50s/it, acc=0.2000, loss=2.1126]\n",
            "Training:   1%|          | 5/490 [00:15<20:12,  2.50s/it, acc=0.2031, loss=2.3593]#015Training:   1%|          | 6/490 [00:15<20:00,  2.48s/it, acc=0.2031, loss=2.3593]\n",
            "Training:   1%|          | 6/490 [00:17<20:00,  2.48s/it, acc=0.2098, loss=1.9817]\n",
            "Training:   1%|‚ñè         | 7/490 [00:17<19:53,  2.47s/it, acc=0.2098, loss=1.9817]\n",
            "Training:   1%|‚ñè         | 7/490 [00:20<19:53,  2.47s/it, acc=0.2266, loss=1.8573]\n",
            "Training:   2%|‚ñè         | 8/490 [00:20<19:47,  2.46s/it, acc=0.2266, loss=1.8573]\n",
            "Training:   2%|‚ñè         | 8/490 [00:22<19:47,  2.46s/it, acc=0.2153, loss=2.0659]\n",
            "Training:   2%|‚ñè         | 9/490 [00:22<19:43,  2.46s/it, acc=0.2153, loss=2.0659]\n",
            "Training:   2%|‚ñè         | 9/490 [00:25<19:43,  2.46s/it, acc=0.2281, loss=1.7081]\n",
            "Training:   2%|‚ñè         | 10/490 [00:25<19:41,  2.46s/it, acc=0.2281, loss=1.7081]\n",
            "Training:   2%|‚ñè         | 10/490 [00:27<19:41,  2.46s/it, acc=0.2386, loss=1.6425]\n",
            "Training:   2%|‚ñè         | 11/490 [00:27<19:41,  2.47s/it, acc=0.2386, loss=1.6425]\n",
            "Training:   2%|‚ñè         | 11/490 [00:30<19:41,  2.47s/it, acc=0.2526, loss=1.6183]\n",
            "Training:   2%|‚ñè         | 12/490 [00:30<19:40,  2.47s/it, acc=0.2526, loss=1.6183]\n",
            "Training:   2%|‚ñè         | 12/490 [00:32<19:40,  2.47s/it, acc=0.2620, loss=1.6254]\n",
            "Training:   3%|‚ñé         | 13/490 [00:32<19:37,  2.47s/it, acc=0.2620, loss=1.6254]\n",
            "Training:   3%|‚ñé         | 13/490 [00:35<19:37,  2.47s/it, acc=0.2656, loss=1.6826]\n",
            "Training:   3%|‚ñé         | 14/490 [00:35<19:34,  2.47s/it, acc=0.2656, loss=1.6826]\n",
            "Training:   3%|‚ñé         | 14/490 [00:37<19:34,  2.47s/it, acc=0.2667, loss=1.7989]\n",
            "Training:   3%|‚ñé         | 15/490 [00:37<19:31,  2.47s/it, acc=0.2667, loss=1.7989]\n",
            "Training:   3%|‚ñé         | 15/490 [00:39<19:31,  2.47s/it, acc=0.2812, loss=1.4762]\n",
            "Training:   3%|‚ñé         | 16/490 [00:39<19:29,  2.47s/it, acc=0.2812, loss=1.4762]\n",
            "Training:   3%|‚ñé         | 16/490 [00:42<19:29,  2.47s/it, acc=0.2904, loss=1.5614]\n",
            "Training:   3%|‚ñé         | 17/490 [00:42<19:27,  2.47s/it, acc=0.2904, loss=1.5614]\n",
            "Training:   3%|‚ñé         | 17/490 [00:44<19:27,  2.47s/it, acc=0.3021, loss=1.2401]\n",
            "Training:   4%|‚ñé         | 18/490 [00:44<19:25,  2.47s/it, acc=0.3021, loss=1.2401]\n",
            "Training:   4%|‚ñé         | 18/490 [00:47<19:25,  2.47s/it, acc=0.3059, loss=1.6894]\n",
            "Training:   4%|‚ñç         | 19/490 [00:47<19:23,  2.47s/it, acc=0.3059, loss=1.6894]\n",
            "Training:   4%|‚ñç         | 19/490 [00:49<19:23,  2.47s/it, acc=0.3109, loss=1.6478]\n",
            "Training:   4%|‚ñç         | 20/490 [00:49<19:21,  2.47s/it, acc=0.3109, loss=1.6478]\n",
            "Training:   4%|‚ñç         | 20/490 [00:52<19:21,  2.47s/it, acc=0.3155, loss=1.5680]\n",
            "Training:   4%|‚ñç         | 21/490 [00:52<19:20,  2.48s/it, acc=0.3155, loss=1.5680]\n",
            "Training:   4%|‚ñç         | 21/490 [00:54<19:20,  2.48s/it, acc=0.3281, loss=1.2144]\n",
            "Training:   4%|‚ñç         | 22/490 [00:54<19:18,  2.48s/it, acc=0.3281, loss=1.2144]\n",
            "Training:   4%|‚ñç         | 22/490 [00:57<19:18,  2.48s/it, acc=0.3397, loss=1.2869]\n",
            "Training:   5%|‚ñç         | 23/490 [00:57<19:18,  2.48s/it, acc=0.3397, loss=1.2869]\n",
            "Training:   5%|‚ñç         | 23/490 [00:59<19:18,  2.48s/it, acc=0.3438, loss=1.7121]\n",
            "Training:   5%|‚ñç         | 24/490 [00:59<19:17,  2.48s/it, acc=0.3438, loss=1.7121]\n",
            "Training:   5%|‚ñç         | 24/490 [01:02<19:17,  2.48s/it, acc=0.3450, loss=1.4735]\n",
            "Training:   5%|‚ñå         | 25/490 [01:02<19:16,  2.49s/it, acc=0.3450, loss=1.4735]\n",
            "Training:   5%|‚ñå         | 25/490 [01:04<19:16,  2.49s/it, acc=0.3522, loss=1.4416]\n",
            "Training:   5%|‚ñå         | 26/490 [01:04<19:14,  2.49s/it, acc=0.3522, loss=1.4416]\n",
            "Training:   5%|‚ñå         | 26/490 [01:07<19:14,  2.49s/it, acc=0.3553, loss=1.4460]\n",
            "Training:   6%|‚ñå         | 27/490 [01:07<19:13,  2.49s/it, acc=0.3553, loss=1.4460]\n",
            "Training:   6%|‚ñå         | 27/490 [01:09<19:13,  2.49s/it, acc=0.3594, loss=1.2890]\n",
            "Training:   6%|‚ñå         | 28/490 [01:09<19:10,  2.49s/it, acc=0.3594, loss=1.2890]\n",
            "Training:   6%|‚ñå         | 28/490 [01:12<19:10,  2.49s/it, acc=0.3631, loss=1.3842]\n",
            "Training:   6%|‚ñå         | 29/490 [01:12<19:09,  2.49s/it, acc=0.3631, loss=1.3842]\n",
            "Training:   6%|‚ñå         | 29/490 [01:14<19:09,  2.49s/it, acc=0.3677, loss=1.4881]\n",
            "Training:   6%|‚ñå         | 30/490 [01:14<19:07,  2.49s/it, acc=0.3677, loss=1.4881]\n",
            "Training:   6%|‚ñå         | 30/490 [01:17<19:07,  2.49s/it, acc=0.3679, loss=1.6647]\n",
            "Training:   6%|‚ñã         | 31/490 [01:17<19:05,  2.50s/it, acc=0.3679, loss=1.6647]\n",
            "Training:   6%|‚ñã         | 31/490 [01:19<19:05,  2.50s/it, acc=0.3691, loss=1.4885]\n",
            "Training:   7%|‚ñã         | 32/490 [01:19<19:02,  2.50s/it, acc=0.3691, loss=1.4885]\n",
            "Training:   7%|‚ñã         | 32/490 [01:22<19:02,  2.50s/it, acc=0.3712, loss=1.3956]\n",
            "Training:   7%|‚ñã         | 33/490 [01:22<19:01,  2.50s/it, acc=0.3712, loss=1.3956]\n",
            "Training:   7%|‚ñã         | 33/490 [01:24<19:01,  2.50s/it, acc=0.3796, loss=0.9570]\n",
            "Training:   7%|‚ñã         | 34/490 [01:24<18:59,  2.50s/it, acc=0.3796, loss=0.9570]\n",
            "Training:   7%|‚ñã         | 34/490 [01:27<18:59,  2.50s/it, acc=0.3830, loss=1.4445]\n",
            "Training:   7%|‚ñã         | 35/490 [01:27<18:58,  2.50s/it, acc=0.3830, loss=1.4445]\n",
            "Training:   7%|‚ñã         | 35/490 [01:29<18:58,  2.50s/it, acc=0.3837, loss=1.5006]\n",
            "Training:   7%|‚ñã         | 36/490 [01:29<18:55,  2.50s/it, acc=0.3837, loss=1.5006]\n",
            "Training:   7%|‚ñã         | 36/490 [01:32<18:55,  2.50s/it, acc=0.3843, loss=1.5036]\n",
            "Training:   8%|‚ñä         | 37/490 [01:32<18:53,  2.50s/it, acc=0.3843, loss=1.5036]\n",
            "Training:   8%|‚ñä         | 37/490 [01:34<18:53,  2.50s/it, acc=0.3832, loss=1.4622]\n",
            "Training:   8%|‚ñä         | 38/490 [01:34<18:52,  2.51s/it, acc=0.3832, loss=1.4622]\n",
            "Training:   8%|‚ñä         | 38/490 [01:37<18:52,  2.51s/it, acc=0.3862, loss=1.3133]\n",
            "Training:   8%|‚ñä         | 39/490 [01:37<18:50,  2.51s/it, acc=0.3862, loss=1.3133]\n",
            "Training:   8%|‚ñä         | 39/490 [01:39<18:50,  2.51s/it, acc=0.3867, loss=1.3992]\n",
            "Training:   8%|‚ñä         | 40/490 [01:39<18:48,  2.51s/it, acc=0.3867, loss=1.3992]\n",
            "Training:   8%|‚ñä         | 40/490 [01:42<18:48,  2.51s/it, acc=0.3910, loss=1.1486]\n",
            "Training:   8%|‚ñä         | 41/490 [01:42<18:46,  2.51s/it, acc=0.3910, loss=1.1486]\n",
            "Training:   8%|‚ñä         | 41/490 [01:44<18:46,  2.51s/it, acc=0.3914, loss=1.6595]\n",
            "Training:   9%|‚ñä         | 42/490 [01:44<18:44,  2.51s/it, acc=0.3914, loss=1.6595]\n",
            "Training:   9%|‚ñä         | 42/490 [01:47<18:44,  2.51s/it, acc=0.3983, loss=1.1082]\n",
            "Training:   9%|‚ñâ         | 43/490 [01:47<18:41,  2.51s/it, acc=0.3983, loss=1.1082]\n",
            "Training:   9%|‚ñâ         | 43/490 [01:49<18:41,  2.51s/it, acc=0.4020, loss=1.1028]\n",
            "Training:   9%|‚ñâ         | 44/490 [01:49<18:39,  2.51s/it, acc=0.4020, loss=1.1028]\n",
            "Training:   9%|‚ñâ         | 44/490 [01:52<18:39,  2.51s/it, acc=0.4062, loss=0.9953]\n",
            "Training:   9%|‚ñâ         | 45/490 [01:52<18:37,  2.51s/it, acc=0.4062, loss=0.9953]\n",
            "Training:   9%|‚ñâ         | 45/490 [01:54<18:37,  2.51s/it, acc=0.4090, loss=1.2958]\n",
            "Training:   9%|‚ñâ         | 46/490 [01:54<18:35,  2.51s/it, acc=0.4090, loss=1.2958]\n",
            "Training:   9%|‚ñâ         | 46/490 [01:57<18:35,  2.51s/it, acc=0.4116, loss=1.3917]\n",
            "Training:  10%|‚ñâ         | 47/490 [01:57<18:33,  2.51s/it, acc=0.4116, loss=1.3917]\n",
            "Training:  10%|‚ñâ         | 47/490 [01:59<18:33,  2.51s/it, acc=0.4160, loss=1.1187]#015Training:  10%|‚ñâ         | 48/490 [01:59<18:30,  2.51s/it, acc=0.4160, loss=1.1187]\n",
            "Training:  10%|‚ñâ         | 48/490 [02:02<18:30,  2.51s/it, acc=0.4222, loss=0.8160]\n",
            "Training:  10%|‚ñà         | 49/490 [02:02<18:27,  2.51s/it, acc=0.4222, loss=0.8160]\n",
            "Training:  10%|‚ñà         | 49/490 [02:04<18:27,  2.51s/it, acc=0.4238, loss=1.3039]\n",
            "Training:  10%|‚ñà         | 50/490 [02:04<18:25,  2.51s/it, acc=0.4238, loss=1.3039]\n",
            "Training:  10%|‚ñà         | 50/490 [02:07<18:25,  2.51s/it, acc=0.4271, loss=1.3406]\n",
            "Training:  10%|‚ñà         | 51/490 [02:07<18:23,  2.51s/it, acc=0.4271, loss=1.3406]\n",
            "Training:  10%|‚ñà         | 51/490 [02:10<18:23,  2.51s/it, acc=0.4303, loss=1.0563]\n",
            "Training:  11%|‚ñà         | 52/490 [02:10<18:21,  2.51s/it, acc=0.4303, loss=1.0563]\n",
            "Training:  11%|‚ñà         | 52/490 [02:12<18:21,  2.51s/it, acc=0.4334, loss=1.2233]\n",
            "Training:  11%|‚ñà         | 53/490 [02:12<18:18,  2.51s/it, acc=0.4334, loss=1.2233]\n",
            "Training:  11%|‚ñà         | 53/490 [02:15<18:18,  2.51s/it, acc=0.4352, loss=1.3867]\n",
            "Training:  11%|‚ñà         | 54/490 [02:15<18:17,  2.52s/it, acc=0.4352, loss=1.3867]\n",
            "Training:  11%|‚ñà         | 54/490 [02:17<18:17,  2.52s/it, acc=0.4369, loss=1.3533]\n",
            "Training:  11%|‚ñà         | 55/490 [02:17<18:14,  2.52s/it, acc=0.4369, loss=1.3533]\n",
            "Training:  11%|‚ñà         | 55/490 [02:20<18:14,  2.52s/it, acc=0.4408, loss=1.0214]\n",
            "Training:  11%|‚ñà‚ñè        | 56/490 [02:20<18:11,  2.52s/it, acc=0.4408, loss=1.0214]\n",
            "Training:  11%|‚ñà‚ñè        | 56/490 [02:22<18:11,  2.52s/it, acc=0.4424, loss=1.1860]\n",
            "Training:  12%|‚ñà‚ñè        | 57/490 [02:22<18:09,  2.52s/it, acc=0.4424, loss=1.1860]\n",
            "Training:  12%|‚ñà‚ñè        | 57/490 [02:25<18:09,  2.52s/it, acc=0.4450, loss=1.1330]\n",
            "Training:  12%|‚ñà‚ñè        | 58/490 [02:25<18:07,  2.52s/it, acc=0.4450, loss=1.1330]\n",
            "Training:  12%|‚ñà‚ñè        | 58/490 [02:27<18:07,  2.52s/it, acc=0.4460, loss=1.0899]\n",
            "Training:  12%|‚ñà‚ñè        | 59/490 [02:27<18:05,  2.52s/it, acc=0.4460, loss=1.0899]\n",
            "Training:  12%|‚ñà‚ñè        | 59/490 [02:30<18:05,  2.52s/it, acc=0.4474, loss=1.2507]\n",
            "Training:  12%|‚ñà‚ñè        | 60/490 [02:30<18:02,  2.52s/it, acc=0.4474, loss=1.2507]\n",
            "Training:  12%|‚ñà‚ñè        | 60/490 [02:32<18:02,  2.52s/it, acc=0.4488, loss=1.1623]\n",
            "Training:  12%|‚ñà‚ñè        | 61/490 [02:32<18:00,  2.52s/it, acc=0.4488, loss=1.1623]\n",
            "Training:  12%|‚ñà‚ñè        | 61/490 [02:35<18:00,  2.52s/it, acc=0.4511, loss=1.0775]\n",
            "Training:  13%|‚ñà‚ñé        | 62/490 [02:35<17:58,  2.52s/it, acc=0.4511, loss=1.0775]\n",
            "Training:  13%|‚ñà‚ñé        | 62/490 [02:37<17:58,  2.52s/it, acc=0.4524, loss=1.3096]\n",
            "Training:  13%|‚ñà‚ñé        | 63/490 [02:37<17:55,  2.52s/it, acc=0.4524, loss=1.3096]\n",
            "Training:  13%|‚ñà‚ñé        | 63/490 [02:40<17:55,  2.52s/it, acc=0.4556, loss=1.2142]\n",
            "Training:  13%|‚ñà‚ñé        | 64/490 [02:40<17:53,  2.52s/it, acc=0.4556, loss=1.2142]\n",
            "Training:  13%|‚ñà‚ñé        | 64/490 [02:42<17:53,  2.52s/it, acc=0.4548, loss=1.4156]\n",
            "Training:  13%|‚ñà‚ñé        | 65/490 [02:42<17:50,  2.52s/it, acc=0.4548, loss=1.4156]\n",
            "Training:  13%|‚ñà‚ñé        | 65/490 [02:45<17:50,  2.52s/it, acc=0.4564, loss=1.2861]\n",
            "Training:  13%|‚ñà‚ñé        | 66/490 [02:45<17:48,  2.52s/it, acc=0.4564, loss=1.2861]\n",
            "Training:  13%|‚ñà‚ñé        | 66/490 [02:47<17:48,  2.52s/it, acc=0.4571, loss=1.4946]\n",
            "Training:  14%|‚ñà‚ñé        | 67/490 [02:47<17:45,  2.52s/it, acc=0.4571, loss=1.4946]\n",
            "Training:  14%|‚ñà‚ñé        | 67/490 [02:50<17:45,  2.52s/it, acc=0.4568, loss=1.2683]\n",
            "Training:  14%|‚ñà‚ñç        | 68/490 [02:50<17:43,  2.52s/it, acc=0.4568, loss=1.2683]\n",
            "Training:  14%|‚ñà‚ñç        | 68/490 [02:52<17:43,  2.52s/it, acc=0.4597, loss=1.0675]\n",
            "Training:  14%|‚ñà‚ñç        | 69/490 [02:52<17:40,  2.52s/it, acc=0.4597, loss=1.0675]\n",
            "Training:  14%|‚ñà‚ñç        | 69/490 [02:55<17:40,  2.52s/it, acc=0.4616, loss=1.0509]\n",
            "Training:  14%|‚ñà‚ñç        | 70/490 [02:55<17:39,  2.52s/it, acc=0.4616, loss=1.0509]\n",
            "Training:  14%|‚ñà‚ñç        | 70/490 [02:57<17:39,  2.52s/it, acc=0.4648, loss=0.9202]\n",
            "Training:  14%|‚ñà‚ñç        | 71/490 [02:57<17:36,  2.52s/it, acc=0.4648, loss=0.9202]\n",
            "Training:  14%|‚ñà‚ñç        | 71/490 [03:00<17:36,  2.52s/it, acc=0.4657, loss=1.1611]\n",
            "Training:  15%|‚ñà‚ñç        | 72/490 [03:00<17:34,  2.52s/it, acc=0.4657, loss=1.1611]\n",
            "Training:  15%|‚ñà‚ñç        | 72/490 [03:02<17:34,  2.52s/it, acc=0.4679, loss=1.1858]\n",
            "Training:  15%|‚ñà‚ñç        | 73/490 [03:02<17:31,  2.52s/it, acc=0.4679, loss=1.1858]\n",
            "Training:  15%|‚ñà‚ñç        | 73/490 [03:05<17:31,  2.52s/it, acc=0.4700, loss=1.2231]\n",
            "Training:  15%|‚ñà‚ñå        | 74/490 [03:05<17:28,  2.52s/it, acc=0.4700, loss=1.2231]\n",
            "Training:  15%|‚ñà‚ñå        | 74/490 [03:07<17:28,  2.52s/it, acc=0.4696, loss=1.1821]\n",
            "Training:  15%|‚ñà‚ñå        | 75/490 [03:07<17:25,  2.52s/it, acc=0.4696, loss=1.1821]\n",
            "Training:  15%|‚ñà‚ñå        | 75/490 [03:10<17:25,  2.52s/it, acc=0.4712, loss=1.1038]\n",
            "Training:  16%|‚ñà‚ñå        | 76/490 [03:10<17:23,  2.52s/it, acc=0.4712, loss=1.1038]\n",
            "Training:  16%|‚ñà‚ñå        | 76/490 [03:12<17:23,  2.52s/it, acc=0.4724, loss=1.0957]\n",
            "Training:  16%|‚ñà‚ñå        | 77/490 [03:12<17:20,  2.52s/it, acc=0.4724, loss=1.0957]\n",
            "Training:  16%|‚ñà‚ñå        | 77/490 [03:15<17:20,  2.52s/it, acc=0.4748, loss=1.1170]\n",
            "Training:  16%|‚ñà‚ñå        | 78/490 [03:15<17:18,  2.52s/it, acc=0.4748, loss=1.1170]\n",
            "Training:  16%|‚ñà‚ñå        | 78/490 [03:18<17:18,  2.52s/it, acc=0.4786, loss=0.8622]\n",
            "Training:  16%|‚ñà‚ñå        | 79/490 [03:18<17:16,  2.52s/it, acc=0.4786, loss=0.8622]\n",
            "Training:  16%|‚ñà‚ñå        | 79/490 [03:20<17:16,  2.52s/it, acc=0.4785, loss=1.4070]\n",
            "Training:  16%|‚ñà‚ñã        | 80/490 [03:20<17:14,  2.52s/it, acc=0.4785, loss=1.4070]\n",
            "Training:  16%|‚ñà‚ñã        | 80/490 [03:23<17:14,  2.52s/it, acc=0.4799, loss=1.1057]\n",
            "Training:  17%|‚ñà‚ñã        | 81/490 [03:23<17:11,  2.52s/it, acc=0.4799, loss=1.1057]\n",
            "Training:  17%|‚ñà‚ñã        | 81/490 [03:25<17:11,  2.52s/it, acc=0.4794, loss=1.2832]\n",
            "Training:  17%|‚ñà‚ñã        | 82/490 [03:25<17:08,  2.52s/it, acc=0.4794, loss=1.2832]\n",
            "Training:  17%|‚ñà‚ñã        | 82/490 [03:28<17:08,  2.52s/it, acc=0.4812, loss=1.0579]\n",
            "Training:  17%|‚ñà‚ñã        | 83/490 [03:28<17:06,  2.52s/it, acc=0.4812, loss=1.0579]\n",
            "Training:  17%|‚ñà‚ñã        | 83/490 [03:30<17:06,  2.52s/it, acc=0.4833, loss=0.8911]\n",
            "Training:  17%|‚ñà‚ñã        | 84/490 [03:30<17:04,  2.52s/it, acc=0.4833, loss=0.8911]\n",
            "Training:  17%|‚ñà‚ñã        | 84/490 [03:33<17:04,  2.52s/it, acc=0.4853, loss=1.0208]\n",
            "Training:  17%|‚ñà‚ñã        | 85/490 [03:33<17:01,  2.52s/it, acc=0.4853, loss=1.0208]\n",
            "Training:  17%|‚ñà‚ñã        | 85/490 [03:35<17:01,  2.52s/it, acc=0.4876, loss=0.8329]\n",
            "Training:  18%|‚ñà‚ñä        | 86/490 [03:35<16:58,  2.52s/it, acc=0.4876, loss=0.8329]\n",
            "Training:  18%|‚ñà‚ñä        | 86/490 [03:38<16:58,  2.52s/it, acc=0.4889, loss=1.2429]\n",
            "Training:  18%|‚ñà‚ñä        | 87/490 [03:38<16:56,  2.52s/it, acc=0.4889, loss=1.2429]\n",
            "Training:  18%|‚ñà‚ñä        | 87/490 [03:40<16:56,  2.52s/it, acc=0.4890, loss=1.4982]\n",
            "Training:  18%|‚ñà‚ñä        | 88/490 [03:40<16:53,  2.52s/it, acc=0.4890, loss=1.4982]\n",
            "Training:  18%|‚ñà‚ñä        | 88/490 [03:43<16:53,  2.52s/it, acc=0.4895, loss=1.1805]\n",
            "Training:  18%|‚ñà‚ñä        | 89/490 [03:43<16:50,  2.52s/it, acc=0.4895, loss=1.1805]\n",
            "Training:  18%|‚ñà‚ñä        | 89/490 [03:45<16:50,  2.52s/it, acc=0.4920, loss=0.8667]\n",
            "Training:  18%|‚ñà‚ñä        | 90/490 [03:45<16:48,  2.52s/it, acc=0.4920, loss=0.8667]\n",
            "Training:  18%|‚ñà‚ñä        | 90/490 [03:48<16:48,  2.52s/it, acc=0.4948, loss=0.7649]\n",
            "Training:  19%|‚ñà‚ñä        | 91/490 [03:48<16:45,  2.52s/it, acc=0.4948, loss=0.7649]\n",
            "Training:  19%|‚ñà‚ñä        | 91/490 [03:50<16:45,  2.52s/it, acc=0.4952, loss=1.2570]\n",
            "Training:  19%|‚ñà‚ñâ        | 92/490 [03:50<16:43,  2.52s/it, acc=0.4952, loss=1.2570]\n",
            "Training:  19%|‚ñà‚ñâ        | 92/490 [03:53<16:43,  2.52s/it, acc=0.4966, loss=1.0152]\n",
            "Training:  19%|‚ñà‚ñâ        | 93/490 [03:53<16:40,  2.52s/it, acc=0.4966, loss=1.0152]\n",
            "Training:  19%|‚ñà‚ñâ        | 93/490 [03:55<16:40,  2.52s/it, acc=0.4970, loss=1.2692]\n",
            "Training:  19%|‚ñà‚ñâ        | 94/490 [03:55<16:37,  2.52s/it, acc=0.4970, loss=1.2692]\n",
            "Training:  19%|‚ñà‚ñâ        | 94/490 [03:58<16:37,  2.52s/it, acc=0.4984, loss=0.7515]\n",
            "Training:  19%|‚ñà‚ñâ        | 95/490 [03:58<16:36,  2.52s/it, acc=0.4984, loss=0.7515]\n",
            "Training:  19%|‚ñà‚ñâ        | 95/490 [04:00<16:36,  2.52s/it, acc=0.5000, loss=0.8769]\n",
            "Training:  20%|‚ñà‚ñâ        | 96/490 [04:00<16:34,  2.52s/it, acc=0.5000, loss=0.8769]\n",
            "Training:  20%|‚ñà‚ñâ        | 96/490 [04:03<16:34,  2.52s/it, acc=0.5000, loss=1.3412]\n",
            "Training:  20%|‚ñà‚ñâ        | 97/490 [04:03<16:31,  2.52s/it, acc=0.5000, loss=1.3412]\n",
            "Training:  20%|‚ñà‚ñâ        | 97/490 [04:05<16:31,  2.52s/it, acc=0.5013, loss=1.0628]\n",
            "Training:  20%|‚ñà‚ñà        | 98/490 [04:05<16:28,  2.52s/it, acc=0.5013, loss=1.0628]\n",
            "Training:  20%|‚ñà‚ñà        | 98/490 [04:08<16:28,  2.52s/it, acc=0.5019, loss=1.2265]\n",
            "Training:  20%|‚ñà‚ñà        | 99/490 [04:08<16:25,  2.52s/it, acc=0.5019, loss=1.2265]\n",
            "Training:  20%|‚ñà‚ñà        | 99/490 [04:10<16:25,  2.52s/it, acc=0.5022, loss=1.1120]\n",
            "Training:  20%|‚ñà‚ñà        | 100/490 [04:10<16:22,  2.52s/it, acc=0.5022, loss=1.1120]\n",
            "Training:  20%|‚ñà‚ñà        | 100/490 [04:13<16:22,  2.52s/it, acc=0.5040, loss=0.9372]\n",
            "Training:  21%|‚ñà‚ñà        | 101/490 [04:13<16:20,  2.52s/it, acc=0.5040, loss=0.9372]\n",
            "Training:  21%|‚ñà‚ñà        | 101/490 [04:16<16:20,  2.52s/it, acc=0.5043, loss=1.1594]\n",
            "Training:  21%|‚ñà‚ñà        | 102/490 [04:16<16:17,  2.52s/it, acc=0.5043, loss=1.1594]\n",
            "Training:  21%|‚ñà‚ñà        | 102/490 [04:18<16:17,  2.52s/it, acc=0.5046, loss=1.4019]\n",
            "Training:  21%|‚ñà‚ñà        | 103/490 [04:18<16:14,  2.52s/it, acc=0.5046, loss=1.4019]\n",
            "Training:  21%|‚ñà‚ñà        | 103/490 [04:21<16:14,  2.52s/it, acc=0.5036, loss=1.3840]\n",
            "Training:  21%|‚ñà‚ñà        | 104/490 [04:21<16:12,  2.52s/it, acc=0.5036, loss=1.3840]\n",
            "Training:  21%|‚ñà‚ñà        | 104/490 [04:23<16:12,  2.52s/it, acc=0.5054, loss=0.9328]\n",
            "Training:  21%|‚ñà‚ñà‚ñè       | 105/490 [04:23<16:09,  2.52s/it, acc=0.5054, loss=0.9328]\n",
            "Training:  21%|‚ñà‚ñà‚ñè       | 105/490 [04:26<16:09,  2.52s/it, acc=0.5059, loss=1.1456]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 106/490 [04:26<16:07,  2.52s/it, acc=0.5059, loss=1.1456]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 106/490 [04:28<16:07,  2.52s/it, acc=0.5085, loss=0.7514]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 107/490 [04:28<16:04,  2.52s/it, acc=0.5085, loss=0.7514]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 107/490 [04:31<16:04,  2.52s/it, acc=0.5090, loss=1.0964]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 108/490 [04:31<16:02,  2.52s/it, acc=0.5090, loss=1.0964]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 108/490 [04:33<16:02,  2.52s/it, acc=0.5103, loss=0.9365]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 109/490 [04:33<16:00,  2.52s/it, acc=0.5103, loss=0.9365]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 109/490 [04:36<16:00,  2.52s/it, acc=0.5111, loss=0.9311]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 110/490 [04:36<15:58,  2.52s/it, acc=0.5111, loss=0.9311]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 110/490 [04:38<15:58,  2.52s/it, acc=0.5121, loss=0.9899]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 111/490 [04:38<15:55,  2.52s/it, acc=0.5121, loss=0.9899]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 111/490 [04:41<15:55,  2.52s/it, acc=0.5140, loss=0.8734]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 112/490 [04:41<15:54,  2.52s/it, acc=0.5140, loss=0.8734]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 112/490 [04:43<15:54,  2.52s/it, acc=0.5127, loss=1.6488]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 113/490 [04:43<15:51,  2.52s/it, acc=0.5127, loss=1.6488]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 113/490 [04:46<15:51,  2.52s/it, acc=0.5121, loss=1.3331]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 114/490 [04:46<15:49,  2.52s/it, acc=0.5121, loss=1.3331]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 114/490 [04:48<15:49,  2.52s/it, acc=0.5125, loss=1.1679]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 115/490 [04:48<15:45,  2.52s/it, acc=0.5125, loss=1.1679]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 115/490 [04:51<15:45,  2.52s/it, acc=0.5132, loss=1.2852]\n",
            "Training:  24%|‚ñà‚ñà‚ñé       | 116/490 [04:51<15:43,  2.52s/it, acc=0.5132, loss=1.2852]\n",
            "Training:  24%|‚ñà‚ñà‚ñé       | 116/490 [04:53<15:43,  2.52s/it, acc=0.5147, loss=0.8781]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 117/490 [04:53<15:40,  2.52s/it, acc=0.5147, loss=0.8781]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 117/490 [04:56<15:40,  2.52s/it, acc=0.5159, loss=0.9726]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 118/490 [04:56<15:37,  2.52s/it, acc=0.5159, loss=0.9726]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 118/490 [04:58<15:37,  2.52s/it, acc=0.5168, loss=1.0280]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 119/490 [04:58<15:34,  2.52s/it, acc=0.5168, loss=1.0280]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 119/490 [05:01<15:34,  2.52s/it, acc=0.5180, loss=0.8372]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 120/490 [05:01<15:32,  2.52s/it, acc=0.5180, loss=0.8372]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 120/490 [05:03<15:32,  2.52s/it, acc=0.5196, loss=0.8695]\n",
            "Training:  25%|‚ñà‚ñà‚ñç       | 121/490 [05:03<15:29,  2.52s/it, acc=0.5196, loss=0.8695]\n",
            "Training:  25%|‚ñà‚ñà‚ñç       | 121/490 [05:06<15:29,  2.52s/it, acc=0.5202, loss=1.0942]\n",
            "Training:  25%|‚ñà‚ñà‚ñç       | 122/490 [05:06<15:27,  2.52s/it, acc=0.5202, loss=1.0942]\n",
            "Training:  25%|‚ñà‚ñà‚ñç       | 122/490 [05:08<15:27,  2.52s/it, acc=0.5206, loss=1.0623]\n",
            "Training:  25%|‚ñà‚ñà‚ñå       | 123/490 [05:08<15:24,  2.52s/it, acc=0.5206, loss=1.0623]\n",
            "Training:  25%|‚ñà‚ñà‚ñå       | 123/490 [05:11<15:24,  2.52s/it, acc=0.5212, loss=0.9336]\n",
            "Training:  25%|‚ñà‚ñà‚ñå       | 124/490 [05:11<15:22,  2.52s/it, acc=0.5212, loss=0.9336]\n",
            "Training:  25%|‚ñà‚ñà‚ñå       | 124/490 [05:14<15:22,  2.52s/it, acc=0.5215, loss=1.0746]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 125/490 [05:14<15:20,  2.52s/it, acc=0.5215, loss=1.0746]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 125/490 [05:16<15:20,  2.52s/it, acc=0.5223, loss=1.0504]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 126/490 [05:16<15:17,  2.52s/it, acc=0.5223, loss=1.0504]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 126/490 [05:19<15:17,  2.52s/it, acc=0.5239, loss=0.8239]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 127/490 [05:19<15:14,  2.52s/it, acc=0.5239, loss=0.8239]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 127/490 [05:21<15:14,  2.52s/it, acc=0.5244, loss=1.0963]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 128/490 [05:21<15:12,  2.52s/it, acc=0.5244, loss=1.0963]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 128/490 [05:24<15:12,  2.52s/it, acc=0.5252, loss=1.0372]\n",
            "Training:  26%|‚ñà‚ñà‚ñã       | 129/490 [05:24<15:09,  2.52s/it, acc=0.5252, loss=1.0372]\n",
            "Training:  26%|‚ñà‚ñà‚ñã       | 129/490 [05:26<15:09,  2.52s/it, acc=0.5260, loss=1.0278]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 130/490 [05:26<15:07,  2.52s/it, acc=0.5260, loss=1.0278]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 130/490 [05:29<15:07,  2.52s/it, acc=0.5279, loss=0.7360]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 131/490 [05:29<15:04,  2.52s/it, acc=0.5279, loss=0.7360]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 131/490 [05:31<15:04,  2.52s/it, acc=0.5289, loss=1.0098]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 132/490 [05:31<15:02,  2.52s/it, acc=0.5289, loss=1.0098]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 132/490 [05:34<15:02,  2.52s/it, acc=0.5298, loss=0.9333]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 133/490 [05:34<14:59,  2.52s/it, acc=0.5298, loss=0.9333]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 133/490 [05:36<14:59,  2.52s/it, acc=0.5303, loss=1.0352]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 134/490 [05:36<14:57,  2.52s/it, acc=0.5303, loss=1.0352]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 134/490 [05:39<14:57,  2.52s/it, acc=0.5308, loss=1.2261]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 135/490 [05:39<14:55,  2.52s/it, acc=0.5308, loss=1.2261]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 135/490 [05:41<14:55,  2.52s/it, acc=0.5319, loss=0.9342]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 136/490 [05:41<14:52,  2.52s/it, acc=0.5319, loss=0.9342]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 136/490 [05:44<14:52,  2.52s/it, acc=0.5331, loss=0.7649]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 137/490 [05:44<14:50,  2.52s/it, acc=0.5331, loss=0.7649]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 137/490 [05:46<14:50,  2.52s/it, acc=0.5346, loss=0.8706]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 138/490 [05:46<14:48,  2.52s/it, acc=0.5346, loss=0.8706]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 138/490 [05:49<14:48,  2.52s/it, acc=0.5355, loss=0.9657]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 139/490 [05:49<14:45,  2.52s/it, acc=0.5355, loss=0.9657]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 139/490 [05:51<14:45,  2.52s/it, acc=0.5362, loss=1.0897]\n",
            "Training:  29%|‚ñà‚ñà‚ñä       | 140/490 [05:51<14:43,  2.52s/it, acc=0.5362, loss=1.0897]\n",
            "Training:  29%|‚ñà‚ñà‚ñä       | 140/490 [05:54<14:43,  2.52s/it, acc=0.5368, loss=0.9578]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 141/490 [05:54<14:40,  2.52s/it, acc=0.5368, loss=0.9578]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 141/490 [05:56<14:40,  2.52s/it, acc=0.5374, loss=1.1110]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 142/490 [05:56<14:38,  2.53s/it, acc=0.5374, loss=1.1110]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 142/490 [05:59<14:38,  2.53s/it, acc=0.5387, loss=0.7739]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 143/490 [05:59<14:35,  2.52s/it, acc=0.5387, loss=0.7739]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 143/490 [06:01<14:35,  2.52s/it, acc=0.5384, loss=1.4353]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 144/490 [06:01<14:33,  2.52s/it, acc=0.5384, loss=1.4353]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 144/490 [06:04<14:33,  2.52s/it, acc=0.5394, loss=0.8141]\n",
            "Training:  30%|‚ñà‚ñà‚ñâ       | 145/490 [06:04<14:31,  2.53s/it, acc=0.5394, loss=0.8141]\n",
            "Training:  30%|‚ñà‚ñà‚ñâ       | 145/490 [06:06<14:31,  2.53s/it, acc=0.5402, loss=0.8850]\n",
            "Training:  30%|‚ñà‚ñà‚ñâ       | 146/490 [06:06<14:28,  2.53s/it, acc=0.5402, loss=0.8850]\n",
            "Training:  30%|‚ñà‚ñà‚ñâ       | 146/490 [06:09<14:28,  2.53s/it, acc=0.5412, loss=1.0022]\n",
            "Training:  30%|‚ñà‚ñà‚ñà       | 147/490 [06:09<14:26,  2.53s/it, acc=0.5412, loss=1.0022]\n",
            "Training:  30%|‚ñà‚ñà‚ñà       | 147/490 [06:12<14:26,  2.53s/it, acc=0.5420, loss=0.7942]\n",
            "Training:  30%|‚ñà‚ñà‚ñà       | 148/490 [06:12<14:23,  2.52s/it, acc=0.5420, loss=0.7942]\n",
            "Training:  30%|‚ñà‚ñà‚ñà       | 148/490 [06:14<14:23,  2.52s/it, acc=0.5440, loss=0.6106]\n",
            "Training:  30%|‚ñà‚ñà‚ñà       | 149/490 [06:14<14:20,  2.52s/it, acc=0.5440, loss=0.6106]\n",
            "Training:  30%|‚ñà‚ñà‚ñà       | 149/490 [06:17<14:20,  2.52s/it, acc=0.5440, loss=1.0362]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 150/490 [06:17<14:17,  2.52s/it, acc=0.5440, loss=1.0362]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 150/490 [06:19<14:17,  2.52s/it, acc=0.5445, loss=0.8275]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 151/490 [06:19<14:15,  2.52s/it, acc=0.5445, loss=0.8275]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 151/490 [06:22<14:15,  2.52s/it, acc=0.5458, loss=0.7600]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 152/490 [06:22<14:13,  2.52s/it, acc=0.5458, loss=0.7600]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 152/490 [06:24<14:13,  2.52s/it, acc=0.5455, loss=1.4176]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 153/490 [06:24<14:11,  2.53s/it, acc=0.5455, loss=1.4176]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 153/490 [06:27<14:11,  2.53s/it, acc=0.5463, loss=1.1806]\n",
            "Training:  31%|‚ñà‚ñà‚ñà‚ñè      | 154/490 [06:27<14:07,  2.52s/it, acc=0.5463, loss=1.1806]\n",
            "Training:  31%|‚ñà‚ñà‚ñà‚ñè      | 154/490 [06:29<14:07,  2.52s/it, acc=0.5470, loss=1.0472]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 155/490 [06:29<14:05,  2.52s/it, acc=0.5470, loss=1.0472]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 155/490 [06:32<14:05,  2.52s/it, acc=0.5479, loss=0.8957]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 156/490 [06:32<14:03,  2.52s/it, acc=0.5479, loss=0.8957]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 156/490 [06:34<14:03,  2.52s/it, acc=0.5488, loss=0.8106]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 157/490 [06:34<14:00,  2.52s/it, acc=0.5488, loss=0.8106]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 157/490 [06:37<14:00,  2.52s/it, acc=0.5492, loss=0.9599]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 158/490 [06:37<13:58,  2.52s/it, acc=0.5492, loss=0.9599]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 158/490 [06:39<13:58,  2.52s/it, acc=0.5499, loss=0.7345]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 159/490 [06:39<13:55,  2.52s/it, acc=0.5499, loss=0.7345]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 159/490 [06:42<13:55,  2.52s/it, acc=0.5504, loss=0.8800]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 160/490 [06:42<13:53,  2.53s/it, acc=0.5504, loss=0.8800]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 160/490 [06:44<13:53,  2.53s/it, acc=0.5509, loss=0.8399]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 161/490 [06:44<13:50,  2.52s/it, acc=0.5509, loss=0.8399]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 161/490 [06:47<13:50,  2.52s/it, acc=0.5519, loss=0.8516]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 162/490 [06:47<13:48,  2.53s/it, acc=0.5519, loss=0.8516]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 162/490 [06:49<13:48,  2.53s/it, acc=0.5523, loss=0.8592]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 163/490 [06:49<13:45,  2.52s/it, acc=0.5523, loss=0.8592]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 163/490 [06:52<13:45,  2.52s/it, acc=0.5535, loss=0.8578]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 164/490 [06:52<13:42,  2.52s/it, acc=0.5535, loss=0.8578]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 164/490 [06:54<13:42,  2.52s/it, acc=0.5545, loss=0.7191]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñé      | 165/490 [06:54<13:40,  2.53s/it, acc=0.5545, loss=0.7191]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñé      | 165/490 [06:57<13:40,  2.53s/it, acc=0.5555, loss=0.6796]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 166/490 [06:57<13:38,  2.53s/it, acc=0.5555, loss=0.6796]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 166/490 [07:00<13:38,  2.53s/it, acc=0.5556, loss=1.2103]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 167/490 [07:00<13:36,  2.53s/it, acc=0.5556, loss=1.2103]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 167/490 [07:02<13:36,  2.53s/it, acc=0.5556, loss=1.0989]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 168/490 [07:02<13:33,  2.53s/it, acc=0.5556, loss=1.0989]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 168/490 [07:05<13:33,  2.53s/it, acc=0.5564, loss=0.7938]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 169/490 [07:05<13:31,  2.53s/it, acc=0.5564, loss=0.7938]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 169/490 [07:07<13:31,  2.53s/it, acc=0.5577, loss=0.5844]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñç      | 170/490 [07:07<13:28,  2.53s/it, acc=0.5577, loss=0.5844]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñç      | 170/490 [07:10<13:28,  2.53s/it, acc=0.5577, loss=1.2202]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñç      | 171/490 [07:10<13:25,  2.53s/it, acc=0.5577, loss=1.2202]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñç      | 171/490 [07:12<13:25,  2.53s/it, acc=0.5587, loss=0.6669]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñå      | 172/490 [07:12<13:23,  2.53s/it, acc=0.5587, loss=0.6669]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñå      | 172/490 [07:15<13:23,  2.53s/it, acc=0.5602, loss=0.8133]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñå      | 173/490 [07:15<13:20,  2.53s/it, acc=0.5602, loss=0.8133]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñå      | 173/490 [07:17<13:20,  2.53s/it, acc=0.5609, loss=0.8684]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 174/490 [07:17<13:18,  2.53s/it, acc=0.5609, loss=0.8684]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 174/490 [07:20<13:18,  2.53s/it, acc=0.5614, loss=0.9057]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 175/490 [07:20<13:16,  2.53s/it, acc=0.5614, loss=0.9057]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 175/490 [07:22<13:16,  2.53s/it, acc=0.5620, loss=1.0968]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 176/490 [07:22<13:12,  2.53s/it, acc=0.5620, loss=1.0968]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 176/490 [07:25<13:12,  2.53s/it, acc=0.5629, loss=0.7298]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 177/490 [07:25<13:10,  2.52s/it, acc=0.5629, loss=0.7298]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 177/490 [07:27<13:10,  2.52s/it, acc=0.5644, loss=0.5248]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñã      | 178/490 [07:27<13:08,  2.53s/it, acc=0.5644, loss=0.5248]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñã      | 178/490 [07:30<13:08,  2.53s/it, acc=0.5655, loss=0.8489]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 179/490 [07:30<13:05,  2.53s/it, acc=0.5655, loss=0.8489]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 179/490 [07:32<13:05,  2.53s/it, acc=0.5660, loss=0.9060]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 180/490 [07:32<13:03,  2.53s/it, acc=0.5660, loss=0.9060]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 180/490 [07:35<13:03,  2.53s/it, acc=0.5679, loss=0.4700]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 181/490 [07:35<13:00,  2.53s/it, acc=0.5679, loss=0.4700]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 181/490 [07:37<13:00,  2.53s/it, acc=0.5682, loss=0.9543]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 182/490 [07:37<13:03,  2.55s/it, acc=0.5682, loss=0.9543]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 182/490 [07:40<13:03,  2.55s/it, acc=0.5693, loss=0.6644]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 183/490 [07:40<12:59,  2.54s/it, acc=0.5693, loss=0.6644]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 183/490 [07:43<12:59,  2.54s/it, acc=0.5700, loss=1.1603]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 184/490 [07:43<12:56,  2.54s/it, acc=0.5700, loss=1.1603]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 184/490 [07:45<12:56,  2.54s/it, acc=0.5713, loss=0.6365]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 185/490 [07:45<12:52,  2.53s/it, acc=0.5713, loss=0.6365]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 185/490 [07:48<12:52,  2.53s/it, acc=0.5721, loss=0.8307]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 186/490 [07:48<12:48,  2.53s/it, acc=0.5721, loss=0.8307]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 186/490 [07:50<12:48,  2.53s/it, acc=0.5732, loss=0.7335]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 187/490 [07:50<12:46,  2.53s/it, acc=0.5732, loss=0.7335]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 187/490 [07:53<12:46,  2.53s/it, acc=0.5740, loss=1.0992]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 188/490 [07:53<12:43,  2.53s/it, acc=0.5740, loss=1.0992]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 188/490 [07:55<12:43,  2.53s/it, acc=0.5747, loss=0.6720]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñä      | 189/490 [07:55<12:40,  2.53s/it, acc=0.5747, loss=0.6720]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñä      | 189/490 [07:58<12:40,  2.53s/it, acc=0.5758, loss=0.5362]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 190/490 [07:58<12:37,  2.53s/it, acc=0.5758, loss=0.5362]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 190/490 [08:00<12:37,  2.53s/it, acc=0.5764, loss=0.8394]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 191/490 [08:00<12:34,  2.52s/it, acc=0.5764, loss=0.8394]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 191/490 [08:03<12:34,  2.52s/it, acc=0.5775, loss=0.6233]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 192/490 [08:03<12:32,  2.53s/it, acc=0.5775, loss=0.6233]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 192/490 [08:05<12:32,  2.53s/it, acc=0.5785, loss=0.7232]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 193/490 [08:05<12:30,  2.53s/it, acc=0.5785, loss=0.7232]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 193/490 [08:08<12:30,  2.53s/it, acc=0.5788, loss=1.0083]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñâ      | 194/490 [08:08<12:27,  2.53s/it, acc=0.5788, loss=1.0083]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñâ      | 194/490 [08:10<12:27,  2.53s/it, acc=0.5795, loss=0.9087]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñâ      | 195/490 [08:10<12:25,  2.53s/it, acc=0.5795, loss=0.9087]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñâ      | 195/490 [08:13<12:25,  2.53s/it, acc=0.5808, loss=0.5116]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñà      | 196/490 [08:13<12:22,  2.53s/it, acc=0.5808, loss=0.5116]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñà      | 196/490 [08:15<12:22,  2.53s/it, acc=0.5815, loss=0.8479]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñà      | 197/490 [08:15<12:19,  2.52s/it, acc=0.5815, loss=0.8479]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñà      | 197/490 [08:18<12:19,  2.52s/it, acc=0.5822, loss=0.7558]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñà      | 198/490 [08:18<12:17,  2.52s/it, acc=0.5822, loss=0.7558]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñà      | 198/490 [08:20<12:17,  2.52s/it, acc=0.5831, loss=0.7191]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 199/490 [08:20<12:14,  2.53s/it, acc=0.5831, loss=0.7191]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 199/490 [08:23<12:14,  2.53s/it, acc=0.5845, loss=0.6507]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 200/490 [08:23<12:11,  2.52s/it, acc=0.5845, loss=0.6507]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 200/490 [08:25<12:11,  2.52s/it, acc=0.5849, loss=1.0537]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 201/490 [08:25<12:09,  2.52s/it, acc=0.5849, loss=1.0537]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 201/490 [08:28<12:09,  2.52s/it, acc=0.5849, loss=0.9104]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 202/490 [08:28<12:06,  2.52s/it, acc=0.5849, loss=0.9104]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 202/490 [08:30<12:06,  2.52s/it, acc=0.5848, loss=1.0965]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 203/490 [08:30<12:03,  2.52s/it, acc=0.5848, loss=1.0965]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 203/490 [08:33<12:03,  2.52s/it, acc=0.5853, loss=0.8207]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 204/490 [08:33<12:01,  2.52s/it, acc=0.5853, loss=0.8207]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 204/490 [08:36<12:01,  2.52s/it, acc=0.5852, loss=1.2559]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 205/490 [08:36<11:59,  2.52s/it, acc=0.5852, loss=1.2559]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 205/490 [08:38<11:59,  2.52s/it, acc=0.5857, loss=0.8745]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 206/490 [08:38<11:56,  2.52s/it, acc=0.5857, loss=0.8745]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 206/490 [08:41<11:56,  2.52s/it, acc=0.5870, loss=0.6681]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 207/490 [08:41<11:54,  2.52s/it, acc=0.5870, loss=0.6681]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 207/490 [08:43<11:54,  2.52s/it, acc=0.5879, loss=0.5719]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 208/490 [08:43<11:51,  2.52s/it, acc=0.5879, loss=0.5719]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 208/490 [08:46<11:51,  2.52s/it, acc=0.5891, loss=0.5468]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 209/490 [08:46<11:49,  2.53s/it, acc=0.5891, loss=0.5468]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 209/490 [08:48<11:49,  2.53s/it, acc=0.5896, loss=0.9719]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 210/490 [08:48<11:46,  2.52s/it, acc=0.5896, loss=0.9719]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 210/490 [08:51<11:46,  2.52s/it, acc=0.5899, loss=1.0763]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 211/490 [08:51<11:43,  2.52s/it, acc=0.5899, loss=1.0763]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 211/490 [08:53<11:43,  2.52s/it, acc=0.5905, loss=0.9076]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 212/490 [08:53<11:40,  2.52s/it, acc=0.5905, loss=0.9076]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 212/490 [08:56<11:40,  2.52s/it, acc=0.5917, loss=0.6181]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 213/490 [08:56<11:38,  2.52s/it, acc=0.5917, loss=0.6181]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 213/490 [08:58<11:38,  2.52s/it, acc=0.5920, loss=1.1278]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 214/490 [08:58<11:36,  2.52s/it, acc=0.5920, loss=1.1278]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 214/490 [09:01<11:36,  2.52s/it, acc=0.5932, loss=0.4931]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 215/490 [09:01<11:34,  2.53s/it, acc=0.5932, loss=0.4931]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 215/490 [09:03<11:34,  2.53s/it, acc=0.5935, loss=0.8453]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 216/490 [09:03<11:31,  2.52s/it, acc=0.5935, loss=0.8453]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 216/490 [09:06<11:31,  2.52s/it, acc=0.5935, loss=0.9351]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 217/490 [09:06<11:29,  2.52s/it, acc=0.5935, loss=0.9351]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 217/490 [09:08<11:29,  2.52s/it, acc=0.5948, loss=0.4834]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 218/490 [09:08<11:25,  2.52s/it, acc=0.5948, loss=0.4834]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 218/490 [09:11<11:25,  2.52s/it, acc=0.5949, loss=1.0396]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 219/490 [09:11<11:23,  2.52s/it, acc=0.5949, loss=1.0396]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 219/490 [09:13<11:23,  2.52s/it, acc=0.5952, loss=0.9612]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 220/490 [09:13<11:20,  2.52s/it, acc=0.5952, loss=0.9612]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 220/490 [09:16<11:20,  2.52s/it, acc=0.5962, loss=0.6163]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 221/490 [09:16<11:18,  2.52s/it, acc=0.5962, loss=0.6163]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 221/490 [09:18<11:18,  2.52s/it, acc=0.5963, loss=0.9663]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 222/490 [09:18<11:15,  2.52s/it, acc=0.5963, loss=0.9663]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 222/490 [09:21<11:15,  2.52s/it, acc=0.5966, loss=0.9464]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 223/490 [09:21<11:13,  2.52s/it, acc=0.5966, loss=0.9464]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 223/490 [09:23<11:13,  2.52s/it, acc=0.5974, loss=0.7120]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 224/490 [09:23<11:11,  2.52s/it, acc=0.5974, loss=0.7120]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 224/490 [09:26<11:11,  2.52s/it, acc=0.5978, loss=0.8770]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 225/490 [09:26<11:08,  2.52s/it, acc=0.5978, loss=0.8770]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 225/490 [09:29<11:08,  2.52s/it, acc=0.5987, loss=0.5533]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 226/490 [09:29<11:05,  2.52s/it, acc=0.5987, loss=0.5533]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 226/490 [09:31<11:05,  2.52s/it, acc=0.5993, loss=0.8144]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 227/490 [09:31<11:02,  2.52s/it, acc=0.5993, loss=0.8144]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 227/490 [09:34<11:02,  2.52s/it, acc=0.6005, loss=0.3437]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 228/490 [09:34<11:00,  2.52s/it, acc=0.6005, loss=0.3437]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 228/490 [09:36<11:00,  2.52s/it, acc=0.6008, loss=0.9938]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 229/490 [09:36<10:58,  2.52s/it, acc=0.6008, loss=0.9938]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 229/490 [09:39<10:58,  2.52s/it, acc=0.6015, loss=0.8142]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 230/490 [09:39<10:54,  2.52s/it, acc=0.6015, loss=0.8142]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 230/490 [09:41<10:54,  2.52s/it, acc=0.6020, loss=0.7221]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 231/490 [09:41<10:52,  2.52s/it, acc=0.6020, loss=0.7221]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 231/490 [09:44<10:52,  2.52s/it, acc=0.6026, loss=0.5292]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 232/490 [09:44<10:50,  2.52s/it, acc=0.6026, loss=0.5292]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 232/490 [09:46<10:50,  2.52s/it, acc=0.6034, loss=0.7806]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 233/490 [09:46<10:47,  2.52s/it, acc=0.6034, loss=0.7806]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 233/490 [09:49<10:47,  2.52s/it, acc=0.6040, loss=0.6828]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 234/490 [09:49<10:45,  2.52s/it, acc=0.6040, loss=0.6828]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 234/490 [09:51<10:45,  2.52s/it, acc=0.6047, loss=0.6666]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 235/490 [09:51<10:43,  2.52s/it, acc=0.6047, loss=0.6666]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 235/490 [09:54<10:43,  2.52s/it, acc=0.6055, loss=0.6978]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 236/490 [09:54<10:40,  2.52s/it, acc=0.6055, loss=0.6978]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 236/490 [09:56<10:40,  2.52s/it, acc=0.6059, loss=1.0405]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 237/490 [09:56<10:37,  2.52s/it, acc=0.6059, loss=1.0405]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 237/490 [09:59<10:37,  2.52s/it, acc=0.6064, loss=0.8531]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 238/490 [09:59<10:34,  2.52s/it, acc=0.6064, loss=0.8531]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 238/490 [10:01<10:34,  2.52s/it, acc=0.6068, loss=0.7153]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 239/490 [10:01<10:31,  2.52s/it, acc=0.6068, loss=0.7153]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 239/490 [10:04<10:31,  2.52s/it, acc=0.6070, loss=1.2265]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 240/490 [10:04<10:29,  2.52s/it, acc=0.6070, loss=1.2265]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 240/490 [10:06<10:29,  2.52s/it, acc=0.6072, loss=0.9685]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 241/490 [10:06<10:27,  2.52s/it, acc=0.6072, loss=0.9685]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 241/490 [10:09<10:27,  2.52s/it, acc=0.6077, loss=0.7505]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 242/490 [10:09<10:25,  2.52s/it, acc=0.6077, loss=0.7505]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 242/490 [10:11<10:25,  2.52s/it, acc=0.6085, loss=0.6243]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 243/490 [10:11<10:22,  2.52s/it, acc=0.6085, loss=0.6243]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 243/490 [10:14<10:22,  2.52s/it, acc=0.6091, loss=0.8668]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 244/490 [10:14<10:19,  2.52s/it, acc=0.6091, loss=0.8668]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 244/490 [10:16<10:19,  2.52s/it, acc=0.6092, loss=1.0731]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 245/490 [10:16<10:16,  2.52s/it, acc=0.6092, loss=1.0731]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 245/490 [10:19<10:16,  2.52s/it, acc=0.6100, loss=0.3978]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 246/490 [10:19<10:14,  2.52s/it, acc=0.6100, loss=0.3978]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 246/490 [10:21<10:14,  2.52s/it, acc=0.6101, loss=0.9092]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 247/490 [10:21<10:12,  2.52s/it, acc=0.6101, loss=0.9092]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 247/490 [10:24<10:12,  2.52s/it, acc=0.6105, loss=0.8048]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 248/490 [10:24<10:09,  2.52s/it, acc=0.6105, loss=0.8048]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 248/490 [10:26<10:09,  2.52s/it, acc=0.6107, loss=0.8618]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 249/490 [10:26<10:07,  2.52s/it, acc=0.6107, loss=0.8618]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 249/490 [10:29<10:07,  2.52s/it, acc=0.6108, loss=0.9734]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 250/490 [10:29<10:04,  2.52s/it, acc=0.6108, loss=0.9734]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 250/490 [10:31<10:04,  2.52s/it, acc=0.6112, loss=0.8602]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 251/490 [10:31<10:02,  2.52s/it, acc=0.6112, loss=0.8602]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 251/490 [10:34<10:02,  2.52s/it, acc=0.6120, loss=0.7532]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 252/490 [10:34<09:59,  2.52s/it, acc=0.6120, loss=0.7532]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 252/490 [10:37<09:59,  2.52s/it, acc=0.6114, loss=1.2038]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 253/490 [10:37<09:57,  2.52s/it, acc=0.6114, loss=1.2038]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 253/490 [10:39<09:57,  2.52s/it, acc=0.6120, loss=0.7469]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 254/490 [10:39<09:54,  2.52s/it, acc=0.6120, loss=0.7469]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 254/490 [10:42<09:54,  2.52s/it, acc=0.6125, loss=0.7579]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 255/490 [10:42<09:51,  2.52s/it, acc=0.6125, loss=0.7579]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 255/490 [10:44<09:51,  2.52s/it, acc=0.6123, loss=0.9531]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 256/490 [10:44<09:49,  2.52s/it, acc=0.6123, loss=0.9531]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 256/490 [10:47<09:49,  2.52s/it, acc=0.6128, loss=0.7218]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 257/490 [10:47<09:46,  2.52s/it, acc=0.6128, loss=0.7218]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 257/490 [10:49<09:46,  2.52s/it, acc=0.6134, loss=0.7301]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 258/490 [10:49<09:44,  2.52s/it, acc=0.6134, loss=0.7301]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 258/490 [10:52<09:44,  2.52s/it, acc=0.6141, loss=0.7120]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 259/490 [10:52<09:42,  2.52s/it, acc=0.6141, loss=0.7120]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 259/490 [10:54<09:42,  2.52s/it, acc=0.6144, loss=1.0036]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 260/490 [10:54<09:39,  2.52s/it, acc=0.6144, loss=1.0036]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 260/490 [10:57<09:39,  2.52s/it, acc=0.6142, loss=1.2323]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 261/490 [10:57<09:37,  2.52s/it, acc=0.6142, loss=1.2323]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 261/490 [10:59<09:37,  2.52s/it, acc=0.6147, loss=0.7528]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 262/490 [10:59<09:34,  2.52s/it, acc=0.6147, loss=0.7528]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 262/490 [11:02<09:34,  2.52s/it, acc=0.6159, loss=0.5039]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 263/490 [11:02<09:31,  2.52s/it, acc=0.6159, loss=0.5039]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 263/490 [11:04<09:31,  2.52s/it, acc=0.6165, loss=0.7796]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 264/490 [11:04<09:29,  2.52s/it, acc=0.6165, loss=0.7796]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 264/490 [11:07<09:29,  2.52s/it, acc=0.6171, loss=0.5172]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 265/490 [11:07<09:26,  2.52s/it, acc=0.6171, loss=0.5172]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 265/490 [11:09<09:26,  2.52s/it, acc=0.6176, loss=0.7262]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 266/490 [11:09<09:23,  2.52s/it, acc=0.6176, loss=0.7262]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 266/490 [11:12<09:23,  2.52s/it, acc=0.6182, loss=0.6986]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 267/490 [11:12<09:21,  2.52s/it, acc=0.6182, loss=0.6986]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 267/490 [11:14<09:21,  2.52s/it, acc=0.6181, loss=0.9940]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 268/490 [11:14<09:19,  2.52s/it, acc=0.6181, loss=0.9940]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 268/490 [11:17<09:19,  2.52s/it, acc=0.6186, loss=0.6584]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 269/490 [11:17<09:17,  2.52s/it, acc=0.6186, loss=0.6584]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 269/490 [11:19<09:17,  2.52s/it, acc=0.6188, loss=0.8405]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 270/490 [11:19<09:15,  2.52s/it, acc=0.6188, loss=0.8405]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 270/490 [11:22<09:15,  2.52s/it, acc=0.6188, loss=0.9209]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 271/490 [11:22<09:12,  2.52s/it, acc=0.6188, loss=0.9209]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 271/490 [11:24<09:12,  2.52s/it, acc=0.6194, loss=0.5580]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 272/490 [11:24<09:09,  2.52s/it, acc=0.6194, loss=0.5580]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 272/490 [11:27<09:09,  2.52s/it, acc=0.6197, loss=0.9212]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 273/490 [11:27<09:07,  2.52s/it, acc=0.6197, loss=0.9212]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 273/490 [11:29<09:07,  2.52s/it, acc=0.6198, loss=1.0369]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 274/490 [11:29<09:05,  2.52s/it, acc=0.6198, loss=1.0369]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 274/490 [11:32<09:05,  2.52s/it, acc=0.6202, loss=0.9580]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 275/490 [11:32<09:01,  2.52s/it, acc=0.6202, loss=0.9580]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 275/490 [11:35<09:01,  2.52s/it, acc=0.6212, loss=0.6208]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 276/490 [11:35<08:59,  2.52s/it, acc=0.6212, loss=0.6208]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 276/490 [11:37<08:59,  2.52s/it, acc=0.6211, loss=0.9349]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 277/490 [11:37<08:56,  2.52s/it, acc=0.6211, loss=0.9349]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 277/490 [11:40<08:56,  2.52s/it, acc=0.6215, loss=0.8000]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 278/490 [11:40<08:54,  2.52s/it, acc=0.6215, loss=0.8000]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 278/490 [11:42<08:54,  2.52s/it, acc=0.6223, loss=0.5678]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 279/490 [11:42<08:51,  2.52s/it, acc=0.6223, loss=0.5678]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 279/490 [11:45<08:51,  2.52s/it, acc=0.6228, loss=0.6994]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 280/490 [11:45<08:49,  2.52s/it, acc=0.6228, loss=0.6994]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 280/490 [11:47<08:49,  2.52s/it, acc=0.6232, loss=0.7598]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 281/490 [11:47<08:46,  2.52s/it, acc=0.6232, loss=0.7598]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 281/490 [11:50<08:46,  2.52s/it, acc=0.6233, loss=0.8911]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 282/490 [11:50<08:43,  2.52s/it, acc=0.6233, loss=0.8911]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 282/490 [11:52<08:43,  2.52s/it, acc=0.6236, loss=1.1506]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 283/490 [11:52<08:41,  2.52s/it, acc=0.6236, loss=1.1506]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 283/490 [11:55<08:41,  2.52s/it, acc=0.6236, loss=1.0374]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 284/490 [11:55<08:39,  2.52s/it, acc=0.6236, loss=1.0374]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 284/490 [11:57<08:39,  2.52s/it, acc=0.6237, loss=0.9105]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 285/490 [11:57<08:36,  2.52s/it, acc=0.6237, loss=0.9105]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 285/490 [12:00<08:36,  2.52s/it, acc=0.6243, loss=0.5366]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 286/490 [12:00<08:34,  2.52s/it, acc=0.6243, loss=0.5366]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 286/490 [12:02<08:34,  2.52s/it, acc=0.6247, loss=0.7300]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 287/490 [12:02<08:31,  2.52s/it, acc=0.6247, loss=0.7300]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 287/490 [12:05<08:31,  2.52s/it, acc=0.6254, loss=0.5019]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 288/490 [12:05<08:29,  2.52s/it, acc=0.6254, loss=0.5019]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 288/490 [12:07<08:29,  2.52s/it, acc=0.6259, loss=0.6964]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 289/490 [12:07<08:26,  2.52s/it, acc=0.6259, loss=0.6964]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 289/490 [12:10<08:26,  2.52s/it, acc=0.6268, loss=0.3614]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 290/490 [12:10<08:23,  2.52s/it, acc=0.6268, loss=0.3614]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 290/490 [12:12<08:23,  2.52s/it, acc=0.6274, loss=0.6633]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 291/490 [12:12<08:21,  2.52s/it, acc=0.6274, loss=0.6633]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 291/490 [12:15<08:21,  2.52s/it, acc=0.6274, loss=0.8868]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 292/490 [12:15<08:18,  2.52s/it, acc=0.6274, loss=0.8868]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 292/490 [12:17<08:18,  2.52s/it, acc=0.6276, loss=0.7694]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 293/490 [12:17<08:16,  2.52s/it, acc=0.6276, loss=0.7694]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 293/490 [12:20<08:16,  2.52s/it, acc=0.6278, loss=0.6301]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 294/490 [12:20<08:13,  2.52s/it, acc=0.6278, loss=0.6301]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 294/490 [12:22<08:13,  2.52s/it, acc=0.6286, loss=0.4266]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 295/490 [12:22<08:11,  2.52s/it, acc=0.6286, loss=0.4266]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 295/490 [12:25<08:11,  2.52s/it, acc=0.6289, loss=0.7364]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 296/490 [12:25<08:09,  2.52s/it, acc=0.6289, loss=0.7364]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 296/490 [12:27<08:09,  2.52s/it, acc=0.6293, loss=0.5849]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 297/490 [12:27<08:06,  2.52s/it, acc=0.6293, loss=0.5849]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 297/490 [12:30<08:06,  2.52s/it, acc=0.6298, loss=0.5609]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 298/490 [12:30<08:04,  2.52s/it, acc=0.6298, loss=0.5609]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 298/490 [12:32<08:04,  2.52s/it, acc=0.6300, loss=1.0382]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 299/490 [12:32<08:01,  2.52s/it, acc=0.6300, loss=1.0382]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 299/490 [12:35<08:01,  2.52s/it, acc=0.6304, loss=0.7173]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 300/490 [12:35<07:59,  2.52s/it, acc=0.6304, loss=0.7173]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 300/490 [12:38<07:59,  2.52s/it, acc=0.6309, loss=0.6032]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 301/490 [12:38<07:56,  2.52s/it, acc=0.6309, loss=0.6032]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 301/490 [12:40<07:56,  2.52s/it, acc=0.6314, loss=0.5441]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 302/490 [12:40<07:54,  2.52s/it, acc=0.6314, loss=0.5441]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 302/490 [12:43<07:54,  2.52s/it, acc=0.6314, loss=0.7366]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 303/490 [12:43<07:51,  2.52s/it, acc=0.6314, loss=0.7366]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 303/490 [12:45<07:51,  2.52s/it, acc=0.6322, loss=0.4002]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 304/490 [12:45<07:48,  2.52s/it, acc=0.6322, loss=0.4002]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 304/490 [12:48<07:48,  2.52s/it, acc=0.6328, loss=0.7194]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 305/490 [12:48<07:46,  2.52s/it, acc=0.6328, loss=0.7194]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 305/490 [12:50<07:46,  2.52s/it, acc=0.6332, loss=0.7308]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 306/490 [12:50<07:44,  2.52s/it, acc=0.6332, loss=0.7308]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 306/490 [12:53<07:44,  2.52s/it, acc=0.6334, loss=0.7056]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 307/490 [12:53<07:41,  2.52s/it, acc=0.6334, loss=0.7056]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 307/490 [12:55<07:41,  2.52s/it, acc=0.6335, loss=0.9209]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 308/490 [12:55<07:38,  2.52s/it, acc=0.6335, loss=0.9209]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 308/490 [12:58<07:38,  2.52s/it, acc=0.6339, loss=0.6681]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 309/490 [12:58<07:36,  2.52s/it, acc=0.6339, loss=0.6681]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 309/490 [13:00<07:36,  2.52s/it, acc=0.6343, loss=0.6876]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 310/490 [13:00<07:33,  2.52s/it, acc=0.6343, loss=0.6876]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 310/490 [13:03<07:33,  2.52s/it, acc=0.6340, loss=1.0649]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 311/490 [13:03<07:31,  2.52s/it, acc=0.6340, loss=1.0649]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 311/490 [13:05<07:31,  2.52s/it, acc=0.6339, loss=1.0860]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 312/490 [13:05<07:28,  2.52s/it, acc=0.6339, loss=1.0860]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 312/490 [13:08<07:28,  2.52s/it, acc=0.6345, loss=0.5981]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 313/490 [13:08<07:25,  2.52s/it, acc=0.6345, loss=0.5981]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 313/490 [13:10<07:25,  2.52s/it, acc=0.6346, loss=0.7766]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 314/490 [13:10<07:23,  2.52s/it, acc=0.6346, loss=0.7766]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 314/490 [13:13<07:23,  2.52s/it, acc=0.6349, loss=0.5751]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 315/490 [13:13<07:21,  2.52s/it, acc=0.6349, loss=0.5751]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 315/490 [13:15<07:21,  2.52s/it, acc=0.6351, loss=0.9468]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 316/490 [13:15<07:18,  2.52s/it, acc=0.6351, loss=0.9468]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 316/490 [13:18<07:18,  2.52s/it, acc=0.6355, loss=0.7117]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 317/490 [13:18<07:16,  2.52s/it, acc=0.6355, loss=0.7117]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 317/490 [13:20<07:16,  2.52s/it, acc=0.6358, loss=0.8056]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 318/490 [13:20<07:13,  2.52s/it, acc=0.6358, loss=0.8056]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 318/490 [13:23<07:13,  2.52s/it, acc=0.6360, loss=0.8057]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 319/490 [13:23<07:10,  2.52s/it, acc=0.6360, loss=0.8057]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 319/490 [13:25<07:10,  2.52s/it, acc=0.6360, loss=0.9091]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 320/490 [13:25<07:08,  2.52s/it, acc=0.6360, loss=0.9091]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 320/490 [13:28<07:08,  2.52s/it, acc=0.6364, loss=0.5922]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 321/490 [13:28<07:05,  2.52s/it, acc=0.6364, loss=0.5922]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 321/490 [13:30<07:05,  2.52s/it, acc=0.6370, loss=0.4922]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 322/490 [13:30<07:03,  2.52s/it, acc=0.6370, loss=0.4922]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 322/490 [13:33<07:03,  2.52s/it, acc=0.6376, loss=0.5499]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 323/490 [13:33<07:01,  2.52s/it, acc=0.6376, loss=0.5499]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 323/490 [13:35<07:01,  2.52s/it, acc=0.6382, loss=0.5813]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 324/490 [13:35<06:58,  2.52s/it, acc=0.6382, loss=0.5813]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 324/490 [13:38<06:58,  2.52s/it, acc=0.6385, loss=0.8566]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 325/490 [13:38<06:55,  2.52s/it, acc=0.6385, loss=0.8566]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 325/490 [13:41<06:55,  2.52s/it, acc=0.6386, loss=0.9935]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 326/490 [13:41<06:53,  2.52s/it, acc=0.6386, loss=0.9935]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 326/490 [13:43<06:53,  2.52s/it, acc=0.6388, loss=0.8574]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 327/490 [13:43<06:50,  2.52s/it, acc=0.6388, loss=0.8574]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 327/490 [13:46<06:50,  2.52s/it, acc=0.6387, loss=0.7623]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 328/490 [13:46<06:48,  2.52s/it, acc=0.6387, loss=0.7623]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 328/490 [13:48<06:48,  2.52s/it, acc=0.6388, loss=0.7325]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 329/490 [13:48<06:46,  2.52s/it, acc=0.6388, loss=0.7325]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 329/490 [13:51<06:46,  2.52s/it, acc=0.6391, loss=0.6573]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 330/490 [13:51<06:43,  2.52s/it, acc=0.6391, loss=0.6573]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 330/490 [13:53<06:43,  2.52s/it, acc=0.6391, loss=0.8570]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 331/490 [13:53<06:40,  2.52s/it, acc=0.6391, loss=0.8570]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 331/490 [13:56<06:40,  2.52s/it, acc=0.6395, loss=0.6008]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 332/490 [13:56<06:38,  2.52s/it, acc=0.6395, loss=0.6008]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 332/490 [13:58<06:38,  2.52s/it, acc=0.6399, loss=0.6601]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 333/490 [13:58<06:35,  2.52s/it, acc=0.6399, loss=0.6601]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 333/490 [14:01<06:35,  2.52s/it, acc=0.6400, loss=0.8730]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 334/490 [14:01<06:33,  2.52s/it, acc=0.6400, loss=0.8730]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 334/490 [14:03<06:33,  2.52s/it, acc=0.6407, loss=0.4201]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 335/490 [14:03<06:30,  2.52s/it, acc=0.6407, loss=0.4201]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 335/490 [14:06<06:30,  2.52s/it, acc=0.6408, loss=0.7118]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 336/490 [14:06<06:27,  2.52s/it, acc=0.6408, loss=0.7118]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 336/490 [14:08<06:27,  2.52s/it, acc=0.6415, loss=0.3202]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 337/490 [14:08<06:25,  2.52s/it, acc=0.6415, loss=0.3202]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 337/490 [14:11<06:25,  2.52s/it, acc=0.6418, loss=0.7567]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 338/490 [14:11<06:23,  2.52s/it, acc=0.6418, loss=0.7567]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 338/490 [14:13<06:23,  2.52s/it, acc=0.6422, loss=0.5703]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 339/490 [14:13<06:20,  2.52s/it, acc=0.6422, loss=0.5703]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 339/490 [14:16<06:20,  2.52s/it, acc=0.6425, loss=0.7600]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 340/490 [14:16<06:18,  2.52s/it, acc=0.6425, loss=0.7600]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 340/490 [14:18<06:18,  2.52s/it, acc=0.6428, loss=0.8149]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 341/490 [14:18<06:15,  2.52s/it, acc=0.6428, loss=0.8149]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 341/490 [14:21<06:15,  2.52s/it, acc=0.6431, loss=0.8120]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 342/490 [14:21<06:12,  2.52s/it, acc=0.6431, loss=0.8120]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 342/490 [14:23<06:12,  2.52s/it, acc=0.6431, loss=0.9051]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 343/490 [14:23<06:10,  2.52s/it, acc=0.6431, loss=0.9051]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 343/490 [14:26<06:10,  2.52s/it, acc=0.6435, loss=0.7220]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 344/490 [14:26<06:07,  2.52s/it, acc=0.6435, loss=0.7220]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 344/490 [14:28<06:07,  2.52s/it, acc=0.6434, loss=1.0392]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 345/490 [14:28<06:05,  2.52s/it, acc=0.6434, loss=1.0392]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 345/490 [14:31<06:05,  2.52s/it, acc=0.6437, loss=0.7768]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 346/490 [14:31<06:02,  2.52s/it, acc=0.6437, loss=0.7768]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 346/490 [14:33<06:02,  2.52s/it, acc=0.6443, loss=0.6682]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 347/490 [14:33<06:00,  2.52s/it, acc=0.6443, loss=0.6682]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 347/490 [14:36<06:00,  2.52s/it, acc=0.6447, loss=0.4724]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 348/490 [14:36<05:57,  2.52s/it, acc=0.6447, loss=0.4724]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 348/490 [14:38<05:57,  2.52s/it, acc=0.6450, loss=0.7117]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 349/490 [14:38<05:55,  2.52s/it, acc=0.6450, loss=0.7117]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 349/490 [14:41<05:55,  2.52s/it, acc=0.6456, loss=0.4223]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 350/490 [14:41<05:52,  2.52s/it, acc=0.6456, loss=0.4223]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 350/490 [14:44<05:52,  2.52s/it, acc=0.6459, loss=0.6398]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 351/490 [14:44<05:50,  2.52s/it, acc=0.6459, loss=0.6398]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 351/490 [14:46<05:50,  2.52s/it, acc=0.6458, loss=0.9925]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 352/490 [14:46<05:48,  2.52s/it, acc=0.6458, loss=0.9925]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 352/490 [14:49<05:48,  2.52s/it, acc=0.6458, loss=1.0101]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 353/490 [14:49<05:45,  2.52s/it, acc=0.6458, loss=1.0101]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 353/490 [14:51<05:45,  2.52s/it, acc=0.6460, loss=0.7835]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 354/490 [14:51<05:43,  2.52s/it, acc=0.6460, loss=0.7835]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 354/490 [14:54<05:43,  2.52s/it, acc=0.6465, loss=0.5211]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 355/490 [14:54<05:40,  2.52s/it, acc=0.6465, loss=0.5211]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 355/490 [14:56<05:40,  2.52s/it, acc=0.6469, loss=0.4533]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 356/490 [14:56<05:37,  2.52s/it, acc=0.6469, loss=0.4533]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 356/490 [14:59<05:37,  2.52s/it, acc=0.6471, loss=0.5356]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 357/490 [14:59<05:35,  2.52s/it, acc=0.6471, loss=0.5356]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 357/490 [15:01<05:35,  2.52s/it, acc=0.6474, loss=0.5426]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 358/490 [15:01<05:32,  2.52s/it, acc=0.6474, loss=0.5426]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 358/490 [15:04<05:32,  2.52s/it, acc=0.6475, loss=1.0575]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 359/490 [15:04<05:30,  2.52s/it, acc=0.6475, loss=1.0575]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 359/490 [15:06<05:30,  2.52s/it, acc=0.6476, loss=0.9061]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 360/490 [15:06<05:27,  2.52s/it, acc=0.6476, loss=0.9061]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 360/490 [15:09<05:27,  2.52s/it, acc=0.6476, loss=0.8442]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 361/490 [15:09<05:25,  2.52s/it, acc=0.6476, loss=0.8442]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 361/490 [15:11<05:25,  2.52s/it, acc=0.6472, loss=1.4189]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 362/490 [15:11<05:23,  2.52s/it, acc=0.6472, loss=1.4189]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 362/490 [15:14<05:23,  2.52s/it, acc=0.6474, loss=0.8340]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 363/490 [15:14<05:20,  2.52s/it, acc=0.6474, loss=0.8340]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 363/490 [15:16<05:20,  2.52s/it, acc=0.6478, loss=0.7039]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 364/490 [15:16<05:18,  2.52s/it, acc=0.6478, loss=0.7039]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 364/490 [15:19<05:18,  2.52s/it, acc=0.6479, loss=0.9386]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 365/490 [15:19<05:15,  2.52s/it, acc=0.6479, loss=0.9386]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 365/490 [15:21<05:15,  2.52s/it, acc=0.6482, loss=0.7095]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 366/490 [15:21<05:12,  2.52s/it, acc=0.6482, loss=0.7095]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 366/490 [15:24<05:12,  2.52s/it, acc=0.6484, loss=1.2031]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 367/490 [15:24<05:10,  2.52s/it, acc=0.6484, loss=1.2031]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 367/490 [15:26<05:10,  2.52s/it, acc=0.6489, loss=0.5831]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 368/490 [15:26<05:08,  2.52s/it, acc=0.6489, loss=0.5831]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 368/490 [15:29<05:08,  2.52s/it, acc=0.6488, loss=0.9344]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 369/490 [15:29<05:05,  2.52s/it, acc=0.6488, loss=0.9344]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 369/490 [15:31<05:05,  2.52s/it, acc=0.6492, loss=0.4592]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 370/490 [15:31<05:03,  2.53s/it, acc=0.6492, loss=0.4592]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 370/490 [15:34<05:03,  2.53s/it, acc=0.6496, loss=0.4974]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 371/490 [15:34<05:00,  2.52s/it, acc=0.6496, loss=0.4974]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 371/490 [15:37<05:00,  2.52s/it, acc=0.6498, loss=0.6224]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 372/490 [15:37<04:57,  2.52s/it, acc=0.6498, loss=0.6224]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 372/490 [15:39<04:57,  2.52s/it, acc=0.6498, loss=0.9946]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 373/490 [15:39<04:55,  2.52s/it, acc=0.6498, loss=0.9946]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 373/490 [15:42<04:55,  2.52s/it, acc=0.6500, loss=0.6259]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 374/490 [15:42<04:52,  2.52s/it, acc=0.6500, loss=0.6259]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 374/490 [15:44<04:52,  2.52s/it, acc=0.6503, loss=0.5992]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 375/490 [15:44<04:50,  2.52s/it, acc=0.6503, loss=0.5992]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 375/490 [15:47<04:50,  2.52s/it, acc=0.6509, loss=0.6241]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 376/490 [15:47<04:47,  2.52s/it, acc=0.6509, loss=0.6241]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 376/490 [15:49<04:47,  2.52s/it, acc=0.6514, loss=0.6843]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 377/490 [15:49<04:45,  2.52s/it, acc=0.6514, loss=0.6843]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 377/490 [15:52<04:45,  2.52s/it, acc=0.6516, loss=0.7109]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 378/490 [15:52<04:42,  2.52s/it, acc=0.6516, loss=0.7109]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 378/490 [15:54<04:42,  2.52s/it, acc=0.6520, loss=0.7381]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 379/490 [15:54<04:40,  2.52s/it, acc=0.6520, loss=0.7381]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 379/490 [15:57<04:40,  2.52s/it, acc=0.6523, loss=0.5958]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 380/490 [15:57<04:37,  2.52s/it, acc=0.6523, loss=0.5958]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 380/490 [15:59<04:37,  2.52s/it, acc=0.6525, loss=0.7518]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 381/490 [15:59<04:34,  2.52s/it, acc=0.6525, loss=0.7518]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 381/490 [16:02<04:34,  2.52s/it, acc=0.6531, loss=0.5730]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 382/490 [16:02<04:32,  2.52s/it, acc=0.6531, loss=0.5730]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 382/490 [16:04<04:32,  2.52s/it, acc=0.6533, loss=0.8658]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 383/490 [16:04<04:29,  2.52s/it, acc=0.6533, loss=0.8658]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 383/490 [16:07<04:29,  2.52s/it, acc=0.6537, loss=0.5725]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 384/490 [16:07<04:27,  2.52s/it, acc=0.6537, loss=0.5725]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 384/490 [16:09<04:27,  2.52s/it, acc=0.6537, loss=0.8444]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 385/490 [16:09<04:24,  2.52s/it, acc=0.6537, loss=0.8444]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 385/490 [16:12<04:24,  2.52s/it, acc=0.6540, loss=0.5971]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 386/490 [16:12<04:22,  2.52s/it, acc=0.6540, loss=0.5971]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 386/490 [16:14<04:22,  2.52s/it, acc=0.6542, loss=0.7535]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 387/490 [16:14<04:19,  2.52s/it, acc=0.6542, loss=0.7535]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 387/490 [16:17<04:19,  2.52s/it, acc=0.6542, loss=1.0696]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 388/490 [16:17<04:17,  2.52s/it, acc=0.6542, loss=1.0696]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 388/490 [16:19<04:17,  2.52s/it, acc=0.6545, loss=0.5708]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 389/490 [16:19<04:14,  2.52s/it, acc=0.6545, loss=0.5708]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 389/490 [16:22<04:14,  2.52s/it, acc=0.6548, loss=0.4845]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 390/490 [16:22<04:12,  2.52s/it, acc=0.6548, loss=0.4845]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 390/490 [16:24<04:12,  2.52s/it, acc=0.6551, loss=0.7937]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 391/490 [16:24<04:09,  2.52s/it, acc=0.6551, loss=0.7937]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 391/490 [16:27<04:09,  2.52s/it, acc=0.6555, loss=0.5283]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 392/490 [16:27<04:06,  2.52s/it, acc=0.6555, loss=0.5283]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 392/490 [16:29<04:06,  2.52s/it, acc=0.6557, loss=0.6727]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 393/490 [16:29<04:04,  2.52s/it, acc=0.6557, loss=0.6727]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 393/490 [16:32<04:04,  2.52s/it, acc=0.6562, loss=0.4663]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 394/490 [16:32<04:02,  2.52s/it, acc=0.6562, loss=0.4663]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 394/490 [16:35<04:02,  2.52s/it, acc=0.6562, loss=0.9958]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 395/490 [16:35<03:59,  2.52s/it, acc=0.6562, loss=0.9958]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 395/490 [16:37<03:59,  2.52s/it, acc=0.6566, loss=0.7411]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 396/490 [16:37<03:57,  2.52s/it, acc=0.6566, loss=0.7411]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 396/490 [16:40<03:57,  2.52s/it, acc=0.6568, loss=0.6037]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 397/490 [16:40<03:54,  2.52s/it, acc=0.6568, loss=0.6037]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 397/490 [16:42<03:54,  2.52s/it, acc=0.6570, loss=0.5756]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 398/490 [16:42<03:51,  2.52s/it, acc=0.6570, loss=0.5756]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 398/490 [16:45<03:51,  2.52s/it, acc=0.6574, loss=0.6084]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 399/490 [16:45<03:49,  2.52s/it, acc=0.6574, loss=0.6084]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 399/490 [16:47<03:49,  2.52s/it, acc=0.6575, loss=0.7176]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 400/490 [16:47<03:46,  2.52s/it, acc=0.6575, loss=0.7176]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 400/490 [16:50<03:46,  2.52s/it, acc=0.6577, loss=0.7154]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 401/490 [16:50<03:44,  2.52s/it, acc=0.6577, loss=0.7154]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 401/490 [16:52<03:44,  2.52s/it, acc=0.6582, loss=0.5475]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 402/490 [16:52<03:42,  2.52s/it, acc=0.6582, loss=0.5475]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 402/490 [16:55<03:42,  2.52s/it, acc=0.6584, loss=0.4211]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 403/490 [16:55<03:39,  2.52s/it, acc=0.6584, loss=0.4211]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 403/490 [16:57<03:39,  2.52s/it, acc=0.6588, loss=0.4570]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 404/490 [16:57<03:36,  2.52s/it, acc=0.6588, loss=0.4570]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 404/490 [17:00<03:36,  2.52s/it, acc=0.6586, loss=0.9811]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 405/490 [17:00<03:34,  2.52s/it, acc=0.6586, loss=0.9811]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 405/490 [17:02<03:34,  2.52s/it, acc=0.6586, loss=0.7064]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 406/490 [17:02<03:31,  2.52s/it, acc=0.6586, loss=0.7064]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 406/490 [17:05<03:31,  2.52s/it, acc=0.6586, loss=0.6600]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 407/490 [17:05<03:29,  2.52s/it, acc=0.6586, loss=0.6600]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 407/490 [17:07<03:29,  2.52s/it, acc=0.6588, loss=0.6313]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 408/490 [17:07<03:26,  2.52s/it, acc=0.6588, loss=0.6313]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 408/490 [17:10<03:26,  2.52s/it, acc=0.6589, loss=0.6064]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 409/490 [17:10<03:24,  2.52s/it, acc=0.6589, loss=0.6064]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 409/490 [17:12<03:24,  2.52s/it, acc=0.6592, loss=0.6023]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 410/490 [17:12<03:21,  2.52s/it, acc=0.6592, loss=0.6023]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 410/490 [17:15<03:21,  2.52s/it, acc=0.6591, loss=0.9906]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 411/490 [17:15<03:19,  2.52s/it, acc=0.6591, loss=0.9906]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 411/490 [17:17<03:19,  2.52s/it, acc=0.6595, loss=0.6564]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 412/490 [17:17<03:16,  2.52s/it, acc=0.6595, loss=0.6564]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 412/490 [17:20<03:16,  2.52s/it, acc=0.6597, loss=0.7854]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 413/490 [17:20<03:13,  2.52s/it, acc=0.6597, loss=0.7854]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 413/490 [17:22<03:13,  2.52s/it, acc=0.6598, loss=0.7511]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 414/490 [17:22<03:11,  2.52s/it, acc=0.6598, loss=0.7511]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 414/490 [17:25<03:11,  2.52s/it, acc=0.6602, loss=0.6096]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 415/490 [17:25<03:08,  2.52s/it, acc=0.6602, loss=0.6096]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 415/490 [17:27<03:08,  2.52s/it, acc=0.6604, loss=0.7200]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 416/490 [17:27<03:06,  2.52s/it, acc=0.6604, loss=0.7200]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 416/490 [17:30<03:06,  2.52s/it, acc=0.6607, loss=0.5940]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 417/490 [17:30<03:03,  2.52s/it, acc=0.6607, loss=0.5940]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 417/490 [17:32<03:03,  2.52s/it, acc=0.6607, loss=0.7436]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 418/490 [17:32<03:01,  2.52s/it, acc=0.6607, loss=0.7436]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 418/490 [17:35<03:01,  2.52s/it, acc=0.6609, loss=0.5837]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 419/490 [17:35<02:58,  2.52s/it, acc=0.6609, loss=0.5837]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 419/490 [17:38<02:58,  2.52s/it, acc=0.6611, loss=0.6390]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 420/490 [17:38<02:56,  2.52s/it, acc=0.6611, loss=0.6390]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 420/490 [17:40<02:56,  2.52s/it, acc=0.6613, loss=0.7692]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 421/490 [17:40<02:53,  2.52s/it, acc=0.6613, loss=0.7692]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 421/490 [17:43<02:53,  2.52s/it, acc=0.6618, loss=0.4407]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 422/490 [17:43<02:51,  2.52s/it, acc=0.6618, loss=0.4407]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 422/490 [17:45<02:51,  2.52s/it, acc=0.6621, loss=0.5743]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 423/490 [17:45<02:48,  2.52s/it, acc=0.6621, loss=0.5743]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 423/490 [17:48<02:48,  2.52s/it, acc=0.6623, loss=0.6838]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 424/490 [17:48<02:46,  2.52s/it, acc=0.6623, loss=0.6838]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 424/490 [17:50<02:46,  2.52s/it, acc=0.6625, loss=0.7902]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 425/490 [17:50<02:43,  2.52s/it, acc=0.6625, loss=0.7902]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 425/490 [17:53<02:43,  2.52s/it, acc=0.6625, loss=0.9664]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 426/490 [17:53<02:41,  2.52s/it, acc=0.6625, loss=0.9664]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 426/490 [17:55<02:41,  2.52s/it, acc=0.6627, loss=0.6315]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 427/490 [17:55<02:38,  2.52s/it, acc=0.6627, loss=0.6315]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 427/490 [17:58<02:38,  2.52s/it, acc=0.6630, loss=0.6394]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 428/490 [17:58<02:36,  2.52s/it, acc=0.6630, loss=0.6394]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 428/490 [18:00<02:36,  2.52s/it, acc=0.6631, loss=0.8597]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 429/490 [18:00<02:33,  2.52s/it, acc=0.6631, loss=0.8597]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 429/490 [18:03<02:33,  2.52s/it, acc=0.6632, loss=0.7542]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 430/490 [18:03<02:30,  2.52s/it, acc=0.6632, loss=0.7542]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 430/490 [18:05<02:30,  2.52s/it, acc=0.6635, loss=0.5606]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 431/490 [18:05<02:28,  2.51s/it, acc=0.6635, loss=0.5606]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 431/490 [18:08<02:28,  2.51s/it, acc=0.6640, loss=0.4918]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 432/490 [18:08<02:25,  2.51s/it, acc=0.6640, loss=0.4918]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 432/490 [18:10<02:25,  2.51s/it, acc=0.6640, loss=0.9055]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 433/490 [18:10<02:23,  2.51s/it, acc=0.6640, loss=0.9055]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 433/490 [18:13<02:23,  2.51s/it, acc=0.6645, loss=0.5928]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 434/490 [18:13<02:20,  2.51s/it, acc=0.6645, loss=0.5928]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 434/490 [18:15<02:20,  2.51s/it, acc=0.6647, loss=0.7429]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 435/490 [18:15<02:18,  2.51s/it, acc=0.6647, loss=0.7429]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 435/490 [18:18<02:18,  2.51s/it, acc=0.6649, loss=0.6095]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 436/490 [18:18<02:15,  2.52s/it, acc=0.6649, loss=0.6095]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 436/490 [18:20<02:15,  2.52s/it, acc=0.6653, loss=0.5088]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 437/490 [18:20<02:13,  2.52s/it, acc=0.6653, loss=0.5088]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 437/490 [18:23<02:13,  2.52s/it, acc=0.6655, loss=0.7443]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 438/490 [18:23<02:10,  2.52s/it, acc=0.6655, loss=0.7443]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 438/490 [18:25<02:10,  2.52s/it, acc=0.6655, loss=0.8213]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 439/490 [18:25<02:08,  2.52s/it, acc=0.6655, loss=0.8213]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 439/490 [18:28<02:08,  2.52s/it, acc=0.6658, loss=0.5288]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 440/490 [18:28<02:05,  2.52s/it, acc=0.6658, loss=0.5288]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 440/490 [18:30<02:05,  2.52s/it, acc=0.6660, loss=0.5453]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 441/490 [18:30<02:03,  2.52s/it, acc=0.6660, loss=0.5453]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 441/490 [18:33<02:03,  2.52s/it, acc=0.6657, loss=1.1307]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 442/490 [18:33<02:00,  2.52s/it, acc=0.6657, loss=1.1307]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 442/490 [18:35<02:00,  2.52s/it, acc=0.6660, loss=0.5994]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 443/490 [18:35<01:58,  2.52s/it, acc=0.6660, loss=0.5994]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 443/490 [18:38<01:58,  2.52s/it, acc=0.6664, loss=0.4861]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 444/490 [18:38<01:55,  2.52s/it, acc=0.6664, loss=0.4861]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 444/490 [18:40<01:55,  2.52s/it, acc=0.6669, loss=0.4130]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 445/490 [18:40<01:53,  2.52s/it, acc=0.6669, loss=0.4130]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 445/490 [18:43<01:53,  2.52s/it, acc=0.6668, loss=0.7692]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 446/490 [18:43<01:50,  2.52s/it, acc=0.6668, loss=0.7692]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 446/490 [18:45<01:50,  2.52s/it, acc=0.6673, loss=0.3166]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 447/490 [18:45<01:48,  2.52s/it, acc=0.6673, loss=0.3166]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 447/490 [18:48<01:48,  2.52s/it, acc=0.6676, loss=0.5789]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 448/490 [18:48<01:45,  2.52s/it, acc=0.6676, loss=0.5789]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 448/490 [18:51<01:45,  2.52s/it, acc=0.6678, loss=0.6925]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 449/490 [18:51<01:43,  2.52s/it, acc=0.6678, loss=0.6925]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 449/490 [18:53<01:43,  2.52s/it, acc=0.6680, loss=0.7179]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 450/490 [18:53<01:40,  2.52s/it, acc=0.6680, loss=0.7179]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 450/490 [18:56<01:40,  2.52s/it, acc=0.6681, loss=0.6912]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 451/490 [18:56<01:38,  2.52s/it, acc=0.6681, loss=0.6912]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 451/490 [18:58<01:38,  2.52s/it, acc=0.6683, loss=0.7731]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 452/490 [18:58<01:35,  2.52s/it, acc=0.6683, loss=0.7731]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 452/490 [19:01<01:35,  2.52s/it, acc=0.6683, loss=1.0228]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 453/490 [19:01<01:33,  2.51s/it, acc=0.6683, loss=1.0228]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 453/490 [19:03<01:33,  2.51s/it, acc=0.6684, loss=0.7076]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 454/490 [19:03<01:30,  2.52s/it, acc=0.6684, loss=0.7076]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 454/490 [19:06<01:30,  2.52s/it, acc=0.6687, loss=0.6962]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 455/490 [19:06<01:28,  2.52s/it, acc=0.6687, loss=0.6962]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 455/490 [19:08<01:28,  2.52s/it, acc=0.6689, loss=0.5497]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 456/490 [19:08<01:25,  2.52s/it, acc=0.6689, loss=0.5497]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 456/490 [19:11<01:25,  2.52s/it, acc=0.6690, loss=0.7863]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 457/490 [19:11<01:23,  2.52s/it, acc=0.6690, loss=0.7863]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 457/490 [19:13<01:23,  2.52s/it, acc=0.6689, loss=0.9690]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 458/490 [19:13<01:20,  2.51s/it, acc=0.6689, loss=0.9690]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 458/490 [19:16<01:20,  2.51s/it, acc=0.6688, loss=0.7179]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 459/490 [19:16<01:17,  2.51s/it, acc=0.6688, loss=0.7179]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 459/490 [19:18<01:17,  2.51s/it, acc=0.6692, loss=0.4236]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 460/490 [19:18<01:15,  2.51s/it, acc=0.6692, loss=0.4236]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 460/490 [19:21<01:15,  2.51s/it, acc=0.6692, loss=0.7280]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 461/490 [19:21<01:12,  2.51s/it, acc=0.6692, loss=0.7280]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 461/490 [19:23<01:12,  2.51s/it, acc=0.6693, loss=0.7323]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 462/490 [19:23<01:10,  2.51s/it, acc=0.6693, loss=0.7323]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 462/490 [19:26<01:10,  2.51s/it, acc=0.6695, loss=0.6818]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 463/490 [19:26<01:07,  2.51s/it, acc=0.6695, loss=0.6818]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 463/490 [19:28<01:07,  2.51s/it, acc=0.6698, loss=0.5088]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 464/490 [19:28<01:05,  2.51s/it, acc=0.6698, loss=0.5088]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 464/490 [19:31<01:05,  2.51s/it, acc=0.6699, loss=0.6460]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 465/490 [19:31<01:02,  2.52s/it, acc=0.6699, loss=0.6460]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 465/490 [19:33<01:02,  2.52s/it, acc=0.6701, loss=0.5696]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 466/490 [19:33<01:00,  2.52s/it, acc=0.6701, loss=0.5696]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 466/490 [19:36<01:00,  2.52s/it, acc=0.6705, loss=0.4831]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 467/490 [19:36<00:57,  2.52s/it, acc=0.6705, loss=0.4831]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 467/490 [19:38<00:57,  2.52s/it, acc=0.6710, loss=0.3877]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 468/490 [19:38<00:55,  2.52s/it, acc=0.6710, loss=0.3877]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 468/490 [19:41<00:55,  2.52s/it, acc=0.6713, loss=0.5077]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 469/490 [19:41<00:52,  2.52s/it, acc=0.6713, loss=0.5077]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 469/490 [19:43<00:52,  2.52s/it, acc=0.6716, loss=0.5850]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 470/490 [19:43<00:50,  2.52s/it, acc=0.6716, loss=0.5850]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 470/490 [19:46<00:50,  2.52s/it, acc=0.6717, loss=0.7287]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 471/490 [19:46<00:47,  2.52s/it, acc=0.6717, loss=0.7287]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 471/490 [19:48<00:47,  2.52s/it, acc=0.6718, loss=0.5875]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 472/490 [19:48<00:45,  2.52s/it, acc=0.6718, loss=0.5875]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 472/490 [19:51<00:45,  2.52s/it, acc=0.6718, loss=0.7648]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 473/490 [19:51<00:42,  2.52s/it, acc=0.6718, loss=0.7648]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 473/490 [19:53<00:42,  2.52s/it, acc=0.6717, loss=0.8760]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 474/490 [19:53<00:40,  2.52s/it, acc=0.6717, loss=0.8760]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 474/490 [19:56<00:40,  2.52s/it, acc=0.6716, loss=0.7337]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 475/490 [19:56<00:37,  2.52s/it, acc=0.6716, loss=0.7337]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 475/490 [19:58<00:37,  2.52s/it, acc=0.6715, loss=0.9952]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 476/490 [19:58<00:35,  2.51s/it, acc=0.6715, loss=0.9952]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 476/490 [20:01<00:35,  2.51s/it, acc=0.6718, loss=0.6319]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 477/490 [20:01<00:32,  2.51s/it, acc=0.6718, loss=0.6319]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 477/490 [20:03<00:32,  2.51s/it, acc=0.6719, loss=0.8494]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 478/490 [20:03<00:30,  2.51s/it, acc=0.6719, loss=0.8494]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 478/490 [20:06<00:30,  2.51s/it, acc=0.6719, loss=0.7073]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 479/490 [20:06<00:27,  2.51s/it, acc=0.6719, loss=0.7073]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 479/490 [20:08<00:27,  2.51s/it, acc=0.6721, loss=0.6012]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 480/490 [20:08<00:25,  2.51s/it, acc=0.6721, loss=0.6012]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 480/490 [20:11<00:25,  2.51s/it, acc=0.6724, loss=0.4713]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 481/490 [20:11<00:22,  2.51s/it, acc=0.6724, loss=0.4713]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 481/490 [20:14<00:22,  2.51s/it, acc=0.6725, loss=0.8165]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 482/490 [20:14<00:20,  2.51s/it, acc=0.6725, loss=0.8165]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 482/490 [20:16<00:20,  2.51s/it, acc=0.6723, loss=0.9640]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 483/490 [20:16<00:17,  2.51s/it, acc=0.6723, loss=0.9640]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 483/490 [20:19<00:17,  2.51s/it, acc=0.6728, loss=0.3633]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 484/490 [20:19<00:15,  2.51s/it, acc=0.6728, loss=0.3633]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 484/490 [20:21<00:15,  2.51s/it, acc=0.6729, loss=0.6377]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 485/490 [20:21<00:12,  2.52s/it, acc=0.6729, loss=0.6377]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 485/490 [20:24<00:12,  2.52s/it, acc=0.6732, loss=0.4346]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 486/490 [20:24<00:10,  2.52s/it, acc=0.6732, loss=0.4346]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 486/490 [20:26<00:10,  2.52s/it, acc=0.6734, loss=0.7229]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 487/490 [20:26<00:07,  2.52s/it, acc=0.6734, loss=0.7229]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 487/490 [20:29<00:07,  2.52s/it, acc=0.6735, loss=0.5573]\n",
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 488/490 [20:29<00:05,  2.52s/it, acc=0.6735, loss=0.5573]\n",
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 488/490 [20:31<00:05,  2.52s/it, acc=0.6734, loss=0.9914]\n",
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 489/490 [20:31<00:02,  2.52s/it, acc=0.6734, loss=0.9914]\n",
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 489/490 [20:33<00:02,  2.52s/it, acc=0.6736, loss=0.6718]\n",
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 490/490 [20:33<00:00,  2.18s/it, acc=0.6736, loss=0.6718]\n",
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 490/490 [20:33<00:00,  2.52s/it, acc=0.6736, loss=0.6718]\n",
            "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2956: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "Train Acc: 0.6736, Top-3 Acc: 0.9003, Log Loss: 0.8971\n",
            "[METRICS] epoch=0 train_loss=0.8971 train_acc=0.6736\n",
            "  Top-3 Accuracy: 0.9003\n",
            "  Log Loss: 0.8971\n",
            "  Macro Avg    - F1: 0.6799, Precision: 0.6892, Recall: 0.6732\n",
            "  Weighted Avg - F1: 0.6742, Precision: 0.6767, Recall: 0.6736\n",
            "  Per-Class F1 Scores:\n",
            "    antelope_duiker     : F1=0.5787, Confidence=0.6315\n",
            "    bird                : F1=0.6671, Confidence=0.6967\n",
            "blank               : F1=0.4820, Confidence=0.5091\n",
            "    civet_genet         : F1=0.8259, Confidence=0.7945\n",
            "    hog                 : F1=0.7716, Confidence=0.7991\n",
            "    leopard             : F1=0.8443, Confidence=0.8411\n",
            "    monkey_prosimian    : F1=0.6441, Confidence=0.6486\n",
            "    rodent              : F1=0.6253, Confidence=0.6328\n",
            "After training GPU memory - Allocated: 3017.58 MB, Reserved: 13962.00 MB\n",
            "Validating:   0%|          | 0/26 [00:00<?, ?it/s]\n",
            "Validating:   0%|          | 0/26 [00:01<?, ?it/s, acc=0.8438, loss=0.5194]\n",
            "Validating:   4%|‚ñç         | 1/26 [00:01<00:27,  1.11s/it, acc=0.8438, loss=0.5194]\n",
            "Validating:   4%|‚ñç         | 1/26 [00:01<00:27,  1.11s/it, acc=0.7969, loss=0.7203]\n",
            "Validating:   8%|‚ñä         | 2/26 [00:01<00:22,  1.07it/s, acc=0.7969, loss=0.7203]\n",
            "Validating:   8%|‚ñä         | 2/26 [00:02<00:22,  1.07it/s, acc=0.8229, loss=0.4379]\n",
            "Validating:  12%|‚ñà‚ñè        | 3/26 [00:02<00:20,  1.14it/s, acc=0.8229, loss=0.4379]\n",
            "Validating:  12%|‚ñà‚ñè        | 3/26 [00:03<00:20,  1.14it/s, acc=0.8281, loss=0.4951]\n",
            "Validating:  15%|‚ñà‚ñå        | 4/26 [00:03<00:18,  1.17it/s, acc=0.8281, loss=0.4951]\n",
            "Validating:  15%|‚ñà‚ñå        | 4/26 [00:04<00:18,  1.17it/s, acc=0.8313, loss=0.6835]\n",
            "Validating:  19%|‚ñà‚ñâ        | 5/26 [00:04<00:17,  1.19it/s, acc=0.8313, loss=0.6835]\n",
            "Validating:  19%|‚ñà‚ñâ        | 5/26 [00:05<00:17,  1.19it/s, acc=0.8385, loss=0.4234]\n",
            "Validating:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:05<00:16,  1.20it/s, acc=0.8385, loss=0.4234]\n",
            "Validating:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:05<00:16,  1.20it/s, acc=0.8482, loss=0.3531]\n",
            "Validating:  27%|‚ñà‚ñà‚ñã       | 7/26 [00:05<00:15,  1.21it/s, acc=0.8482, loss=0.3531]\n",
            "Validating:  27%|‚ñà‚ñà‚ñã       | 7/26 [00:06<00:15,  1.21it/s, acc=0.8477, loss=0.5124]\n",
            "Validating:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:06<00:14,  1.22it/s, acc=0.8477, loss=0.5124]\n",
            "Validating:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:07<00:14,  1.22it/s, acc=0.8438, loss=0.6779]\n",
            "Validating:  35%|‚ñà‚ñà‚ñà‚ñç      | 9/26 [00:07<00:13,  1.22it/s, acc=0.8438, loss=0.6779]\n",
            "Validating:  35%|‚ñà‚ñà‚ñà‚ñç      | 9/26 [00:08<00:13,  1.22it/s, acc=0.8250, loss=0.7996]\n",
            "Validating:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:08<00:13,  1.22it/s, acc=0.8250, loss=0.7996]\n",
            "Validating:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:09<00:13,  1.22it/s, acc=0.8210, loss=0.6217]\n",
            "Validating:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 11/26 [00:09<00:12,  1.22it/s, acc=0.8210, loss=0.6217]\n",
            "Validating:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 11/26 [00:10<00:12,  1.22it/s, acc=0.8229, loss=0.3652]\n",
            "Validating:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:10<00:11,  1.22it/s, acc=0.8229, loss=0.3652]\n",
            "Validating:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:10<00:11,  1.22it/s, acc=0.8269, loss=0.4289]\n",
            "Validating:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 13/26 [00:10<00:10,  1.22it/s, acc=0.8269, loss=0.4289]\n",
            "Validating:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 13/26 [00:11<00:10,  1.22it/s, acc=0.8326, loss=0.2117]\n",
            "Validating:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:11<00:09,  1.22it/s, acc=0.8326, loss=0.2117]\n",
            "Validating:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:12<00:09,  1.22it/s, acc=0.8313, loss=0.4712]\n",
            "Validating:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 15/26 [00:12<00:08,  1.22it/s, acc=0.8313, loss=0.4712]\n",
            "Validating:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 15/26 [00:13<00:08,  1.22it/s, acc=0.8301, loss=0.6484]\n",
            "Validating:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:13<00:08,  1.22it/s, acc=0.8301, loss=0.6484]\n",
            "Validating:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:14<00:08,  1.22it/s, acc=0.8272, loss=0.5230]\n",
            "Validating:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 17/26 [00:14<00:07,  1.22it/s, acc=0.8272, loss=0.5230]\n",
            "Validating:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 17/26 [00:14<00:07,  1.22it/s, acc=0.8299, loss=0.5999]\n",
            "Validating:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:14<00:06,  1.22it/s, acc=0.8299, loss=0.5999]\n",
            "Validating:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:15<00:06,  1.22it/s, acc=0.8306, loss=0.5842]\n",
            "Validating:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 19/26 [00:15<00:05,  1.22it/s, acc=0.8306, loss=0.5842]\n",
            "Validating:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 19/26 [00:16<00:05,  1.22it/s, acc=0.8281, loss=0.5682]\n",
            "Validating:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:16<00:04,  1.22it/s, acc=0.8281, loss=0.5682]\n",
            "Validating:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:17<00:04,  1.22it/s, acc=0.8304, loss=0.3951]\n",
            "Validating:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 21/26 [00:17<00:04,  1.22it/s, acc=0.8304, loss=0.3951]\n",
            "Validating:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 21/26 [00:18<00:04,  1.22it/s, acc=0.8281, loss=0.3812]\n",
            "Validating:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:18<00:03,  1.22it/s, acc=0.8281, loss=0.3812]\n",
            "Validating:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:19<00:03,  1.22it/s, acc=0.8274, loss=0.5753]\n",
            "Validating:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 23/26 [00:19<00:02,  1.22it/s, acc=0.8274, loss=0.5753]\n",
            "Validating:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 23/26 [00:19<00:02,  1.22it/s, acc=0.8229, loss=0.6581]\n",
            "Validating:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:19<00:01,  1.22it/s, acc=0.8229, loss=0.6581]\n",
            "Validating:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:20<00:01,  1.22it/s, acc=0.8263, loss=0.4908]\n",
            "Validating:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 25/26 [00:20<00:00,  1.22it/s, acc=0.8263, loss=0.4908]\n",
            "Validating:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 25/26 [00:21<00:00,  1.22it/s, acc=0.8267, loss=0.6218]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [00:21<00:00,  1.30it/s, acc=0.8267, loss=0.6218]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [00:21<00:00,  1.22it/s, acc=0.8267, loss=0.6218]\n",
            "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2956: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "Validation Loss: 0.5287, Validation Acc: 0.8267, Top-3 Acc: 0.9576, Log Loss: 0.5287\n",
            "[METRICS] epoch=0 val_loss=0.5287 val_acc=0.8267\n",
            "  Top-3 Accuracy: 0.9576\n",
            "Log Loss: 0.5287\n",
            "  Macro Avg    - F1: 0.8328, Precision: 0.8460, Recall: 0.8298\n",
            "  Weighted Avg - F1: 0.8261, Precision: 0.8354, Recall: 0.8267\n",
            "  Per-Class F1 Scores:\n",
            "antelope_duiker     : F1=0.7819, Confidence=0.7454\n",
            "    bird                : F1=0.8625, Confidence=0.8867\n",
            "    blank               : F1=0.6802, Confidence=0.5970\n",
            "    civet_genet         : F1=0.9134, Confidence=0.9254\n",
            "    hog                 : F1=0.9231, Confidence=0.9496\n",
            "    leopard             : F1=0.9558, Confidence=0.9320\n",
            "    monkey_prosimian    : F1=0.8067, Confidence=0.8086\n",
            "    rodent              : F1=0.7386, Confidence=0.7270\n",
            "Learning Rate: 0.000100 ‚Üí 0.000098\n",
            "After validation GPU memory - Allocated: 3017.58 MB, Reserved: 14662.00 MB\n",
            "Saving best model to convnext-largeWeights_0_best.pth with val acc 0.8267\n",
            "‚úì Best model saved! (Val Acc: 0.8267), path: /opt/ml/model/convnext-largeWeights_0_best.pth\n",
            "Saving metrics to /opt/ml/model\n",
            "‚úì Metrics saved to /opt/ml/model\n",
            "  - /opt/ml/model/train_metrics_0.json\n",
            "  Total epochs logged: 1\n",
            "Saving metrics to /opt/ml/model\n",
            "‚úì Metrics saved to /opt/ml/model\n",
            "  - /opt/ml/model/val_metrics_0.json\n",
            "  Total epochs logged: 1\n",
            "Epoch 2/10\n",
            "Start of epoch GPU memory - Allocated: 3017.58 MB, Reserved: 3824.00 MB\n",
            "Training...\n",
            "Training:   0%|          | 0/490 [00:00<?, ?it/s]\n",
            "Training:   0%|          | 0/490 [00:02<?, ?it/s, acc=0.7812, loss=0.6041]\n",
            "Training:   0%|          | 1/490 [00:02<23:54,  2.93s/it, acc=0.7812, loss=0.6041]\n",
            "Training:   0%|          | 1/490 [00:05<23:54,  2.93s/it, acc=0.7656, loss=0.6301]\n",
            "Training:   0%|          | 2/490 [00:05<21:49,  2.68s/it, acc=0.7656, loss=0.6301]\n",
            "Training:   0%|          | 2/490 [00:07<21:49,  2.68s/it, acc=0.7292, loss=0.9132]\n",
            "Training:   1%|          | 3/490 [00:07<21:09,  2.61s/it, acc=0.7292, loss=0.9132]\n",
            "Training:   1%|          | 3/490 [00:10<21:09,  2.61s/it, acc=0.7656, loss=0.4353]\n",
            "Training:   1%|          | 4/490 [00:10<20:48,  2.57s/it, acc=0.7656, loss=0.4353]\n",
            "Training:   1%|          | 4/490 [00:12<20:48,  2.57s/it, acc=0.7625, loss=0.8393]\n",
            "Training:   1%|          | 5/490 [00:12<20:35,  2.55s/it, acc=0.7625, loss=0.8393]\n",
            "Training:   1%|          | 5/490 [00:15<20:35,  2.55s/it, acc=0.7656, loss=0.5708]\n",
            "Training:   1%|          | 6/490 [00:15<20:27,  2.54s/it, acc=0.7656, loss=0.5708]\n",
            "Training:   1%|          | 6/490 [00:17<20:27,  2.54s/it, acc=0.7857, loss=0.4372]\n",
            "Training:   1%|‚ñè         | 7/490 [00:17<20:19,  2.53s/it, acc=0.7857, loss=0.4372]\n",
            "Training:   1%|‚ñè         | 7/490 [00:20<20:19,  2.53s/it, acc=0.7891, loss=0.6585]\n",
            "Training:   2%|‚ñè         | 8/490 [00:20<20:15,  2.52s/it, acc=0.7891, loss=0.6585]\n",
            "Training:   2%|‚ñè         | 8/490 [00:23<20:15,  2.52s/it, acc=0.7882, loss=0.4997]\n",
            "Training:   2%|‚ñè         | 9/490 [00:23<20:11,  2.52s/it, acc=0.7882, loss=0.4997]\n",
            "Training:   2%|‚ñè         | 9/490 [00:25<20:11,  2.52s/it, acc=0.7781, loss=0.8675]\n",
            "Training:   2%|‚ñè         | 10/490 [00:25<20:08,  2.52s/it, acc=0.7781, loss=0.8675]\n",
            "Training:   2%|‚ñè         | 10/490 [00:28<20:08,  2.52s/it, acc=0.7812, loss=0.5510]\n",
            "Training:   2%|‚ñè         | 11/490 [00:28<20:04,  2.52s/it, acc=0.7812, loss=0.5510]\n",
            "Training:   2%|‚ñè         | 11/490 [00:30<20:04,  2.52s/it, acc=0.7708, loss=0.7667]\n",
            "Training:   2%|‚ñè         | 12/490 [00:30<20:02,  2.52s/it, acc=0.7708, loss=0.7667]\n",
            "Training:   2%|‚ñè         | 12/490 [00:33<20:02,  2.52s/it, acc=0.7812, loss=0.5010]\n",
            "Training:   3%|‚ñé         | 13/490 [00:33<20:01,  2.52s/it, acc=0.7812, loss=0.5010]\n",
            "Training:   3%|‚ñé         | 13/490 [00:35<20:01,  2.52s/it, acc=0.7746, loss=0.7768]\n",
            "Training:   3%|‚ñé         | 14/490 [00:35<19:59,  2.52s/it, acc=0.7746, loss=0.7768]\n",
            "Training:   3%|‚ñé         | 14/490 [00:38<19:59,  2.52s/it, acc=0.7688, loss=0.9330]\n",
            "Training:   3%|‚ñé         | 15/490 [00:38<19:56,  2.52s/it, acc=0.7688, loss=0.9330]\n",
            "Training:   3%|‚ñé         | 15/490 [00:40<19:56,  2.52s/it, acc=0.7754, loss=0.4983]\n",
            "Training:   3%|‚ñé         | 16/490 [00:40<19:53,  2.52s/it, acc=0.7754, loss=0.4983]\n",
            "Training:   3%|‚ñé         | 16/490 [00:43<19:53,  2.52s/it, acc=0.7794, loss=0.4716]\n",
            "Training:   3%|‚ñé         | 17/490 [00:43<19:50,  2.52s/it, acc=0.7794, loss=0.4716]\n",
            "Training:   3%|‚ñé         | 17/490 [00:45<19:50,  2.52s/it, acc=0.7760, loss=0.8210]\n",
            "Training:   4%|‚ñé         | 18/490 [00:45<19:48,  2.52s/it, acc=0.7760, loss=0.8210]\n",
            "Training:   4%|‚ñé         | 18/490 [00:48<19:48,  2.52s/it, acc=0.7763, loss=0.7752]\n",
            "Training:   4%|‚ñç         | 19/490 [00:48<19:47,  2.52s/it, acc=0.7763, loss=0.7752]\n",
            "Training:   4%|‚ñç         | 19/490 [00:50<19:47,  2.52s/it, acc=0.7797, loss=0.4688]\n",
            "Training:   4%|‚ñç         | 20/490 [00:50<19:45,  2.52s/it, acc=0.7797, loss=0.4688]\n",
            "Training:   4%|‚ñç         | 20/490 [00:53<19:45,  2.52s/it, acc=0.7783, loss=0.6446]\n",
            "Training:   4%|‚ñç         | 21/490 [00:53<19:41,  2.52s/it, acc=0.7783, loss=0.6446]\n",
            "Training:   4%|‚ñç         | 21/490 [00:55<19:41,  2.52s/it, acc=0.7812, loss=0.4232]\n",
            "Training:   4%|‚ñç         | 22/490 [00:55<19:39,  2.52s/it, acc=0.7812, loss=0.4232]\n",
            "Training:   4%|‚ñç         | 22/490 [00:58<19:39,  2.52s/it, acc=0.7880, loss=0.3949]\n",
            "Training:   5%|‚ñç         | 23/490 [00:58<19:37,  2.52s/it, acc=0.7880, loss=0.3949]\n",
            "Training:   5%|‚ñç         | 23/490 [01:00<19:37,  2.52s/it, acc=0.7878, loss=0.7143]\n",
            "Training:   5%|‚ñç         | 24/490 [01:00<19:35,  2.52s/it, acc=0.7878, loss=0.7143]\n",
            "Training:   5%|‚ñç         | 24/490 [01:03<19:35,  2.52s/it, acc=0.7837, loss=0.5972]\n",
            "Training:   5%|‚ñå         | 25/490 [01:03<19:33,  2.52s/it, acc=0.7837, loss=0.5972]\n",
            "Training:   5%|‚ñå         | 25/490 [01:05<19:33,  2.52s/it, acc=0.7885, loss=0.2995]\n",
            "Training:   5%|‚ñå         | 26/490 [01:05<19:30,  2.52s/it, acc=0.7885, loss=0.2995]\n",
            "Training:   5%|‚ñå         | 26/490 [01:08<19:30,  2.52s/it, acc=0.7905, loss=0.3687]\n",
            "Training:   6%|‚ñå         | 27/490 [01:08<19:27,  2.52s/it, acc=0.7905, loss=0.3687]\n",
            "Training:   6%|‚ñå         | 27/490 [01:10<19:27,  2.52s/it, acc=0.7891, loss=0.7505]\n",
            "Training:   6%|‚ñå         | 28/490 [01:10<19:25,  2.52s/it, acc=0.7891, loss=0.7505]\n",
            "Training:   6%|‚ñå         | 28/490 [01:13<19:25,  2.52s/it, acc=0.7899, loss=0.7298]\n",
            "Training:   6%|‚ñå         | 29/490 [01:13<19:22,  2.52s/it, acc=0.7899, loss=0.7298]\n",
            "Training:   6%|‚ñå         | 29/490 [01:15<19:22,  2.52s/it, acc=0.7917, loss=0.4541]\n",
            "Training:   6%|‚ñå         | 30/490 [01:15<19:20,  2.52s/it, acc=0.7917, loss=0.4541]\n",
            "Training:   6%|‚ñå         | 30/490 [01:18<19:20,  2.52s/it, acc=0.7933, loss=0.5832]\n",
            "Training:   6%|‚ñã         | 31/490 [01:18<19:16,  2.52s/it, acc=0.7933, loss=0.5832]\n",
            "Training:   6%|‚ñã         | 31/490 [01:20<19:16,  2.52s/it, acc=0.7900, loss=0.7228]\n",
            "Training:   7%|‚ñã         | 32/490 [01:20<19:13,  2.52s/it, acc=0.7900, loss=0.7228]\n",
            "Training:   7%|‚ñã         | 32/490 [01:23<19:13,  2.52s/it, acc=0.7926, loss=0.4253]\n",
            "Training:   7%|‚ñã         | 33/490 [01:23<19:11,  2.52s/it, acc=0.7926, loss=0.4253]\n",
            "Training:   7%|‚ñã         | 33/490 [01:26<19:11,  2.52s/it, acc=0.7904, loss=0.7998]\n",
            "Training:   7%|‚ñã         | 34/490 [01:26<19:10,  2.52s/it, acc=0.7904, loss=0.7998]\n",
            "Training:   7%|‚ñã         | 34/490 [01:28<19:10,  2.52s/it, acc=0.7937, loss=0.2812]\n",
            "Training:   7%|‚ñã         | 35/490 [01:28<19:08,  2.52s/it, acc=0.7937, loss=0.2812]\n",
            "Training:   7%|‚ñã         | 35/490 [01:31<19:08,  2.52s/it, acc=0.7960, loss=0.3959]\n",
            "Training:   7%|‚ñã         | 36/490 [01:31<19:04,  2.52s/it, acc=0.7960, loss=0.3959]\n",
            "Training:   7%|‚ñã         | 36/490 [01:33<19:04,  2.52s/it, acc=0.7981, loss=0.3641]\n",
            "Training:   8%|‚ñä         | 37/490 [01:33<19:03,  2.52s/it, acc=0.7981, loss=0.3641]\n",
            "Training:   8%|‚ñä         | 37/490 [01:36<19:03,  2.52s/it, acc=0.7985, loss=0.7810]\n",
            "Training:   8%|‚ñä         | 38/490 [01:36<19:00,  2.52s/it, acc=0.7985, loss=0.7810]\n",
            "Training:   8%|‚ñä         | 38/490 [01:38<19:00,  2.52s/it, acc=0.7981, loss=0.6117]\n",
            "Training:   8%|‚ñä         | 39/490 [01:38<18:58,  2.53s/it, acc=0.7981, loss=0.6117]\n",
            "Training:   8%|‚ñä         | 39/490 [01:41<18:58,  2.53s/it, acc=0.7992, loss=0.4633]\n",
            "Training:   8%|‚ñä         | 40/490 [01:41<18:55,  2.52s/it, acc=0.7992, loss=0.4633]\n",
            "Training:   8%|‚ñä         | 40/490 [01:43<18:55,  2.52s/it, acc=0.7965, loss=0.9837]\n",
            "Training:   8%|‚ñä         | 41/490 [01:43<18:53,  2.53s/it, acc=0.7965, loss=0.9837]\n",
            "Training:   8%|‚ñä         | 41/490 [01:46<18:53,  2.53s/it, acc=0.7976, loss=0.4381]\n",
            "Training:   9%|‚ñä         | 42/490 [01:46<18:51,  2.52s/it, acc=0.7976, loss=0.4381]\n",
            "Training:   9%|‚ñä         | 42/490 [01:48<18:51,  2.52s/it, acc=0.7994, loss=0.5857]\n",
            "Training:   9%|‚ñâ         | 43/490 [01:48<18:49,  2.53s/it, acc=0.7994, loss=0.5857]\n",
            "Training:   9%|‚ñâ         | 43/490 [01:51<18:49,  2.53s/it, acc=0.8011, loss=0.3422]\n",
            "Training:   9%|‚ñâ         | 44/490 [01:51<18:45,  2.52s/it, acc=0.8011, loss=0.3422]\n",
            "Training:   9%|‚ñâ         | 44/490 [01:53<18:45,  2.52s/it, acc=0.7986, loss=0.8798]\n",
            "Training:   9%|‚ñâ         | 45/490 [01:53<18:43,  2.52s/it, acc=0.7986, loss=0.8798]\n",
            "Training:   9%|‚ñâ         | 45/490 [01:56<18:43,  2.52s/it, acc=0.7976, loss=0.7950]\n",
            "Training:   9%|‚ñâ         | 46/490 [01:56<18:41,  2.52s/it, acc=0.7976, loss=0.7950]\n",
            "Training:   9%|‚ñâ         | 46/490 [01:58<18:41,  2.52s/it, acc=0.7959, loss=0.8016]\n",
            "Training:  10%|‚ñâ         | 47/490 [01:58<18:37,  2.52s/it, acc=0.7959, loss=0.8016]\n",
            "Training:  10%|‚ñâ         | 47/490 [02:01<18:37,  2.52s/it, acc=0.7988, loss=0.2599]\n",
            "Training:  10%|‚ñâ         | 48/490 [02:01<18:34,  2.52s/it, acc=0.7988, loss=0.2599]\n",
            "Training:  10%|‚ñâ         | 48/490 [02:03<18:34,  2.52s/it, acc=0.8004, loss=0.4434]\n",
            "Training:  10%|‚ñà         | 49/490 [02:03<18:32,  2.52s/it, acc=0.8004, loss=0.4434]\n",
            "Training:  10%|‚ñà         | 49/490 [02:06<18:32,  2.52s/it, acc=0.8013, loss=0.5434]\n",
            "Training:  10%|‚ñà         | 50/490 [02:06<18:30,  2.52s/it, acc=0.8013, loss=0.5434]\n",
            "Training:  10%|‚ñà         | 50/490 [02:08<18:30,  2.52s/it, acc=0.8015, loss=0.4726]\n",
            "Training:  10%|‚ñà         | 51/490 [02:08<18:28,  2.52s/it, acc=0.8015, loss=0.4726]\n",
            "Training:  10%|‚ñà         | 51/490 [02:11<18:28,  2.52s/it, acc=0.8029, loss=0.4393]\n",
            "Training:  11%|‚ñà         | 52/490 [02:11<18:25,  2.52s/it, acc=0.8029, loss=0.4393]\n",
            "Training:  11%|‚ñà         | 52/490 [02:13<18:25,  2.52s/it, acc=0.8048, loss=0.4368]\n",
            "Training:  11%|‚ñà         | 53/490 [02:13<18:23,  2.53s/it, acc=0.8048, loss=0.4368]\n",
            "Training:  11%|‚ñà         | 53/490 [02:16<18:23,  2.53s/it, acc=0.8073, loss=0.3297]\n",
            "Training:  11%|‚ñà         | 54/490 [02:16<18:21,  2.53s/it, acc=0.8073, loss=0.3297]\n",
            "Training:  11%|‚ñà         | 54/490 [02:19<18:21,  2.53s/it, acc=0.8068, loss=0.7390]\n",
            "Training:  11%|‚ñà         | 55/490 [02:19<18:18,  2.52s/it, acc=0.8068, loss=0.7390]\n",
            "Training:  11%|‚ñà         | 55/490 [02:21<18:18,  2.52s/it, acc=0.8075, loss=0.4633]\n",
            "Training:  11%|‚ñà‚ñè        | 56/490 [02:21<18:14,  2.52s/it, acc=0.8075, loss=0.4633]\n",
            "Training:  11%|‚ñà‚ñè        | 56/490 [02:24<18:14,  2.52s/it, acc=0.8081, loss=0.5167]\n",
            "Training:  12%|‚ñà‚ñè        | 57/490 [02:24<18:12,  2.52s/it, acc=0.8081, loss=0.5167]\n",
            "Training:  12%|‚ñà‚ñè        | 57/490 [02:26<18:12,  2.52s/it, acc=0.8098, loss=0.3349]\n",
            "Training:  12%|‚ñà‚ñè        | 58/490 [02:26<18:09,  2.52s/it, acc=0.8098, loss=0.3349]\n",
            "Training:  12%|‚ñà‚ñè        | 58/490 [02:29<18:09,  2.52s/it, acc=0.8104, loss=0.3555]\n",
            "Training:  12%|‚ñà‚ñè        | 59/490 [02:29<18:08,  2.52s/it, acc=0.8104, loss=0.3555]\n",
            "Training:  12%|‚ñà‚ñè        | 59/490 [02:31<18:08,  2.52s/it, acc=0.8104, loss=0.5643]\n",
            "Training:  12%|‚ñà‚ñè        | 60/490 [02:31<18:05,  2.53s/it, acc=0.8104, loss=0.5643]\n",
            "Training:  12%|‚ñà‚ñè        | 60/490 [02:34<18:05,  2.53s/it, acc=0.8115, loss=0.2756]\n",
            "Training:  12%|‚ñà‚ñè        | 61/490 [02:34<18:02,  2.52s/it, acc=0.8115, loss=0.2756]\n",
            "Training:  12%|‚ñà‚ñè        | 61/490 [02:36<18:02,  2.52s/it, acc=0.8105, loss=0.7287]\n",
            "Training:  13%|‚ñà‚ñé        | 62/490 [02:36<18:00,  2.52s/it, acc=0.8105, loss=0.7287]\n",
            "Training:  13%|‚ñà‚ñé        | 62/490 [02:39<18:00,  2.52s/it, acc=0.8100, loss=0.7536]\n",
            "Training:  13%|‚ñà‚ñé        | 63/490 [02:39<17:57,  2.52s/it, acc=0.8100, loss=0.7536]\n",
            "Training:  13%|‚ñà‚ñé        | 63/490 [02:41<17:57,  2.52s/it, acc=0.8076, loss=0.9035]\n",
            "Training:  13%|‚ñà‚ñé        | 64/490 [02:41<17:55,  2.52s/it, acc=0.8076, loss=0.9035]\n",
            "Training:  13%|‚ñà‚ñé        | 64/490 [02:44<17:55,  2.52s/it, acc=0.8077, loss=0.3867]\n",
            "Training:  13%|‚ñà‚ñé        | 65/490 [02:44<17:52,  2.52s/it, acc=0.8077, loss=0.3867]\n",
            "Training:  13%|‚ñà‚ñé        | 65/490 [02:46<17:52,  2.52s/it, acc=0.8073, loss=0.6169]\n",
            "Training:  13%|‚ñà‚ñé        | 66/490 [02:46<17:49,  2.52s/it, acc=0.8073, loss=0.6169]\n",
            "Training:  13%|‚ñà‚ñé        | 66/490 [02:49<17:49,  2.52s/it, acc=0.8050, loss=0.7479]\n",
            "Training:  14%|‚ñà‚ñé        | 67/490 [02:49<17:46,  2.52s/it, acc=0.8050, loss=0.7479]\n",
            "Training:  14%|‚ñà‚ñé        | 67/490 [02:51<17:46,  2.52s/it, acc=0.8047, loss=0.4840]\n",
            "Training:  14%|‚ñà‚ñç        | 68/490 [02:51<17:44,  2.52s/it, acc=0.8047, loss=0.4840]\n",
            "Training:  14%|‚ñà‚ñç        | 68/490 [02:54<17:44,  2.52s/it, acc=0.8048, loss=0.4888]\n",
            "Training:  14%|‚ñà‚ñç        | 69/490 [02:54<17:43,  2.53s/it, acc=0.8048, loss=0.4888]\n",
            "Training:  14%|‚ñà‚ñç        | 69/490 [02:56<17:43,  2.53s/it, acc=0.8049, loss=0.4999]\n",
            "Training:  14%|‚ñà‚ñç        | 70/490 [02:56<17:39,  2.52s/it, acc=0.8049, loss=0.4999]\n",
            "Training:  14%|‚ñà‚ñç        | 70/490 [02:59<17:39,  2.52s/it, acc=0.8050, loss=0.5455]\n",
            "Training:  14%|‚ñà‚ñç        | 71/490 [02:59<17:36,  2.52s/it, acc=0.8050, loss=0.5455]\n",
            "Training:  14%|‚ñà‚ñç        | 71/490 [03:01<17:36,  2.52s/it, acc=0.8047, loss=0.5964]\n",
            "Training:  15%|‚ñà‚ñç        | 72/490 [03:01<17:34,  2.52s/it, acc=0.8047, loss=0.5964]\n",
            "Training:  15%|‚ñà‚ñç        | 72/490 [03:04<17:34,  2.52s/it, acc=0.8061, loss=0.4117]\n",
            "Training:  15%|‚ñà‚ñç        | 73/490 [03:04<17:32,  2.52s/it, acc=0.8061, loss=0.4117]\n",
            "Training:  15%|‚ñà‚ñç        | 73/490 [03:06<17:32,  2.52s/it, acc=0.8074, loss=0.2772]\n",
            "Training:  15%|‚ñà‚ñå        | 74/490 [03:06<17:29,  2.52s/it, acc=0.8074, loss=0.2772]\n",
            "Training:  15%|‚ñà‚ñå        | 74/490 [03:09<17:29,  2.52s/it, acc=0.8087, loss=0.3300]\n",
            "Training:  15%|‚ñà‚ñå        | 75/490 [03:09<17:26,  2.52s/it, acc=0.8087, loss=0.3300]\n",
            "Training:  15%|‚ñà‚ñå        | 75/490 [03:12<17:26,  2.52s/it, acc=0.8076, loss=0.8451]\n",
            "Training:  16%|‚ñà‚ñå        | 76/490 [03:12<17:25,  2.52s/it, acc=0.8076, loss=0.8451]\n",
            "Training:  16%|‚ñà‚ñå        | 76/490 [03:14<17:25,  2.52s/it, acc=0.8064, loss=0.6715]\n",
            "Training:  16%|‚ñà‚ñå        | 77/490 [03:14<17:22,  2.52s/it, acc=0.8064, loss=0.6715]\n",
            "Training:  16%|‚ñà‚ñå        | 77/490 [03:17<17:22,  2.52s/it, acc=0.8061, loss=0.6201]\n",
            "Training:  16%|‚ñà‚ñå        | 78/490 [03:17<17:19,  2.52s/it, acc=0.8061, loss=0.6201]\n",
            "Training:  16%|‚ñà‚ñå        | 78/490 [03:19<17:19,  2.52s/it, acc=0.8062, loss=0.6726]\n",
            "Training:  16%|‚ñà‚ñå        | 79/490 [03:19<17:16,  2.52s/it, acc=0.8062, loss=0.6726]\n",
            "Training:  16%|‚ñà‚ñå        | 79/490 [03:22<17:16,  2.52s/it, acc=0.8059, loss=0.4460]\n",
            "Training:  16%|‚ñà‚ñã        | 80/490 [03:22<17:14,  2.52s/it, acc=0.8059, loss=0.4460]\n",
            "Training:  16%|‚ñà‚ñã        | 80/490 [03:24<17:14,  2.52s/it, acc=0.8063, loss=0.5236]\n",
            "Training:  17%|‚ñà‚ñã        | 81/490 [03:24<17:11,  2.52s/it, acc=0.8063, loss=0.5236]\n",
            "Training:  17%|‚ñà‚ñã        | 81/490 [03:27<17:11,  2.52s/it, acc=0.8060, loss=0.6235]\n",
            "Training:  17%|‚ñà‚ñã        | 82/490 [03:27<17:09,  2.52s/it, acc=0.8060, loss=0.6235]\n",
            "Training:  17%|‚ñà‚ñã        | 82/490 [03:29<17:09,  2.52s/it, acc=0.8057, loss=0.6834]\n",
            "Training:  17%|‚ñà‚ñã        | 83/490 [03:29<17:06,  2.52s/it, acc=0.8057, loss=0.6834]\n",
            "Training:  17%|‚ñà‚ñã        | 83/490 [03:32<17:06,  2.52s/it, acc=0.8062, loss=0.4045]\n",
            "Training:  17%|‚ñà‚ñã        | 84/490 [03:32<17:03,  2.52s/it, acc=0.8062, loss=0.4045]\n",
            "Training:  17%|‚ñà‚ñã        | 84/490 [03:34<17:03,  2.52s/it, acc=0.8059, loss=0.5746]\n",
            "Training:  17%|‚ñà‚ñã        | 85/490 [03:34<17:01,  2.52s/it, acc=0.8059, loss=0.5746]\n",
            "Training:  17%|‚ñà‚ñã        | 85/490 [03:37<17:01,  2.52s/it, acc=0.8052, loss=0.9617]\n",
            "Training:  18%|‚ñà‚ñä        | 86/490 [03:37<16:58,  2.52s/it, acc=0.8052, loss=0.9617]\n",
            "Training:  18%|‚ñà‚ñä        | 86/490 [03:39<16:58,  2.52s/it, acc=0.8050, loss=0.5994]\n",
            "Training:  18%|‚ñà‚ñä        | 87/490 [03:39<16:56,  2.52s/it, acc=0.8050, loss=0.5994]\n",
            "Training:  18%|‚ñà‚ñä        | 87/490 [03:42<16:56,  2.52s/it, acc=0.8033, loss=0.6561]\n",
            "Training:  18%|‚ñà‚ñä        | 88/490 [03:42<16:53,  2.52s/it, acc=0.8033, loss=0.6561]\n",
            "Training:  18%|‚ñà‚ñä        | 88/490 [03:44<16:53,  2.52s/it, acc=0.8030, loss=0.4798]\n",
            "Training:  18%|‚ñà‚ñä        | 89/490 [03:44<16:51,  2.52s/it, acc=0.8030, loss=0.4798]\n",
            "Training:  18%|‚ñà‚ñä        | 89/490 [03:47<16:51,  2.52s/it, acc=0.8014, loss=0.7943]\n",
            "Training:  18%|‚ñà‚ñä        | 90/490 [03:47<16:49,  2.52s/it, acc=0.8014, loss=0.7943]\n",
            "Training:  18%|‚ñà‚ñä        | 90/490 [03:49<16:49,  2.52s/it, acc=0.8012, loss=0.4552]\n",
            "Training:  19%|‚ñà‚ñä        | 91/490 [03:49<16:47,  2.52s/it, acc=0.8012, loss=0.4552]\n",
            "Training:  19%|‚ñà‚ñä        | 91/490 [03:52<16:47,  2.52s/it, acc=0.8016, loss=0.3868]\n",
            "Training:  19%|‚ñà‚ñâ        | 92/490 [03:52<16:43,  2.52s/it, acc=0.8016, loss=0.3868]\n",
            "Training:  19%|‚ñà‚ñâ        | 92/490 [03:54<16:43,  2.52s/it, acc=0.8024, loss=0.4333]\n",
            "Training:  19%|‚ñà‚ñâ        | 93/490 [03:54<16:40,  2.52s/it, acc=0.8024, loss=0.4333]\n",
            "Training:  19%|‚ñà‚ñâ        | 93/490 [03:57<16:40,  2.52s/it, acc=0.8025, loss=0.4809]\n",
            "Training:  19%|‚ñà‚ñâ        | 94/490 [03:57<16:38,  2.52s/it, acc=0.8025, loss=0.4809]\n",
            "Training:  19%|‚ñà‚ñâ        | 94/490 [03:59<16:38,  2.52s/it, acc=0.8033, loss=0.4361]\n",
            "Training:  19%|‚ñà‚ñâ        | 95/490 [03:59<16:35,  2.52s/it, acc=0.8033, loss=0.4361]\n",
            "Training:  19%|‚ñà‚ñâ        | 95/490 [04:02<16:35,  2.52s/it, acc=0.8040, loss=0.3917]\n",
            "Training:  20%|‚ñà‚ñâ        | 96/490 [04:02<16:33,  2.52s/it, acc=0.8040, loss=0.3917]\n",
            "Training:  20%|‚ñà‚ñâ        | 96/490 [04:04<16:33,  2.52s/it, acc=0.8035, loss=0.6706]\n",
            "Training:  20%|‚ñà‚ñâ        | 97/490 [04:04<16:31,  2.52s/it, acc=0.8035, loss=0.6706]\n",
            "Training:  20%|‚ñà‚ñâ        | 97/490 [04:07<16:31,  2.52s/it, acc=0.8039, loss=0.5255]\n",
            "Training:  20%|‚ñà‚ñà        | 98/490 [04:07<16:29,  2.52s/it, acc=0.8039, loss=0.5255]\n",
            "Training:  20%|‚ñà‚ñà        | 98/490 [04:10<16:29,  2.52s/it, acc=0.8040, loss=0.5015]\n",
            "Training:  20%|‚ñà‚ñà        | 99/490 [04:10<16:26,  2.52s/it, acc=0.8040, loss=0.5015]\n",
            "Training:  20%|‚ñà‚ñà        | 99/490 [04:12<16:26,  2.52s/it, acc=0.8041, loss=0.7356]\n",
            "Training:  20%|‚ñà‚ñà        | 100/490 [04:12<16:23,  2.52s/it, acc=0.8041, loss=0.7356]\n",
            "Training:  20%|‚ñà‚ñà        | 100/490 [04:15<16:23,  2.52s/it, acc=0.8038, loss=0.5972]\n",
            "Training:  21%|‚ñà‚ñà        | 101/490 [04:15<16:20,  2.52s/it, acc=0.8038, loss=0.5972]\n",
            "Training:  21%|‚ñà‚ñà        | 101/490 [04:17<16:20,  2.52s/it, acc=0.8036, loss=0.6381]\n",
            "Training:  21%|‚ñà‚ñà        | 102/490 [04:17<16:17,  2.52s/it, acc=0.8036, loss=0.6381]\n",
            "Training:  21%|‚ñà‚ñà        | 102/490 [04:20<16:17,  2.52s/it, acc=0.8040, loss=0.5058]\n",
            "Training:  21%|‚ñà‚ñà        | 103/490 [04:20<16:15,  2.52s/it, acc=0.8040, loss=0.5058]\n",
            "Training:  21%|‚ñà‚ñà        | 103/490 [04:22<16:15,  2.52s/it, acc=0.8041, loss=0.4749]\n",
            "Training:  21%|‚ñà‚ñà        | 104/490 [04:22<16:13,  2.52s/it, acc=0.8041, loss=0.4749]\n",
            "Training:  21%|‚ñà‚ñà        | 104/490 [04:25<16:13,  2.52s/it, acc=0.8045, loss=0.5533]\n",
            "Training:  21%|‚ñà‚ñà‚ñè       | 105/490 [04:25<16:10,  2.52s/it, acc=0.8045, loss=0.5533]\n",
            "Training:  21%|‚ñà‚ñà‚ñè       | 105/490 [04:27<16:10,  2.52s/it, acc=0.8045, loss=0.5218]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 106/490 [04:27<16:07,  2.52s/it, acc=0.8045, loss=0.5218]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 106/490 [04:30<16:07,  2.52s/it, acc=0.8046, loss=0.4775]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 107/490 [04:30<16:05,  2.52s/it, acc=0.8046, loss=0.4775]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 107/490 [04:32<16:05,  2.52s/it, acc=0.8050, loss=0.3059]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 108/490 [04:32<16:02,  2.52s/it, acc=0.8050, loss=0.3059]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 108/490 [04:35<16:02,  2.52s/it, acc=0.8059, loss=0.3897]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 109/490 [04:35<16:00,  2.52s/it, acc=0.8059, loss=0.3897]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 109/490 [04:37<16:00,  2.52s/it, acc=0.8043, loss=0.8204]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 110/490 [04:37<15:57,  2.52s/it, acc=0.8043, loss=0.8204]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 110/490 [04:40<15:57,  2.52s/it, acc=0.8038, loss=0.6287]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 111/490 [04:40<15:54,  2.52s/it, acc=0.8038, loss=0.6287]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 111/490 [04:42<15:54,  2.52s/it, acc=0.8036, loss=0.4707]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 112/490 [04:42<15:51,  2.52s/it, acc=0.8036, loss=0.4707]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 112/490 [04:45<15:51,  2.52s/it, acc=0.8028, loss=0.7132]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 113/490 [04:45<15:48,  2.52s/it, acc=0.8028, loss=0.7132]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 113/490 [04:47<15:48,  2.52s/it, acc=0.8024, loss=0.4844]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 114/490 [04:47<15:46,  2.52s/it, acc=0.8024, loss=0.4844]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 114/490 [04:50<15:46,  2.52s/it, acc=0.8027, loss=0.3421]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 115/490 [04:50<15:44,  2.52s/it, acc=0.8027, loss=0.3421]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 115/490 [04:52<15:44,  2.52s/it, acc=0.8031, loss=0.5204]\n",
            "Training:  24%|‚ñà‚ñà‚ñé       | 116/490 [04:52<15:42,  2.52s/it, acc=0.8031, loss=0.5204]\n",
            "Training:  24%|‚ñà‚ñà‚ñé       | 116/490 [04:55<15:42,  2.52s/it, acc=0.8024, loss=0.7087]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 117/490 [04:55<15:39,  2.52s/it, acc=0.8024, loss=0.7087]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 117/490 [04:57<15:39,  2.52s/it, acc=0.8016, loss=0.5797]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 118/490 [04:57<15:37,  2.52s/it, acc=0.8016, loss=0.5797]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 118/490 [05:00<15:37,  2.52s/it, acc=0.8025, loss=0.3249]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 119/490 [05:00<15:35,  2.52s/it, acc=0.8025, loss=0.3249]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 119/490 [05:02<15:35,  2.52s/it, acc=0.8010, loss=1.0852]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 120/490 [05:02<15:31,  2.52s/it, acc=0.8010, loss=1.0852]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 120/490 [05:05<15:31,  2.52s/it, acc=0.8017, loss=0.4593]\n",
            "Training:  25%|‚ñà‚ñà‚ñç       | 121/490 [05:05<15:30,  2.52s/it, acc=0.8017, loss=0.4593]\n",
            "Training:  25%|‚ñà‚ñà‚ñç       | 121/490 [05:07<15:30,  2.52s/it, acc=0.8012, loss=0.5455]\n",
            "Training:  25%|‚ñà‚ñà‚ñç       | 122/490 [05:07<15:27,  2.52s/it, acc=0.8012, loss=0.5455]\n",
            "Training:  25%|‚ñà‚ñà‚ñç       | 122/490 [05:10<15:27,  2.52s/it, acc=0.8018, loss=0.3838]\n",
            "Training:  25%|‚ñà‚ñà‚ñå       | 123/490 [05:10<15:25,  2.52s/it, acc=0.8018, loss=0.3838]\n",
            "Training:  25%|‚ñà‚ñà‚ñå       | 123/490 [05:13<15:25,  2.52s/it, acc=0.8017, loss=0.4826]\n",
            "Training:  25%|‚ñà‚ñà‚ñå       | 124/490 [05:13<15:23,  2.52s/it, acc=0.8017, loss=0.4826]\n",
            "Training:  25%|‚ñà‚ñà‚ñå       | 124/490 [05:15<15:23,  2.52s/it, acc=0.8013, loss=0.7901]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 125/490 [05:15<15:19,  2.52s/it, acc=0.8013, loss=0.7901]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 125/490 [05:18<15:19,  2.52s/it, acc=0.8018, loss=0.3081]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 126/490 [05:18<15:17,  2.52s/it, acc=0.8018, loss=0.3081]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 126/490 [05:20<15:17,  2.52s/it, acc=0.8022, loss=0.6336]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 127/490 [05:20<15:15,  2.52s/it, acc=0.8022, loss=0.6336]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 127/490 [05:23<15:15,  2.52s/it, acc=0.8025, loss=0.4804]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 128/490 [05:23<15:12,  2.52s/it, acc=0.8025, loss=0.4804]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 128/490 [05:25<15:12,  2.52s/it, acc=0.8018, loss=0.6163]\n",
            "Training:  26%|‚ñà‚ñà‚ñã       | 129/490 [05:25<15:09,  2.52s/it, acc=0.8018, loss=0.6163]\n",
            "Training:  26%|‚ñà‚ñà‚ñã       | 129/490 [05:28<15:09,  2.52s/it, acc=0.8019, loss=0.5441]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 130/490 [05:28<15:07,  2.52s/it, acc=0.8019, loss=0.5441]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 130/490 [05:30<15:07,  2.52s/it, acc=0.8018, loss=0.6258]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 131/490 [05:30<15:04,  2.52s/it, acc=0.8018, loss=0.6258]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 131/490 [05:33<15:04,  2.52s/it, acc=0.8018, loss=0.5321]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 132/490 [05:33<15:02,  2.52s/it, acc=0.8018, loss=0.5321]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 132/490 [05:35<15:02,  2.52s/it, acc=0.8017, loss=0.4629]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 133/490 [05:35<14:59,  2.52s/it, acc=0.8017, loss=0.4629]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 133/490 [05:38<14:59,  2.52s/it, acc=0.8018, loss=0.5853]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 134/490 [05:38<14:57,  2.52s/it, acc=0.8018, loss=0.5853]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 134/490 [05:40<14:57,  2.52s/it, acc=0.8021, loss=0.4684]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 135/490 [05:40<14:54,  2.52s/it, acc=0.8021, loss=0.4684]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 135/490 [05:43<14:54,  2.52s/it, acc=0.8019, loss=0.5536]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 136/490 [05:43<14:52,  2.52s/it, acc=0.8019, loss=0.5536]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 136/490 [05:45<14:52,  2.52s/it, acc=0.8025, loss=0.3905]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 137/490 [05:45<14:49,  2.52s/it, acc=0.8025, loss=0.3905]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 137/490 [05:48<14:49,  2.52s/it, acc=0.8025, loss=0.4721]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 138/490 [05:48<14:46,  2.52s/it, acc=0.8025, loss=0.4721]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 138/490 [05:50<14:46,  2.52s/it, acc=0.8024, loss=0.6419]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 139/490 [05:50<14:44,  2.52s/it, acc=0.8024, loss=0.6419]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 139/490 [05:53<14:44,  2.52s/it, acc=0.8025, loss=0.5381]\n",
            "Training:  29%|‚ñà‚ñà‚ñä       | 140/490 [05:53<14:41,  2.52s/it, acc=0.8025, loss=0.5381]\n",
            "Training:  29%|‚ñà‚ñà‚ñä       | 140/490 [05:55<14:41,  2.52s/it, acc=0.8025, loss=0.4046]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 141/490 [05:55<14:40,  2.52s/it, acc=0.8025, loss=0.4046]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 141/490 [05:58<14:40,  2.52s/it, acc=0.8028, loss=0.3893]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 142/490 [05:58<14:37,  2.52s/it, acc=0.8028, loss=0.3893]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 142/490 [06:00<14:37,  2.52s/it, acc=0.8024, loss=0.6529]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 143/490 [06:00<14:34,  2.52s/it, acc=0.8024, loss=0.6529]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 143/490 [06:03<14:34,  2.52s/it, acc=0.8021, loss=0.7411]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 144/490 [06:03<14:32,  2.52s/it, acc=0.8021, loss=0.7411]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 144/490 [06:05<14:32,  2.52s/it, acc=0.8026, loss=0.3621]\n",
            "Training:  30%|‚ñà‚ñà‚ñâ       | 145/490 [06:05<14:29,  2.52s/it, acc=0.8026, loss=0.3621]\n",
            "Training:  30%|‚ñà‚ñà‚ñâ       | 145/490 [06:08<14:29,  2.52s/it, acc=0.8024, loss=0.6422]\n",
            "Training:  30%|‚ñà‚ñà‚ñâ       | 146/490 [06:08<14:27,  2.52s/it, acc=0.8024, loss=0.6422]\n",
            "Training:  30%|‚ñà‚ñà‚ñâ       | 146/490 [06:11<14:27,  2.52s/it, acc=0.8019, loss=0.7413]\n",
            "Training:  30%|‚ñà‚ñà‚ñà       | 147/490 [06:11<14:24,  2.52s/it, acc=0.8019, loss=0.7413]\n",
            "Training:  30%|‚ñà‚ñà‚ñà       | 147/490 [06:13<14:24,  2.52s/it, acc=0.8015, loss=0.7304]\n",
            "Training:  30%|‚ñà‚ñà‚ñà       | 148/490 [06:13<14:21,  2.52s/it, acc=0.8015, loss=0.7304]\n",
            "Training:  30%|‚ñà‚ñà‚ñà       | 148/490 [06:16<14:21,  2.52s/it, acc=0.8008, loss=0.7050]\n",
            "Training:  30%|‚ñà‚ñà‚ñà       | 149/490 [06:16<14:19,  2.52s/it, acc=0.8008, loss=0.7050]\n",
            "Training:  30%|‚ñà‚ñà‚ñà       | 149/490 [06:18<14:19,  2.52s/it, acc=0.7998, loss=0.7381]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 150/490 [06:18<14:16,  2.52s/it, acc=0.7998, loss=0.7381]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 150/490 [06:21<14:16,  2.52s/it, acc=0.7993, loss=0.6811]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 151/490 [06:21<14:13,  2.52s/it, acc=0.7993, loss=0.6811]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 151/490 [06:23<14:13,  2.52s/it, acc=0.7993, loss=0.5336]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 152/490 [06:23<14:11,  2.52s/it, acc=0.7993, loss=0.5336]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 152/490 [06:26<14:11,  2.52s/it, acc=0.7996, loss=0.3653]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 153/490 [06:26<14:08,  2.52s/it, acc=0.7996, loss=0.3653]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 153/490 [06:28<14:08,  2.52s/it, acc=0.8001, loss=0.5125]\n",
            "Training:  31%|‚ñà‚ñà‚ñà‚ñè      | 154/490 [06:28<14:06,  2.52s/it, acc=0.8001, loss=0.5125]\n",
            "Training:  31%|‚ñà‚ñà‚ñà‚ñè      | 154/490 [06:31<14:06,  2.52s/it, acc=0.8000, loss=0.4330]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 155/490 [06:31<14:03,  2.52s/it, acc=0.8000, loss=0.4330]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 155/490 [06:33<14:03,  2.52s/it, acc=0.7997, loss=0.4856]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 156/490 [06:33<14:01,  2.52s/it, acc=0.7997, loss=0.4856]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 156/490 [06:36<14:01,  2.52s/it, acc=0.7994, loss=0.5735]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 157/490 [06:36<13:58,  2.52s/it, acc=0.7994, loss=0.5735]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 157/490 [06:38<13:58,  2.52s/it, acc=0.7992, loss=0.6706]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 158/490 [06:38<13:56,  2.52s/it, acc=0.7992, loss=0.6706]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 158/490 [06:41<13:56,  2.52s/it, acc=0.7995, loss=0.4953]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 159/490 [06:41<13:54,  2.52s/it, acc=0.7995, loss=0.4953]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 159/490 [06:43<13:54,  2.52s/it, acc=0.8000, loss=0.3658]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 160/490 [06:43<13:51,  2.52s/it, acc=0.8000, loss=0.3658]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 160/490 [06:46<13:51,  2.52s/it, acc=0.7997, loss=0.6567]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 161/490 [06:46<13:49,  2.52s/it, acc=0.7997, loss=0.6567]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 161/490 [06:48<13:49,  2.52s/it, acc=0.8002, loss=0.4240]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 162/490 [06:48<13:46,  2.52s/it, acc=0.8002, loss=0.4240]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 162/490 [06:51<13:46,  2.52s/it, acc=0.8006, loss=0.3326]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 163/490 [06:51<13:44,  2.52s/it, acc=0.8006, loss=0.3326]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 163/490 [06:53<13:44,  2.52s/it, acc=0.8007, loss=0.5064]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 164/490 [06:53<13:41,  2.52s/it, acc=0.8007, loss=0.5064]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 164/490 [06:56<13:41,  2.52s/it, acc=0.8009, loss=0.5378]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñé      | 165/490 [06:56<13:39,  2.52s/it, acc=0.8009, loss=0.5378]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñé      | 165/490 [06:58<13:39,  2.52s/it, acc=0.8010, loss=0.3965]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 166/490 [06:58<13:36,  2.52s/it, acc=0.8010, loss=0.3965]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 166/490 [07:01<13:36,  2.52s/it, acc=0.8013, loss=0.3368]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 167/490 [07:01<13:34,  2.52s/it, acc=0.8013, loss=0.3368]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 167/490 [07:03<13:34,  2.52s/it, acc=0.8006, loss=0.7349]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 168/490 [07:03<13:31,  2.52s/it, acc=0.8006, loss=0.7349]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 168/490 [07:06<13:31,  2.52s/it, acc=0.8009, loss=0.5633]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 169/490 [07:06<13:30,  2.52s/it, acc=0.8009, loss=0.5633]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 169/490 [07:08<13:30,  2.52s/it, acc=0.8007, loss=0.7619]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñç      | 170/490 [07:08<13:27,  2.52s/it, acc=0.8007, loss=0.7619]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñç      | 170/490 [07:11<13:27,  2.52s/it, acc=0.8001, loss=0.8011]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñç      | 171/490 [07:11<13:24,  2.52s/it, acc=0.8001, loss=0.8011]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñç      | 171/490 [07:14<13:24,  2.52s/it, acc=0.8000, loss=0.6666]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñå      | 172/490 [07:14<13:22,  2.52s/it, acc=0.8000, loss=0.6666]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñå      | 172/490 [07:16<13:22,  2.52s/it, acc=0.8004, loss=0.4996]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñå      | 173/490 [07:16<13:20,  2.52s/it, acc=0.8004, loss=0.4996]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñå      | 173/490 [07:19<13:20,  2.52s/it, acc=0.8005, loss=0.3316]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 174/490 [07:19<13:17,  2.52s/it, acc=0.8005, loss=0.3316]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 174/490 [07:21<13:17,  2.52s/it, acc=0.8004, loss=0.4349]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 175/490 [07:21<13:14,  2.52s/it, acc=0.8004, loss=0.4349]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 175/490 [07:24<13:14,  2.52s/it, acc=0.8011, loss=0.2934]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 176/490 [07:24<13:12,  2.52s/it, acc=0.8011, loss=0.2934]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 176/490 [07:26<13:12,  2.52s/it, acc=0.8014, loss=0.5853]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 177/490 [07:26<13:09,  2.52s/it, acc=0.8014, loss=0.5853]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 177/490 [07:29<13:09,  2.52s/it, acc=0.8013, loss=0.5204]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñã      | 178/490 [07:29<13:07,  2.52s/it, acc=0.8013, loss=0.5204]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñã      | 178/490 [07:31<13:07,  2.52s/it, acc=0.8019, loss=0.4977]#015Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 179/490 [07:31<13:05,  2.53s/it, acc=0.8019, loss=0.4977]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 179/490 [07:34<13:05,  2.53s/it, acc=0.8021, loss=0.4210]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 180/490 [07:34<13:02,  2.53s/it, acc=0.8021, loss=0.4210]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 180/490 [07:36<13:02,  2.53s/it, acc=0.8016, loss=0.5578]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 181/490 [07:36<12:59,  2.52s/it, acc=0.8016, loss=0.5578]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 181/490 [07:39<12:59,  2.52s/it, acc=0.8013, loss=0.7478]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 182/490 [07:39<12:57,  2.52s/it, acc=0.8013, loss=0.7478]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 182/490 [07:41<12:57,  2.52s/it, acc=0.8014, loss=0.7771]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 183/490 [07:41<12:54,  2.52s/it, acc=0.8014, loss=0.7771]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 183/490 [07:44<12:54,  2.52s/it, acc=0.8015, loss=0.6101]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 184/490 [07:44<12:52,  2.53s/it, acc=0.8015, loss=0.6101]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 184/490 [07:46<12:52,  2.53s/it, acc=0.8015, loss=0.5840]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 185/490 [07:46<12:51,  2.53s/it, acc=0.8015, loss=0.5840]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 185/490 [07:49<12:51,  2.53s/it, acc=0.8017, loss=0.6680]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 186/490 [07:49<12:48,  2.53s/it, acc=0.8017, loss=0.6680]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 186/490 [07:51<12:48,  2.53s/it, acc=0.8016, loss=0.3300]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 187/490 [07:51<12:45,  2.53s/it, acc=0.8016, loss=0.3300]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 187/490 [07:54<12:45,  2.53s/it, acc=0.8012, loss=0.5166]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 188/490 [07:54<12:43,  2.53s/it, acc=0.8012, loss=0.5166]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 188/490 [07:56<12:43,  2.53s/it, acc=0.8011, loss=0.5606]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñä      | 189/490 [07:56<12:41,  2.53s/it, acc=0.8011, loss=0.5606]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñä      | 189/490 [07:59<12:41,  2.53s/it, acc=0.8012, loss=0.5203]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 190/490 [07:59<12:38,  2.53s/it, acc=0.8012, loss=0.5203]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 190/490 [08:02<12:38,  2.53s/it, acc=0.8010, loss=0.7045]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 191/490 [08:02<12:35,  2.53s/it, acc=0.8010, loss=0.7045]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 191/490 [08:04<12:35,  2.53s/it, acc=0.8016, loss=0.3929]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 192/490 [08:04<12:32,  2.53s/it, acc=0.8016, loss=0.3929]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 192/490 [08:07<12:32,  2.53s/it, acc=0.8013, loss=0.5175]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 193/490 [08:07<12:30,  2.53s/it, acc=0.8013, loss=0.5175]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 193/490 [08:09<12:30,  2.53s/it, acc=0.8011, loss=0.5983]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñâ      | 194/490 [08:09<12:28,  2.53s/it, acc=0.8011, loss=0.5983]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñâ      | 194/490 [08:12<12:28,  2.53s/it, acc=0.8016, loss=0.3406]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñâ      | 195/490 [08:12<12:25,  2.53s/it, acc=0.8016, loss=0.3406]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñâ      | 195/490 [08:14<12:25,  2.53s/it, acc=0.8013, loss=0.7730]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñà      | 196/490 [08:14<12:22,  2.53s/it, acc=0.8013, loss=0.7730]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñà      | 196/490 [08:17<12:22,  2.53s/it, acc=0.8011, loss=0.7813]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñà      | 197/490 [08:17<12:20,  2.53s/it, acc=0.8011, loss=0.7813]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñà      | 197/490 [08:19<12:20,  2.53s/it, acc=0.8015, loss=0.4528]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñà      | 198/490 [08:19<12:18,  2.53s/it, acc=0.8015, loss=0.4528]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñà      | 198/490 [08:22<12:18,  2.53s/it, acc=0.8018, loss=0.4504]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 199/490 [08:22<12:16,  2.53s/it, acc=0.8018, loss=0.4504]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 199/490 [08:24<12:16,  2.53s/it, acc=0.8014, loss=0.5012]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 200/490 [08:24<12:14,  2.53s/it, acc=0.8014, loss=0.5012]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 200/490 [08:27<12:14,  2.53s/it, acc=0.8016, loss=0.5210]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 201/490 [08:27<12:11,  2.53s/it, acc=0.8016, loss=0.5210]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 201/490 [08:29<12:11,  2.53s/it, acc=0.8020, loss=0.4851]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 202/490 [08:29<12:08,  2.53s/it, acc=0.8020, loss=0.4851]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 202/490 [08:32<12:08,  2.53s/it, acc=0.8017, loss=0.6960]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 203/490 [08:32<12:06,  2.53s/it, acc=0.8017, loss=0.6960]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 203/490 [08:34<12:06,  2.53s/it, acc=0.8019, loss=0.5303]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 204/490 [08:34<12:04,  2.53s/it, acc=0.8019, loss=0.5303]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 204/490 [08:37<12:04,  2.53s/it, acc=0.8020, loss=0.6603]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 205/490 [08:37<12:01,  2.53s/it, acc=0.8020, loss=0.6603]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 205/490 [08:39<12:01,  2.53s/it, acc=0.8028, loss=0.1815]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 206/490 [08:39<11:58,  2.53s/it, acc=0.8028, loss=0.1815]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 206/490 [08:42<11:58,  2.53s/it, acc=0.8031, loss=0.2595]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 207/490 [08:42<11:56,  2.53s/it, acc=0.8031, loss=0.2595]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 207/490 [08:45<11:56,  2.53s/it, acc=0.8036, loss=0.2822]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 208/490 [08:45<11:53,  2.53s/it, acc=0.8036, loss=0.2822]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 208/490 [08:47<11:53,  2.53s/it, acc=0.8034, loss=0.5204]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 209/490 [08:47<11:51,  2.53s/it, acc=0.8034, loss=0.5204]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 209/490 [08:50<11:51,  2.53s/it, acc=0.8039, loss=0.2683]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 210/490 [08:50<11:48,  2.53s/it, acc=0.8039, loss=0.2683]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 210/490 [08:52<11:48,  2.53s/it, acc=0.8041, loss=0.4405]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 211/490 [08:52<11:46,  2.53s/it, acc=0.8041, loss=0.4405]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 211/490 [08:55<11:46,  2.53s/it, acc=0.8044, loss=0.4610]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 212/490 [08:55<11:43,  2.53s/it, acc=0.8044, loss=0.4610]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 212/490 [08:57<11:43,  2.53s/it, acc=0.8041, loss=0.4758]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 213/490 [08:57<11:40,  2.53s/it, acc=0.8041, loss=0.4758]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 213/490 [09:00<11:40,  2.53s/it, acc=0.8043, loss=0.4270]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 214/490 [09:00<11:38,  2.53s/it, acc=0.8043, loss=0.4270]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 214/490 [09:02<11:38,  2.53s/it, acc=0.8039, loss=0.6075]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 215/490 [09:02<11:35,  2.53s/it, acc=0.8039, loss=0.6075]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 215/490 [09:05<11:35,  2.53s/it, acc=0.8044, loss=0.4369]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 216/490 [09:05<11:33,  2.53s/it, acc=0.8044, loss=0.4369]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 216/490 [09:07<11:33,  2.53s/it, acc=0.8040, loss=0.5872]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 217/490 [09:07<11:30,  2.53s/it, acc=0.8040, loss=0.5872]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 217/490 [09:10<11:30,  2.53s/it, acc=0.8036, loss=0.7388]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 218/490 [09:10<11:28,  2.53s/it, acc=0.8036, loss=0.7388]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 218/490 [09:12<11:28,  2.53s/it, acc=0.8035, loss=0.5640]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 219/490 [09:12<11:25,  2.53s/it, acc=0.8035, loss=0.5640]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 219/490 [09:15<11:25,  2.53s/it, acc=0.8040, loss=0.2966]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 220/490 [09:15<11:23,  2.53s/it, acc=0.8040, loss=0.2966]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 220/490 [09:17<11:23,  2.53s/it, acc=0.8039, loss=0.5108]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 221/490 [09:17<11:20,  2.53s/it, acc=0.8039, loss=0.5108]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 221/490 [09:20<11:20,  2.53s/it, acc=0.8039, loss=0.5327]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 222/490 [09:20<11:18,  2.53s/it, acc=0.8039, loss=0.5327]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 222/490 [09:22<11:18,  2.53s/it, acc=0.8041, loss=0.3720]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 223/490 [09:22<11:16,  2.53s/it, acc=0.8041, loss=0.3720]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 223/490 [09:25<11:16,  2.53s/it, acc=0.8037, loss=0.6472]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 224/490 [09:25<11:13,  2.53s/it, acc=0.8037, loss=0.6472]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 224/490 [09:28<11:13,  2.53s/it, acc=0.8040, loss=0.3068]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 225/490 [09:28<11:10,  2.53s/it, acc=0.8040, loss=0.3068]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 225/490 [09:30<11:10,  2.53s/it, acc=0.8045, loss=0.3183]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 226/490 [09:30<11:08,  2.53s/it, acc=0.8045, loss=0.3183]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 226/490 [09:33<11:08,  2.53s/it, acc=0.8042, loss=0.8013]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 227/490 [09:33<11:06,  2.53s/it, acc=0.8042, loss=0.8013]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 227/490 [09:35<11:06,  2.53s/it, acc=0.8043, loss=0.5375]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 228/490 [09:35<11:02,  2.53s/it, acc=0.8043, loss=0.5375]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 228/490 [09:38<11:02,  2.53s/it, acc=0.8043, loss=0.3717]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 229/490 [09:38<11:00,  2.53s/it, acc=0.8043, loss=0.3717]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 229/490 [09:40<11:00,  2.53s/it, acc=0.8045, loss=0.3274]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 230/490 [09:40<10:57,  2.53s/it, acc=0.8045, loss=0.3274]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 230/490 [09:43<10:57,  2.53s/it, acc=0.8042, loss=0.7378]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 231/490 [09:43<10:54,  2.53s/it, acc=0.8042, loss=0.7378]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 231/490 [09:45<10:54,  2.53s/it, acc=0.8040, loss=0.7227]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 232/490 [09:45<10:52,  2.53s/it, acc=0.8040, loss=0.7227]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 232/490 [09:48<10:52,  2.53s/it, acc=0.8046, loss=0.2241]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 233/490 [09:48<10:50,  2.53s/it, acc=0.8046, loss=0.2241]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 233/490 [09:50<10:50,  2.53s/it, acc=0.8045, loss=0.5006]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 234/490 [09:50<10:47,  2.53s/it, acc=0.8045, loss=0.5006]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 234/490 [09:53<10:47,  2.53s/it, acc=0.8045, loss=0.6307]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 235/490 [09:53<10:45,  2.53s/it, acc=0.8045, loss=0.6307]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 235/490 [09:55<10:45,  2.53s/it, acc=0.8046, loss=0.5891]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 236/490 [09:55<10:42,  2.53s/it, acc=0.8046, loss=0.5891]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 236/490 [09:58<10:42,  2.53s/it, acc=0.8047, loss=0.3437]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 237/490 [09:58<10:40,  2.53s/it, acc=0.8047, loss=0.3437]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 237/490 [10:00<10:40,  2.53s/it, acc=0.8050, loss=0.3246]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 238/490 [10:00<10:37,  2.53s/it, acc=0.8050, loss=0.3246]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 238/490 [10:03<10:37,  2.53s/it, acc=0.8053, loss=0.4212]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 239/490 [10:03<10:35,  2.53s/it, acc=0.8053, loss=0.4212]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 239/490 [10:05<10:35,  2.53s/it, acc=0.8053, loss=0.8090]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 240/490 [10:05<10:32,  2.53s/it, acc=0.8053, loss=0.8090]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 240/490 [10:08<10:32,  2.53s/it, acc=0.8052, loss=0.5196]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 241/490 [10:08<10:29,  2.53s/it, acc=0.8052, loss=0.5196]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 241/490 [10:11<10:29,  2.53s/it, acc=0.8051, loss=0.5728]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 242/490 [10:11<10:27,  2.53s/it, acc=0.8051, loss=0.5728]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 242/490 [10:13<10:27,  2.53s/it, acc=0.8054, loss=0.4380]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 243/490 [10:13<10:24,  2.53s/it, acc=0.8054, loss=0.4380]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 243/490 [10:16<10:24,  2.53s/it, acc=0.8051, loss=1.0025]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 244/490 [10:16<10:22,  2.53s/it, acc=0.8051, loss=1.0025]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 244/490 [10:18<10:22,  2.53s/it, acc=0.8051, loss=0.4541]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 245/490 [10:18<10:19,  2.53s/it, acc=0.8051, loss=0.4541]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 245/490 [10:21<10:19,  2.53s/it, acc=0.8054, loss=0.4032]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 246/490 [10:21<10:16,  2.53s/it, acc=0.8054, loss=0.4032]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 246/490 [10:23<10:16,  2.53s/it, acc=0.8055, loss=0.4704]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 247/490 [10:23<10:13,  2.52s/it, acc=0.8055, loss=0.4704]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 247/490 [10:26<10:13,  2.52s/it, acc=0.8059, loss=0.2290]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 248/490 [10:26<10:11,  2.53s/it, acc=0.8059, loss=0.2290]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 248/490 [10:28<10:11,  2.53s/it, acc=0.8061, loss=0.5272]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 249/490 [10:28<10:08,  2.53s/it, acc=0.8061, loss=0.5272]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 249/490 [10:31<10:08,  2.53s/it, acc=0.8064, loss=0.4088]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 250/490 [10:31<10:06,  2.53s/it, acc=0.8064, loss=0.4088]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 250/490 [10:33<10:06,  2.53s/it, acc=0.8062, loss=0.9544]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 251/490 [10:33<10:04,  2.53s/it, acc=0.8062, loss=0.9544]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 251/490 [10:36<10:04,  2.53s/it, acc=0.8062, loss=0.5374]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 252/490 [10:36<10:01,  2.53s/it, acc=0.8062, loss=0.5374]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 252/490 [10:38<10:01,  2.53s/it, acc=0.8062, loss=0.5400]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 253/490 [10:38<09:58,  2.53s/it, acc=0.8062, loss=0.5400]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 253/490 [10:41<09:58,  2.53s/it, acc=0.8062, loss=0.3689]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 254/490 [10:41<09:55,  2.53s/it, acc=0.8062, loss=0.3689]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 254/490 [10:43<09:55,  2.53s/it, acc=0.8061, loss=0.4720]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 255/490 [10:43<09:53,  2.53s/it, acc=0.8061, loss=0.4720]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 255/490 [10:46<09:53,  2.53s/it, acc=0.8065, loss=0.3743]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 256/490 [10:46<09:50,  2.52s/it, acc=0.8065, loss=0.3743]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 256/490 [10:48<09:50,  2.52s/it, acc=0.8063, loss=0.7163]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 257/490 [10:48<09:47,  2.52s/it, acc=0.8063, loss=0.7163]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 257/490 [10:51<09:47,  2.52s/it, acc=0.8068, loss=0.2609]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 258/490 [10:51<09:45,  2.52s/it, acc=0.8068, loss=0.2609]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 258/490 [10:53<09:45,  2.52s/it, acc=0.8068, loss=0.5440]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 259/490 [10:53<09:43,  2.53s/it, acc=0.8068, loss=0.5440]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 259/490 [10:56<09:43,  2.53s/it, acc=0.8072, loss=0.2834]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 260/490 [10:56<09:40,  2.53s/it, acc=0.8072, loss=0.2834]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 260/490 [10:59<09:40,  2.53s/it, acc=0.8076, loss=0.3624]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 261/490 [10:59<09:38,  2.53s/it, acc=0.8076, loss=0.3624]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 261/490 [11:01<09:38,  2.53s/it, acc=0.8074, loss=0.7596]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 262/490 [11:01<09:36,  2.53s/it, acc=0.8074, loss=0.7596]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 262/490 [11:04<09:36,  2.53s/it, acc=0.8075, loss=0.2976]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 263/490 [11:04<09:33,  2.52s/it, acc=0.8075, loss=0.2976]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 263/490 [11:06<09:33,  2.52s/it, acc=0.8076, loss=0.3821]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 264/490 [11:06<09:30,  2.53s/it, acc=0.8076, loss=0.3821]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 264/490 [11:09<09:30,  2.53s/it, acc=0.8074, loss=0.6148]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 265/490 [11:09<09:28,  2.53s/it, acc=0.8074, loss=0.6148]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 265/490 [11:11<09:28,  2.53s/it, acc=0.8076, loss=0.5063]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 266/490 [11:11<09:25,  2.52s/it, acc=0.8076, loss=0.5063]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 266/490 [11:14<09:25,  2.52s/it, acc=0.8072, loss=0.7765]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 267/490 [11:14<09:22,  2.52s/it, acc=0.8072, loss=0.7765]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 267/490 [11:16<09:22,  2.52s/it, acc=0.8077, loss=0.3898]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 268/490 [11:16<09:19,  2.52s/it, acc=0.8077, loss=0.3898]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 268/490 [11:19<09:19,  2.52s/it, acc=0.8079, loss=0.4493]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 269/490 [11:19<09:16,  2.52s/it, acc=0.8079, loss=0.4493]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 269/490 [11:21<09:16,  2.52s/it, acc=0.8080, loss=0.4930]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 270/490 [11:21<09:14,  2.52s/it, acc=0.8080, loss=0.4930]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 270/490 [11:24<09:14,  2.52s/it, acc=0.8079, loss=0.5066]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 271/490 [11:24<09:12,  2.52s/it, acc=0.8079, loss=0.5066]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 271/490 [11:26<09:12,  2.52s/it, acc=0.8080, loss=0.5225]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 272/490 [11:26<09:10,  2.52s/it, acc=0.8080, loss=0.5225]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 272/490 [11:29<09:10,  2.52s/it, acc=0.8082, loss=0.4309]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 273/490 [11:29<09:07,  2.52s/it, acc=0.8082, loss=0.4309]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 273/490 [11:31<09:07,  2.52s/it, acc=0.8081, loss=0.6603]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 274/490 [11:31<09:04,  2.52s/it, acc=0.8081, loss=0.6603]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 274/490 [11:34<09:04,  2.52s/it, acc=0.8081, loss=0.5329]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 275/490 [11:34<09:02,  2.52s/it, acc=0.8081, loss=0.5329]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 275/490 [11:36<09:02,  2.52s/it, acc=0.8083, loss=0.3417]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 276/490 [11:36<08:59,  2.52s/it, acc=0.8083, loss=0.3417]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 276/490 [11:39<08:59,  2.52s/it, acc=0.8083, loss=0.5465]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 277/490 [11:39<08:57,  2.52s/it, acc=0.8083, loss=0.5465]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 277/490 [11:41<08:57,  2.52s/it, acc=0.8082, loss=0.5220]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 278/490 [11:41<08:54,  2.52s/it, acc=0.8082, loss=0.5220]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 278/490 [11:44<08:54,  2.52s/it, acc=0.8085, loss=0.4303]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 279/490 [11:44<08:51,  2.52s/it, acc=0.8085, loss=0.4303]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 279/490 [11:46<08:51,  2.52s/it, acc=0.8086, loss=0.2995]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 280/490 [11:46<08:49,  2.52s/it, acc=0.8086, loss=0.2995]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 280/490 [11:49<08:49,  2.52s/it, acc=0.8087, loss=0.4157]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 281/490 [11:49<08:46,  2.52s/it, acc=0.8087, loss=0.4157]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 281/490 [11:52<08:46,  2.52s/it, acc=0.8090, loss=0.4761]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 282/490 [11:52<08:44,  2.52s/it, acc=0.8090, loss=0.4761]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 282/490 [11:54<08:44,  2.52s/it, acc=0.8087, loss=0.6318]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 283/490 [11:54<08:41,  2.52s/it, acc=0.8087, loss=0.6318]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 283/490 [11:57<08:41,  2.52s/it, acc=0.8089, loss=0.4961]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 284/490 [11:57<08:38,  2.52s/it, acc=0.8089, loss=0.4961]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 284/490 [11:59<08:38,  2.52s/it, acc=0.8088, loss=0.4484]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 285/490 [11:59<08:36,  2.52s/it, acc=0.8088, loss=0.4484]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 285/490 [12:02<08:36,  2.52s/it, acc=0.8087, loss=0.4622]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 286/490 [12:02<08:33,  2.52s/it, acc=0.8087, loss=0.4622]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 286/490 [12:04<08:33,  2.52s/it, acc=0.8089, loss=0.3623]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 287/490 [12:04<08:31,  2.52s/it, acc=0.8089, loss=0.3623]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 287/490 [12:07<08:31,  2.52s/it, acc=0.8089, loss=0.4238]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 288/490 [12:07<08:28,  2.52s/it, acc=0.8089, loss=0.4238]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 288/490 [12:09<08:28,  2.52s/it, acc=0.8093, loss=0.2562]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 289/490 [12:09<08:26,  2.52s/it, acc=0.8093, loss=0.2562]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 289/490 [12:12<08:26,  2.52s/it, acc=0.8095, loss=0.5378]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 290/490 [12:12<08:23,  2.52s/it, acc=0.8095, loss=0.5378]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 290/490 [12:14<08:23,  2.52s/it, acc=0.8096, loss=0.4506]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 291/490 [12:14<08:20,  2.52s/it, acc=0.8096, loss=0.4506]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 291/490 [12:17<08:20,  2.52s/it, acc=0.8098, loss=0.2786]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 292/490 [12:17<08:18,  2.52s/it, acc=0.8098, loss=0.2786]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 292/490 [12:19<08:18,  2.52s/it, acc=0.8098, loss=0.4678]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 293/490 [12:19<08:16,  2.52s/it, acc=0.8098, loss=0.4678]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 293/490 [12:22<08:16,  2.52s/it, acc=0.8098, loss=0.3530]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 294/490 [12:22<08:13,  2.52s/it, acc=0.8098, loss=0.3530]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 294/490 [12:24<08:13,  2.52s/it, acc=0.8100, loss=0.3266]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 295/490 [12:24<08:11,  2.52s/it, acc=0.8100, loss=0.3266]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 295/490 [12:27<08:11,  2.52s/it, acc=0.8099, loss=0.7918]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 296/490 [12:27<08:08,  2.52s/it, acc=0.8099, loss=0.7918]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 296/490 [12:29<08:08,  2.52s/it, acc=0.8097, loss=0.5287]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 297/490 [12:29<08:05,  2.51s/it, acc=0.8097, loss=0.5287]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 297/490 [12:32<08:05,  2.51s/it, acc=0.8096, loss=0.6812]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 298/490 [12:32<08:02,  2.51s/it, acc=0.8096, loss=0.6812]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 298/490 [12:34<08:02,  2.51s/it, acc=0.8097, loss=0.6233]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 299/490 [12:34<08:00,  2.51s/it, acc=0.8097, loss=0.6233]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 299/490 [12:37<08:00,  2.51s/it, acc=0.8098, loss=0.5641]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 300/490 [12:37<07:57,  2.51s/it, acc=0.8098, loss=0.5641]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 300/490 [12:39<07:57,  2.51s/it, acc=0.8097, loss=0.4539]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 301/490 [12:39<07:55,  2.52s/it, acc=0.8097, loss=0.4539]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 301/490 [12:42<07:55,  2.52s/it, acc=0.8099, loss=0.4086]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 302/490 [12:42<07:53,  2.52s/it, acc=0.8099, loss=0.4086]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 302/490 [12:44<07:53,  2.52s/it, acc=0.8101, loss=0.4761]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 303/490 [12:44<07:50,  2.52s/it, acc=0.8101, loss=0.4761]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 303/490 [12:47<07:50,  2.52s/it, acc=0.8104, loss=0.2950]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 304/490 [12:47<07:47,  2.51s/it, acc=0.8104, loss=0.2950]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 304/490 [12:49<07:47,  2.51s/it, acc=0.8109, loss=0.2433]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 305/490 [12:49<07:45,  2.51s/it, acc=0.8109, loss=0.2433]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 305/490 [12:52<07:45,  2.51s/it, acc=0.8110, loss=0.4290]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 306/490 [12:52<07:42,  2.51s/it, acc=0.8110, loss=0.4290]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 306/490 [12:54<07:42,  2.51s/it, acc=0.8112, loss=0.4106]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 307/490 [12:54<07:39,  2.51s/it, acc=0.8112, loss=0.4106]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 307/490 [12:57<07:39,  2.51s/it, acc=0.8111, loss=0.5095]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 308/490 [12:57<07:37,  2.51s/it, acc=0.8111, loss=0.5095]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 308/490 [12:59<07:37,  2.51s/it, acc=0.8111, loss=0.4140]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 309/490 [12:59<07:34,  2.51s/it, acc=0.8111, loss=0.4140]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 309/490 [13:02<07:34,  2.51s/it, acc=0.8108, loss=0.7575]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 310/490 [13:02<07:31,  2.51s/it, acc=0.8108, loss=0.7575]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 310/490 [13:04<07:31,  2.51s/it, acc=0.8106, loss=0.7440]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 311/490 [13:04<07:29,  2.51s/it, acc=0.8106, loss=0.7440]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 311/490 [13:07<07:29,  2.51s/it, acc=0.8106, loss=0.4328]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 312/490 [13:07<07:27,  2.51s/it, acc=0.8106, loss=0.4328]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 312/490 [13:09<07:27,  2.51s/it, acc=0.8108, loss=0.3274]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 313/490 [13:09<07:25,  2.51s/it, acc=0.8108, loss=0.3274]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 313/490 [13:12<07:25,  2.51s/it, acc=0.8109, loss=0.4413]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 314/490 [13:12<07:22,  2.52s/it, acc=0.8109, loss=0.4413]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 314/490 [13:15<07:22,  2.52s/it, acc=0.8111, loss=0.3235]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 315/490 [13:15<07:20,  2.51s/it, acc=0.8111, loss=0.3235]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 315/490 [13:17<07:20,  2.51s/it, acc=0.8110, loss=0.4477]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 316/490 [13:17<07:17,  2.52s/it, acc=0.8110, loss=0.4477]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 316/490 [13:20<07:17,  2.52s/it, acc=0.8110, loss=0.4880]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 317/490 [13:20<07:15,  2.52s/it, acc=0.8110, loss=0.4880]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 317/490 [13:22<07:15,  2.52s/it, acc=0.8114, loss=0.3251]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 318/490 [13:22<07:13,  2.52s/it, acc=0.8114, loss=0.3251]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 318/490 [13:25<07:13,  2.52s/it, acc=0.8116, loss=0.3887]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 319/490 [13:25<07:10,  2.52s/it, acc=0.8116, loss=0.3887]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 319/490 [13:27<07:10,  2.52s/it, acc=0.8112, loss=0.7851]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 320/490 [13:27<07:07,  2.52s/it, acc=0.8112, loss=0.7851]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 320/490 [13:30<07:07,  2.52s/it, acc=0.8112, loss=0.5242]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 321/490 [13:30<07:04,  2.51s/it, acc=0.8112, loss=0.5242]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 321/490 [13:32<07:04,  2.51s/it, acc=0.8113, loss=0.4227]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 322/490 [13:32<07:02,  2.52s/it, acc=0.8113, loss=0.4227]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 322/490 [13:35<07:02,  2.52s/it, acc=0.8112, loss=0.5586]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 323/490 [13:35<07:00,  2.52s/it, acc=0.8112, loss=0.5586]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 323/490 [13:37<07:00,  2.52s/it, acc=0.8111, loss=0.5963]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 324/490 [13:37<06:57,  2.52s/it, acc=0.8111, loss=0.5963]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 324/490 [13:40<06:57,  2.52s/it, acc=0.8112, loss=0.6944]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 325/490 [13:40<06:54,  2.51s/it, acc=0.8112, loss=0.6944]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 325/490 [13:42<06:54,  2.51s/it, acc=0.8112, loss=0.7030]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 326/490 [13:42<06:52,  2.52s/it, acc=0.8112, loss=0.7030]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 326/490 [13:45<06:52,  2.52s/it, acc=0.8111, loss=0.5690]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 327/490 [13:45<06:50,  2.52s/it, acc=0.8111, loss=0.5690]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 327/490 [13:47<06:50,  2.52s/it, acc=0.8106, loss=0.7349]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 328/490 [13:47<06:47,  2.52s/it, acc=0.8106, loss=0.7349]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 328/490 [13:50<06:47,  2.52s/it, acc=0.8109, loss=0.3630]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 329/490 [13:50<06:45,  2.52s/it, acc=0.8109, loss=0.3630]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 329/490 [13:52<06:45,  2.52s/it, acc=0.8111, loss=0.3862]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 330/490 [13:52<06:42,  2.51s/it, acc=0.8111, loss=0.3862]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 330/490 [13:55<06:42,  2.51s/it, acc=0.8114, loss=0.3868]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 331/490 [13:55<06:39,  2.51s/it, acc=0.8114, loss=0.3868]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 331/490 [13:57<06:39,  2.51s/it, acc=0.8111, loss=0.6122]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 332/490 [13:57<06:37,  2.51s/it, acc=0.8111, loss=0.6122]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 332/490 [14:00<06:37,  2.51s/it, acc=0.8109, loss=0.4975]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 333/490 [14:00<06:34,  2.51s/it, acc=0.8109, loss=0.4975]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 333/490 [14:02<06:34,  2.51s/it, acc=0.8110, loss=0.4393]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 334/490 [14:02<06:32,  2.51s/it, acc=0.8110, loss=0.4393]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 334/490 [14:05<06:32,  2.51s/it, acc=0.8111, loss=0.3894]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 335/490 [14:05<06:30,  2.52s/it, acc=0.8111, loss=0.3894]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 335/490 [14:07<06:30,  2.52s/it, acc=0.8111, loss=0.3615]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 336/490 [14:07<06:27,  2.52s/it, acc=0.8111, loss=0.3615]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 336/490 [14:10<06:27,  2.52s/it, acc=0.8110, loss=0.6035]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 337/490 [14:10<06:25,  2.52s/it, acc=0.8110, loss=0.6035]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 337/490 [14:12<06:25,  2.52s/it, acc=0.8110, loss=0.3879]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 338/490 [14:12<06:22,  2.52s/it, acc=0.8110, loss=0.3879]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 338/490 [14:15<06:22,  2.52s/it, acc=0.8108, loss=0.8066]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 339/490 [14:15<06:20,  2.52s/it, acc=0.8108, loss=0.8066]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 339/490 [14:17<06:20,  2.52s/it, acc=0.8110, loss=0.3584]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 340/490 [14:17<06:17,  2.52s/it, acc=0.8110, loss=0.3584]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 340/490 [14:20<06:17,  2.52s/it, acc=0.8109, loss=0.7807]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 341/490 [14:20<06:15,  2.52s/it, acc=0.8109, loss=0.7807]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 341/490 [14:22<06:15,  2.52s/it, acc=0.8109, loss=0.5194]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 342/490 [14:22<06:12,  2.52s/it, acc=0.8109, loss=0.5194]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 342/490 [14:25<06:12,  2.52s/it, acc=0.8108, loss=0.6236]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 343/490 [14:25<06:10,  2.52s/it, acc=0.8108, loss=0.6236]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 343/490 [14:28<06:10,  2.52s/it, acc=0.8109, loss=0.3100]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 344/490 [14:28<06:07,  2.52s/it, acc=0.8109, loss=0.3100]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 344/490 [14:30<06:07,  2.52s/it, acc=0.8111, loss=0.3409]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 345/490 [14:30<06:05,  2.52s/it, acc=0.8111, loss=0.3409]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 345/490 [14:33<06:05,  2.52s/it, acc=0.8113, loss=0.3300]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 346/490 [14:33<06:03,  2.52s/it, acc=0.8113, loss=0.3300]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 346/490 [14:35<06:03,  2.52s/it, acc=0.8116, loss=0.2703]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 347/490 [14:35<06:00,  2.52s/it, acc=0.8116, loss=0.2703]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 347/490 [14:38<06:00,  2.52s/it, acc=0.8113, loss=0.6992]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 348/490 [14:38<05:58,  2.52s/it, acc=0.8113, loss=0.6992]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 348/490 [14:40<05:58,  2.52s/it, acc=0.8115, loss=0.4089]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 349/490 [14:40<05:55,  2.52s/it, acc=0.8115, loss=0.4089]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 349/490 [14:43<05:55,  2.52s/it, acc=0.8116, loss=0.5352]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 350/490 [14:43<05:52,  2.52s/it, acc=0.8116, loss=0.5352]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 350/490 [14:45<05:52,  2.52s/it, acc=0.8114, loss=0.5632]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 351/490 [14:45<05:50,  2.52s/it, acc=0.8114, loss=0.5632]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 351/490 [14:48<05:50,  2.52s/it, acc=0.8113, loss=0.6623]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 352/490 [14:48<05:47,  2.52s/it, acc=0.8113, loss=0.6623]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 352/490 [14:50<05:47,  2.52s/it, acc=0.8111, loss=0.8534]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 353/490 [14:50<05:45,  2.52s/it, acc=0.8111, loss=0.8534]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 353/490 [14:53<05:45,  2.52s/it, acc=0.8108, loss=0.5776]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 354/490 [14:53<05:42,  2.52s/it, acc=0.8108, loss=0.5776]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 354/490 [14:55<05:42,  2.52s/it, acc=0.8110, loss=0.3420]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 355/490 [14:55<05:40,  2.52s/it, acc=0.8110, loss=0.3420]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 355/490 [14:58<05:40,  2.52s/it, acc=0.8109, loss=0.5778]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 356/490 [14:58<05:37,  2.52s/it, acc=0.8109, loss=0.5778]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 356/490 [15:00<05:37,  2.52s/it, acc=0.8110, loss=0.3421]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 357/490 [15:00<05:35,  2.52s/it, acc=0.8110, loss=0.3421]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 357/490 [15:03<05:35,  2.52s/it, acc=0.8113, loss=0.3581]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 358/490 [15:03<05:32,  2.52s/it, acc=0.8113, loss=0.3581]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 358/490 [15:05<05:32,  2.52s/it, acc=0.8110, loss=0.5599]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 359/490 [15:05<05:30,  2.52s/it, acc=0.8110, loss=0.5599]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 359/490 [15:08<05:30,  2.52s/it, acc=0.8109, loss=0.5807]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 360/490 [15:08<05:27,  2.52s/it, acc=0.8109, loss=0.5807]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 360/490 [15:10<05:27,  2.52s/it, acc=0.8109, loss=0.3814]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 361/490 [15:10<05:25,  2.52s/it, acc=0.8109, loss=0.3814]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 361/490 [15:13<05:25,  2.52s/it, acc=0.8114, loss=0.1891]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 362/490 [15:13<05:22,  2.52s/it, acc=0.8114, loss=0.1891]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 362/490 [15:15<05:22,  2.52s/it, acc=0.8110, loss=0.7925]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 363/490 [15:15<05:20,  2.52s/it, acc=0.8110, loss=0.7925]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 363/490 [15:18<05:20,  2.52s/it, acc=0.8112, loss=0.4787]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 364/490 [15:18<05:17,  2.52s/it, acc=0.8112, loss=0.4787]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 364/490 [15:20<05:17,  2.52s/it, acc=0.8116, loss=0.1870]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 365/490 [15:20<05:15,  2.52s/it, acc=0.8116, loss=0.1870]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 365/490 [15:23<05:15,  2.52s/it, acc=0.8113, loss=0.7685]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 366/490 [15:23<05:12,  2.52s/it, acc=0.8113, loss=0.7685]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 366/490 [15:25<05:12,  2.52s/it, acc=0.8113, loss=0.5207]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 367/490 [15:25<05:10,  2.52s/it, acc=0.8113, loss=0.5207]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 367/490 [15:28<05:10,  2.52s/it, acc=0.8114, loss=0.5545]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 368/490 [15:28<05:07,  2.52s/it, acc=0.8114, loss=0.5545]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 368/490 [15:31<05:07,  2.52s/it, acc=0.8117, loss=0.4041]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 369/490 [15:31<05:05,  2.52s/it, acc=0.8117, loss=0.4041]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 369/490 [15:33<05:05,  2.52s/it, acc=0.8117, loss=0.5615]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 370/490 [15:33<05:03,  2.53s/it, acc=0.8117, loss=0.5615]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 370/490 [15:36<05:03,  2.53s/it, acc=0.8117, loss=0.5294]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 371/490 [15:36<05:00,  2.52s/it, acc=0.8117, loss=0.5294]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 371/490 [15:38<05:00,  2.52s/it, acc=0.8117, loss=0.5665]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 372/490 [15:38<04:57,  2.52s/it, acc=0.8117, loss=0.5665]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 372/490 [15:41<04:57,  2.52s/it, acc=0.8118, loss=0.3447]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 373/490 [15:41<04:55,  2.53s/it, acc=0.8118, loss=0.3447]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 373/490 [15:43<04:55,  2.53s/it, acc=0.8118, loss=0.4205]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 374/490 [15:43<04:53,  2.53s/it, acc=0.8118, loss=0.4205]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 374/490 [15:46<04:53,  2.53s/it, acc=0.8119, loss=0.4278]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 375/490 [15:46<04:50,  2.53s/it, acc=0.8119, loss=0.4278]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 375/490 [15:48<04:50,  2.53s/it, acc=0.8122, loss=0.2905]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 376/490 [15:48<04:47,  2.52s/it, acc=0.8122, loss=0.2905]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 376/490 [15:51<04:47,  2.52s/it, acc=0.8120, loss=0.7580]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 377/490 [15:51<04:45,  2.52s/it, acc=0.8120, loss=0.7580]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 377/490 [15:53<04:45,  2.52s/it, acc=0.8121, loss=0.5519]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 378/490 [15:53<04:42,  2.52s/it, acc=0.8121, loss=0.5519]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 378/490 [15:56<04:42,  2.52s/it, acc=0.8122, loss=0.7199]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 379/490 [15:56<04:40,  2.52s/it, acc=0.8122, loss=0.7199]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 379/490 [15:58<04:40,  2.52s/it, acc=0.8124, loss=0.3786]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 380/490 [15:58<04:37,  2.52s/it, acc=0.8124, loss=0.3786]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 380/490 [16:01<04:37,  2.52s/it, acc=0.8124, loss=0.5701]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 381/490 [16:01<04:34,  2.52s/it, acc=0.8124, loss=0.5701]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 381/490 [16:03<04:34,  2.52s/it, acc=0.8123, loss=0.5817]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 382/490 [16:03<04:32,  2.52s/it, acc=0.8123, loss=0.5817]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 382/490 [16:06<04:32,  2.52s/it, acc=0.8123, loss=0.3448]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 383/490 [16:06<04:30,  2.52s/it, acc=0.8123, loss=0.3448]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 383/490 [16:08<04:30,  2.52s/it, acc=0.8123, loss=0.6770]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 384/490 [16:08<04:27,  2.52s/it, acc=0.8123, loss=0.6770]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 384/490 [16:11<04:27,  2.52s/it, acc=0.8119, loss=0.7763]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 385/490 [16:11<04:25,  2.52s/it, acc=0.8119, loss=0.7763]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 385/490 [16:13<04:25,  2.52s/it, acc=0.8120, loss=0.4008]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 386/490 [16:13<04:22,  2.52s/it, acc=0.8120, loss=0.4008]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 386/490 [16:16<04:22,  2.52s/it, acc=0.8119, loss=0.5848]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 387/490 [16:16<04:20,  2.52s/it, acc=0.8119, loss=0.5848]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 387/490 [16:19<04:20,  2.52s/it, acc=0.8119, loss=0.5381]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 388/490 [16:19<04:17,  2.52s/it, acc=0.8119, loss=0.5381]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 388/490 [16:21<04:17,  2.52s/it, acc=0.8119, loss=0.4543]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 389/490 [16:21<04:14,  2.52s/it, acc=0.8119, loss=0.4543]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 389/490 [16:24<04:14,  2.52s/it, acc=0.8119, loss=0.4384]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 390/490 [16:24<04:12,  2.53s/it, acc=0.8119, loss=0.4384]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 390/490 [16:26<04:12,  2.53s/it, acc=0.8119, loss=0.5582]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 391/490 [16:26<04:09,  2.53s/it, acc=0.8119, loss=0.5582]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 391/490 [16:29<04:09,  2.53s/it, acc=0.8121, loss=0.3289]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 392/490 [16:29<04:07,  2.52s/it, acc=0.8121, loss=0.3289]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 392/490 [16:31<04:07,  2.52s/it, acc=0.8120, loss=0.5592]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 393/490 [16:31<04:04,  2.53s/it, acc=0.8120, loss=0.5592]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 393/490 [16:34<04:04,  2.53s/it, acc=0.8121, loss=0.5712]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 394/490 [16:34<04:02,  2.52s/it, acc=0.8121, loss=0.5712]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 394/490 [16:36<04:02,  2.52s/it, acc=0.8120, loss=0.7165]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 395/490 [16:36<03:59,  2.53s/it, acc=0.8120, loss=0.7165]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 395/490 [16:39<03:59,  2.53s/it, acc=0.8121, loss=0.3186]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 396/490 [16:39<03:57,  2.52s/it, acc=0.8121, loss=0.3186]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 396/490 [16:41<03:57,  2.52s/it, acc=0.8123, loss=0.4765]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 397/490 [16:41<03:54,  2.53s/it, acc=0.8123, loss=0.4765]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 397/490 [16:44<03:54,  2.53s/it, acc=0.8123, loss=0.3827]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 398/490 [16:44<03:52,  2.53s/it, acc=0.8123, loss=0.3827]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 398/490 [16:46<03:52,  2.53s/it, acc=0.8123, loss=0.8304]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 399/490 [16:46<03:49,  2.53s/it, acc=0.8123, loss=0.8304]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 399/490 [16:49<03:49,  2.53s/it, acc=0.8119, loss=0.7715]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 400/490 [16:49<03:47,  2.52s/it, acc=0.8119, loss=0.7715]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 400/490 [16:51<03:47,  2.52s/it, acc=0.8120, loss=0.4237]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 401/490 [16:51<03:44,  2.53s/it, acc=0.8120, loss=0.4237]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 401/490 [16:54<03:44,  2.53s/it, acc=0.8117, loss=0.8338]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 402/490 [16:54<03:42,  2.53s/it, acc=0.8117, loss=0.8338]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 402/490 [16:56<03:42,  2.53s/it, acc=0.8118, loss=0.3773]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 403/490 [16:56<03:39,  2.53s/it, acc=0.8118, loss=0.3773]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 403/490 [16:59<03:39,  2.53s/it, acc=0.8120, loss=0.3908]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 404/490 [16:59<03:37,  2.53s/it, acc=0.8120, loss=0.3908]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 404/490 [17:01<03:37,  2.53s/it, acc=0.8120, loss=0.6055]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 405/490 [17:01<03:34,  2.53s/it, acc=0.8120, loss=0.6055]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 405/490 [17:04<03:34,  2.53s/it, acc=0.8121, loss=0.3807]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 406/490 [17:04<03:31,  2.52s/it, acc=0.8121, loss=0.3807]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 406/490 [17:06<03:31,  2.52s/it, acc=0.8124, loss=0.3980]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 407/490 [17:06<03:29,  2.52s/it, acc=0.8124, loss=0.3980]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 407/490 [17:09<03:29,  2.52s/it, acc=0.8125, loss=0.4149]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 408/490 [17:09<03:27,  2.53s/it, acc=0.8125, loss=0.4149]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 408/490 [17:12<03:27,  2.53s/it, acc=0.8127, loss=0.2849]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 409/490 [17:12<03:24,  2.52s/it, acc=0.8127, loss=0.2849]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 409/490 [17:14<03:24,  2.52s/it, acc=0.8127, loss=0.4124]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 410/490 [17:14<03:22,  2.53s/it, acc=0.8127, loss=0.4124]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 410/490 [17:17<03:22,  2.53s/it, acc=0.8130, loss=0.3717]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 411/490 [17:17<03:19,  2.53s/it, acc=0.8130, loss=0.3717]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 411/490 [17:19<03:19,  2.53s/it, acc=0.8129, loss=0.5102]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 412/490 [17:19<03:16,  2.52s/it, acc=0.8129, loss=0.5102]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 412/490 [17:22<03:16,  2.52s/it, acc=0.8126, loss=0.5643]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 413/490 [17:22<03:14,  2.53s/it, acc=0.8126, loss=0.5643]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 413/490 [17:24<03:14,  2.53s/it, acc=0.8125, loss=0.4600]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 414/490 [17:24<03:11,  2.53s/it, acc=0.8125, loss=0.4600]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 414/490 [17:27<03:11,  2.53s/it, acc=0.8123, loss=0.5252]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 415/490 [17:27<03:09,  2.52s/it, acc=0.8123, loss=0.5252]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 415/490 [17:29<03:09,  2.52s/it, acc=0.8121, loss=0.5350]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 416/490 [17:29<03:06,  2.52s/it, acc=0.8121, loss=0.5350]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 416/490 [17:32<03:06,  2.52s/it, acc=0.8122, loss=0.3544]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 417/490 [17:32<03:04,  2.52s/it, acc=0.8122, loss=0.3544]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 417/490 [17:34<03:04,  2.52s/it, acc=0.8124, loss=0.3431]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 418/490 [17:34<03:01,  2.52s/it, acc=0.8124, loss=0.3431]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 418/490 [17:37<03:01,  2.52s/it, acc=0.8125, loss=0.2288]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 419/490 [17:37<02:59,  2.52s/it, acc=0.8125, loss=0.2288]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 419/490 [17:39<02:59,  2.52s/it, acc=0.8125, loss=0.4087]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 420/490 [17:39<02:56,  2.52s/it, acc=0.8125, loss=0.4087]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 420/490 [17:42<02:56,  2.52s/it, acc=0.8124, loss=0.5318]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 421/490 [17:42<02:53,  2.52s/it, acc=0.8124, loss=0.5318]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 421/490 [17:44<02:53,  2.52s/it, acc=0.8124, loss=0.4008]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 422/490 [17:44<02:51,  2.52s/it, acc=0.8124, loss=0.4008]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 422/490 [17:47<02:51,  2.52s/it, acc=0.8124, loss=0.7333]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 423/490 [17:47<02:48,  2.52s/it, acc=0.8124, loss=0.7333]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 423/490 [17:49<02:48,  2.52s/it, acc=0.8124, loss=0.6439]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 424/490 [17:49<02:46,  2.52s/it, acc=0.8124, loss=0.6439]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 424/490 [17:52<02:46,  2.52s/it, acc=0.8124, loss=0.4248]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 425/490 [17:52<02:43,  2.52s/it, acc=0.8124, loss=0.4248]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 425/490 [17:54<02:43,  2.52s/it, acc=0.8127, loss=0.2536]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 426/490 [17:54<02:41,  2.52s/it, acc=0.8127, loss=0.2536]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 426/490 [17:57<02:41,  2.52s/it, acc=0.8126, loss=0.3832]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 427/490 [17:57<02:38,  2.52s/it, acc=0.8126, loss=0.3832]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 427/490 [17:59<02:38,  2.52s/it, acc=0.8126, loss=0.5681]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 428/490 [17:59<02:36,  2.52s/it, acc=0.8126, loss=0.5681]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 428/490 [18:02<02:36,  2.52s/it, acc=0.8128, loss=0.3160]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 429/490 [18:02<02:33,  2.52s/it, acc=0.8128, loss=0.3160]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 429/490 [18:05<02:33,  2.52s/it, acc=0.8129, loss=0.3400]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 430/490 [18:05<02:31,  2.52s/it, acc=0.8129, loss=0.3400]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 430/490 [18:07<02:31,  2.52s/it, acc=0.8129, loss=0.8288]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 431/490 [18:07<02:28,  2.52s/it, acc=0.8129, loss=0.8288]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 431/490 [18:10<02:28,  2.52s/it, acc=0.8129, loss=0.5496]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 432/490 [18:10<02:26,  2.52s/it, acc=0.8129, loss=0.5496]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 432/490 [18:12<02:26,  2.52s/it, acc=0.8129, loss=0.5531]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 433/490 [18:12<02:23,  2.52s/it, acc=0.8129, loss=0.5531]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 433/490 [18:15<02:23,  2.52s/it, acc=0.8131, loss=0.3115]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 434/490 [18:15<02:20,  2.52s/it, acc=0.8131, loss=0.3115]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 434/490 [18:17<02:20,  2.52s/it, acc=0.8129, loss=0.6126]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 435/490 [18:17<02:18,  2.52s/it, acc=0.8129, loss=0.6126]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 435/490 [18:20<02:18,  2.52s/it, acc=0.8131, loss=0.2781]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 436/490 [18:20<02:15,  2.52s/it, acc=0.8131, loss=0.2781]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 436/490 [18:22<02:15,  2.52s/it, acc=0.8129, loss=0.6809]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 437/490 [18:22<02:13,  2.52s/it, acc=0.8129, loss=0.6809]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 437/490 [18:25<02:13,  2.52s/it, acc=0.8131, loss=0.4237]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 438/490 [18:25<02:10,  2.52s/it, acc=0.8131, loss=0.4237]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 438/490 [18:27<02:10,  2.52s/it, acc=0.8132, loss=0.3140]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 439/490 [18:27<02:08,  2.52s/it, acc=0.8132, loss=0.3140]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 439/490 [18:30<02:08,  2.52s/it, acc=0.8132, loss=0.4335]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 440/490 [18:30<02:05,  2.52s/it, acc=0.8132, loss=0.4335]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 440/490 [18:32<02:05,  2.52s/it, acc=0.8134, loss=0.3879]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 441/490 [18:32<02:03,  2.52s/it, acc=0.8134, loss=0.3879]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 441/490 [18:35<02:03,  2.52s/it, acc=0.8133, loss=0.5929]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 442/490 [18:35<02:00,  2.52s/it, acc=0.8133, loss=0.5929]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 442/490 [18:37<02:00,  2.52s/it, acc=0.8134, loss=0.5456]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 443/490 [18:37<01:58,  2.52s/it, acc=0.8134, loss=0.5456]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 443/490 [18:40<01:58,  2.52s/it, acc=0.8136, loss=0.3230]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 444/490 [18:40<01:55,  2.52s/it, acc=0.8136, loss=0.3230]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 444/490 [18:42<01:55,  2.52s/it, acc=0.8136, loss=0.4349]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 445/490 [18:42<01:53,  2.52s/it, acc=0.8136, loss=0.4349]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 445/490 [18:45<01:53,  2.52s/it, acc=0.8138, loss=0.3154]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 446/490 [18:45<01:50,  2.52s/it, acc=0.8138, loss=0.3154]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 446/490 [18:47<01:50,  2.52s/it, acc=0.8140, loss=0.3443]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 447/490 [18:47<01:48,  2.52s/it, acc=0.8140, loss=0.3443]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 447/490 [18:50<01:48,  2.52s/it, acc=0.8138, loss=0.5915]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 448/490 [18:50<01:45,  2.52s/it, acc=0.8138, loss=0.5915]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 448/490 [18:52<01:45,  2.52s/it, acc=0.8137, loss=0.6042]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 449/490 [18:52<01:43,  2.52s/it, acc=0.8137, loss=0.6042]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 449/490 [18:55<01:43,  2.52s/it, acc=0.8136, loss=0.5631]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 450/490 [18:55<01:40,  2.52s/it, acc=0.8136, loss=0.5631]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 450/490 [18:57<01:40,  2.52s/it, acc=0.8135, loss=0.5833]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 451/490 [18:57<01:38,  2.52s/it, acc=0.8135, loss=0.5833]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 451/490 [19:00<01:38,  2.52s/it, acc=0.8135, loss=0.4852]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 452/490 [19:00<01:35,  2.52s/it, acc=0.8135, loss=0.4852]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 452/490 [19:02<01:35,  2.52s/it, acc=0.8132, loss=0.8189]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 453/490 [19:02<01:33,  2.52s/it, acc=0.8132, loss=0.8189]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 453/490 [19:05<01:33,  2.52s/it, acc=0.8134, loss=0.3391]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 454/490 [19:05<01:30,  2.52s/it, acc=0.8134, loss=0.3391]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 454/490 [19:07<01:30,  2.52s/it, acc=0.8134, loss=0.4206]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 455/490 [19:07<01:28,  2.52s/it, acc=0.8134, loss=0.4206]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 455/490 [19:10<01:28,  2.52s/it, acc=0.8134, loss=0.5578]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 456/490 [19:10<01:25,  2.52s/it, acc=0.8134, loss=0.5578]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 456/490 [19:12<01:25,  2.52s/it, acc=0.8133, loss=0.4784]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 457/490 [19:12<01:23,  2.52s/it, acc=0.8133, loss=0.4784]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 457/490 [19:15<01:23,  2.52s/it, acc=0.8134, loss=0.4073]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 458/490 [19:15<01:20,  2.52s/it, acc=0.8134, loss=0.4073]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 458/490 [19:18<01:20,  2.52s/it, acc=0.8134, loss=0.3828]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 459/490 [19:18<01:17,  2.52s/it, acc=0.8134, loss=0.3828]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 459/490 [19:20<01:17,  2.52s/it, acc=0.8135, loss=0.4270]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 460/490 [19:20<01:15,  2.52s/it, acc=0.8135, loss=0.4270]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 460/490 [19:23<01:15,  2.52s/it, acc=0.8136, loss=0.4423]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 461/490 [19:23<01:12,  2.52s/it, acc=0.8136, loss=0.4423]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 461/490 [19:25<01:12,  2.52s/it, acc=0.8139, loss=0.2596]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 462/490 [19:25<01:10,  2.52s/it, acc=0.8139, loss=0.2596]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 462/490 [19:28<01:10,  2.52s/it, acc=0.8140, loss=0.3369]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 463/490 [19:28<01:07,  2.52s/it, acc=0.8140, loss=0.3369]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 463/490 [19:30<01:07,  2.52s/it, acc=0.8143, loss=0.2389]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 464/490 [19:30<01:05,  2.51s/it, acc=0.8143, loss=0.2389]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 464/490 [19:33<01:05,  2.51s/it, acc=0.8144, loss=0.3335]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 465/490 [19:33<01:02,  2.51s/it, acc=0.8144, loss=0.3335]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 465/490 [19:35<01:02,  2.51s/it, acc=0.8144, loss=0.5012]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 466/490 [19:35<01:00,  2.51s/it, acc=0.8144, loss=0.5012]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 466/490 [19:38<01:00,  2.51s/it, acc=0.8145, loss=0.4778]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 467/490 [19:38<00:57,  2.51s/it, acc=0.8145, loss=0.4778]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 467/490 [19:40<00:57,  2.51s/it, acc=0.8146, loss=0.4318]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 468/490 [19:40<00:55,  2.51s/it, acc=0.8146, loss=0.4318]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 468/490 [19:43<00:55,  2.51s/it, acc=0.8145, loss=0.6375]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 469/490 [19:43<00:52,  2.51s/it, acc=0.8145, loss=0.6375]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 469/490 [19:45<00:52,  2.51s/it, acc=0.8144, loss=0.5929]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 470/490 [19:45<00:50,  2.51s/it, acc=0.8144, loss=0.5929]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 470/490 [19:48<00:50,  2.51s/it, acc=0.8142, loss=0.6314]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 471/490 [19:48<00:47,  2.51s/it, acc=0.8142, loss=0.6314]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 471/490 [19:50<00:47,  2.51s/it, acc=0.8144, loss=0.3759]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 472/490 [19:50<00:45,  2.51s/it, acc=0.8144, loss=0.3759]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 472/490 [19:53<00:45,  2.51s/it, acc=0.8144, loss=0.5243]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 473/490 [19:53<00:42,  2.51s/it, acc=0.8144, loss=0.5243]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 473/490 [19:55<00:42,  2.51s/it, acc=0.8144, loss=0.4886]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 474/490 [19:55<00:40,  2.51s/it, acc=0.8144, loss=0.4886]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 474/490 [19:58<00:40,  2.51s/it, acc=0.8146, loss=0.2466]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 475/490 [19:58<00:37,  2.51s/it, acc=0.8146, loss=0.2466]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 475/490 [20:00<00:37,  2.51s/it, acc=0.8145, loss=0.5502]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 476/490 [20:00<00:35,  2.52s/it, acc=0.8145, loss=0.5502]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 476/490 [20:03<00:35,  2.52s/it, acc=0.8145, loss=0.4404]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 477/490 [20:03<00:32,  2.51s/it, acc=0.8145, loss=0.4404]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 477/490 [20:05<00:32,  2.51s/it, acc=0.8145, loss=0.4971]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 478/490 [20:05<00:30,  2.51s/it, acc=0.8145, loss=0.4971]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 478/490 [20:08<00:30,  2.51s/it, acc=0.8145, loss=0.4633]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 479/490 [20:08<00:27,  2.52s/it, acc=0.8145, loss=0.4633]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 479/490 [20:10<00:27,  2.52s/it, acc=0.8145, loss=0.4147]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 480/490 [20:10<00:25,  2.52s/it, acc=0.8145, loss=0.4147]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 480/490 [20:13<00:25,  2.52s/it, acc=0.8146, loss=0.3414]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 481/490 [20:13<00:22,  2.51s/it, acc=0.8146, loss=0.3414]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 481/490 [20:15<00:22,  2.51s/it, acc=0.8146, loss=0.6096]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 482/490 [20:15<00:20,  2.52s/it, acc=0.8146, loss=0.6096]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 482/490 [20:18<00:20,  2.52s/it, acc=0.8144, loss=0.5926]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 483/490 [20:18<00:17,  2.52s/it, acc=0.8144, loss=0.5926]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 483/490 [20:20<00:17,  2.52s/it, acc=0.8144, loss=0.4670]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 484/490 [20:20<00:15,  2.52s/it, acc=0.8144, loss=0.4670]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 484/490 [20:23<00:15,  2.52s/it, acc=0.8143, loss=0.4620]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 485/490 [20:23<00:12,  2.51s/it, acc=0.8143, loss=0.4620]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 485/490 [20:25<00:12,  2.51s/it, acc=0.8144, loss=0.3506]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 486/490 [20:25<00:10,  2.51s/it, acc=0.8144, loss=0.3506]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 486/490 [20:28<00:10,  2.51s/it, acc=0.8142, loss=0.6804]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 487/490 [20:28<00:07,  2.51s/it, acc=0.8142, loss=0.6804]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 487/490 [20:30<00:07,  2.51s/it, acc=0.8143, loss=0.4502]\n",
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 488/490 [20:30<00:05,  2.51s/it, acc=0.8143, loss=0.4502]\n",
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 488/490 [20:33<00:05,  2.51s/it, acc=0.8140, loss=0.6819]\n",
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 489/490 [20:33<00:02,  2.51s/it, acc=0.8140, loss=0.6819]\n",
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 489/490 [20:34<00:02,  2.51s/it, acc=0.8141, loss=0.5258]\n",
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 490/490 [20:34<00:00,  2.17s/it, acc=0.8141, loss=0.5258]\n",
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 490/490 [20:34<00:00,  2.52s/it, acc=0.8141, loss=0.5258]\n",
            "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2956: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "Train Acc: 0.8141, Top-3 Acc: 0.9681, Log Loss: 0.5167\n",
            "[METRICS] epoch=1 train_loss=0.5167 train_acc=0.8141\n",
            "  Top-3 Accuracy: 0.9681\n",
            "  Log Loss: 0.5167\n",
            "Macro Avg    - F1: 0.8219, Precision: 0.8248, Recall: 0.8199\n",
            "  Weighted Avg - F1: 0.8150, Precision: 0.8167, Recall: 0.8141\n",
            "  Per-Class F1 Scores:\n",
            "    antelope_duiker     : F1=0.7510, Confidence=0.7889\n",
            "bird                : F1=0.8465, Confidence=0.8614\n",
            "    blank               : F1=0.6281, Confidence=0.6230\n",
            "    civet_genet         : F1=0.9050, Confidence=0.9027\n",
            "    hog                 : F1=0.9086, Confidence=0.9230\n",
            "    leopard             : F1=0.9385, Confidence=0.9357\n",
            "    monkey_prosimian    : F1=0.8073, Confidence=0.8220\n",
            "    rodent              : F1=0.7907, Confidence=0.7729\n",
            "After training GPU memory - Allocated: 3017.58 MB, Reserved: 14034.00 MB\n",
            "Validating:   0%|          | 0/26 [00:00<?, ?it/s]\n",
            "Validating:   0%|          | 0/26 [00:01<?, ?it/s, acc=0.7812, loss=0.6305]\n",
            "Validating:   4%|‚ñç         | 1/26 [00:01<00:28,  1.13s/it, acc=0.7812, loss=0.6305]\n",
            "Validating:   4%|‚ñç         | 1/26 [00:01<00:28,  1.13s/it, acc=0.7812, loss=0.5412]\n",
            "Validating:   8%|‚ñä         | 2/26 [00:01<00:22,  1.06it/s, acc=0.7812, loss=0.5412]\n",
            "Validating:   8%|‚ñä         | 2/26 [00:02<00:22,  1.06it/s, acc=0.7917, loss=0.4692]\n",
            "Validating:  12%|‚ñà‚ñè        | 3/26 [00:02<00:20,  1.13it/s, acc=0.7917, loss=0.4692]\n",
            "Validating:  12%|‚ñà‚ñè        | 3/26 [00:03<00:20,  1.13it/s, acc=0.8047, loss=0.6039]\n",
            "Validating:  15%|‚ñà‚ñå        | 4/26 [00:03<00:18,  1.16it/s, acc=0.8047, loss=0.6039]\n",
            "Validating:  15%|‚ñà‚ñå        | 4/26 [00:04<00:18,  1.16it/s, acc=0.7875, loss=0.6133]#015Validating:  19%|‚ñà‚ñâ        | 5/26 [00:04<00:17,  1.18it/s, acc=0.7875, loss=0.6133]\n",
            "Validating:  19%|‚ñà‚ñâ        | 5/26 [00:05<00:17,  1.18it/s, acc=0.8073, loss=0.2507]\n",
            "Validating:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:05<00:16,  1.19it/s, acc=0.8073, loss=0.2507]\n",
            "Validating:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:06<00:16,  1.19it/s, acc=0.8214, loss=0.2552]\n",
            "Validating:  27%|‚ñà‚ñà‚ñã       | 7/26 [00:06<00:15,  1.20it/s, acc=0.8214, loss=0.2552]\n",
            "Validating:  27%|‚ñà‚ñà‚ñã       | 7/26 [00:06<00:15,  1.20it/s, acc=0.8281, loss=0.4009]\n",
            "Validating:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:06<00:14,  1.21it/s, acc=0.8281, loss=0.4009]\n",
            "Validating:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:07<00:14,  1.21it/s, acc=0.8299, loss=0.4415]\n",
            "Validating:  35%|‚ñà‚ñà‚ñà‚ñç      | 9/26 [00:07<00:14,  1.21it/s, acc=0.8299, loss=0.4415]\n",
            "Validating:  35%|‚ñà‚ñà‚ñà‚ñç      | 9/26 [00:08<00:14,  1.21it/s, acc=0.8219, loss=0.6505]\n",
            "Validating:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:08<00:13,  1.22it/s, acc=0.8219, loss=0.6505]\n",
            "Validating:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:09<00:13,  1.22it/s, acc=0.8295, loss=0.4182]\n",
            "Validating:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 11/26 [00:09<00:12,  1.22it/s, acc=0.8295, loss=0.4182]\n",
            "Validating:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 11/26 [00:10<00:12,  1.22it/s, acc=0.8333, loss=0.3437]\n",
            "Validating:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:10<00:11,  1.22it/s, acc=0.8333, loss=0.3437]\n",
            "Validating:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:10<00:11,  1.22it/s, acc=0.8389, loss=0.3174]\n",
            "Validating:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 13/26 [00:10<00:10,  1.22it/s, acc=0.8389, loss=0.3174]\n",
            "Validating:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 13/26 [00:11<00:10,  1.22it/s, acc=0.8415, loss=0.2207]\n",
            "Validating:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:11<00:09,  1.22it/s, acc=0.8415, loss=0.2207]\n",
            "Validating:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:12<00:09,  1.22it/s, acc=0.8479, loss=0.2129]\n",
            "Validating:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 15/26 [00:12<00:08,  1.22it/s, acc=0.8479, loss=0.2129]\n",
            "Validating:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 15/26 [00:13<00:08,  1.22it/s, acc=0.8496, loss=0.3924]\n",
            "Validating:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:13<00:08,  1.22it/s, acc=0.8496, loss=0.3924]\n",
            "Validating:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:14<00:08,  1.22it/s, acc=0.8474, loss=0.5985]\n",
            "Validating:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 17/26 [00:14<00:07,  1.22it/s, acc=0.8474, loss=0.5985]\n",
            "Validating:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 17/26 [00:15<00:07,  1.22it/s, acc=0.8455, loss=0.3793]\n",
            "Validating:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:15<00:06,  1.22it/s, acc=0.8455, loss=0.3793]\n",
            "Validating:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:15<00:06,  1.22it/s, acc=0.8470, loss=0.4758]\n",
            "Validating:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 19/26 [00:15<00:05,  1.22it/s, acc=0.8470, loss=0.4758]\n",
            "Validating:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 19/26 [00:16<00:05,  1.22it/s, acc=0.8500, loss=0.2020]\n",
            "Validating:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:16<00:04,  1.22it/s, acc=0.8500, loss=0.2020]\n",
            "Validating:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:17<00:04,  1.22it/s, acc=0.8467, loss=0.3713]\n",
            "Validating:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 21/26 [00:17<00:04,  1.22it/s, acc=0.8467, loss=0.3713]\n",
            "Validating:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 21/26 [00:18<00:04,  1.22it/s, acc=0.8537, loss=0.1116]\n",
            "Validating:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:18<00:03,  1.22it/s, acc=0.8537, loss=0.1116]\n",
            "Validating:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:19<00:03,  1.22it/s, acc=0.8546, loss=0.3123]\n",
            "Validating:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 23/26 [00:19<00:02,  1.22it/s, acc=0.8546, loss=0.3123]\n",
            "Validating:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 23/26 [00:19<00:02,  1.22it/s, acc=0.8555, loss=0.2722]\n",
            "Validating:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:19<00:01,  1.22it/s, acc=0.8555, loss=0.2722]\n",
            "Validating:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:20<00:01,  1.22it/s, acc=0.8562, loss=0.2952]\n",
            "Validating:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 25/26 [00:20<00:00,  1.22it/s, acc=0.8562, loss=0.2952]\n",
            "Validating:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 25/26 [00:21<00:00,  1.22it/s, acc=0.8570, loss=0.4533]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [00:21<00:00,  1.30it/s, acc=0.8570, loss=0.4533]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [00:21<00:00,  1.21it/s, acc=0.8570, loss=0.4533]\n",
            "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2956: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "Validation Loss: 0.3931, Validation Acc: 0.8570, Top-3 Acc: 0.9891, Log Loss: 0.3931\n",
            "[METRICS] epoch=1 val_loss=0.3931 val_acc=0.8570\n",
            "  Top-3 Accuracy: 0.9891\n",
            "  Log Loss: 0.3931\n",
            "Macro Avg    - F1: 0.8675, Precision: 0.8830, Recall: 0.8618\n",
            "  Weighted Avg - F1: 0.8614, Precision: 0.8763, Recall: 0.8570\n",
            "  Per-Class F1 Scores:\n",
            "antelope_duiker     : F1=0.8356, Confidence=0.8592\n",
            "    bird                : F1=0.8917, Confidence=0.9141\n",
            "    blank               : F1=0.6815, Confidence=0.7585\n",
            "    civet_genet         : F1=0.9350, Confidence=0.9469\n",
            "    hog                 : F1=0.9583, Confidence=0.9731\n",
            "    leopard             : F1=0.9607, Confidence=0.9573\n",
            "    monkey_prosimian    : F1=0.8776, Confidence=0.8659\n",
            "    rodent              : F1=0.8000, Confidence=0.8220\n",
            "Learning Rate: 0.000098 ‚Üí 0.000090\n",
            "After validation GPU memory - Allocated: 3017.58 MB, Reserved: 14734.00 MB\n",
            "Saving best model to convnext-largeWeights_1_best.pth with val acc 0.8570\n",
            "‚úì Best model saved! (Val Acc: 0.8570), path: /opt/ml/model/convnext-largeWeights_1_best.pth\n",
            "Saving metrics to /opt/ml/model\n",
            "‚úì Metrics saved to /opt/ml/model\n",
            "  - /opt/ml/model/train_metrics_1.json\n",
            "  Total epochs logged: 2\n",
            "Saving metrics to /opt/ml/model\n",
            "‚úì Metrics saved to /opt/ml/model\n",
            "  - /opt/ml/model/val_metrics_1.json\n",
            "  Total epochs logged: 2\n",
            "Epoch 3/10\n",
            "Start of epoch GPU memory - Allocated: 3017.58 MB, Reserved: 3824.00 MB\n",
            "Training...\n",
            "Training:   0%|          | 0/490 [00:00<?, ?it/s]\n",
            "Training:   0%|          | 0/490 [00:02<?, ?it/s, acc=0.9062, loss=0.2300]\n",
            "Training:   0%|          | 1/490 [00:02<23:53,  2.93s/it, acc=0.9062, loss=0.2300]\n",
            "Training:   0%|          | 1/490 [00:05<23:53,  2.93s/it, acc=0.9062, loss=0.2971]\n",
            "Training:   0%|          | 2/490 [00:05<21:49,  2.68s/it, acc=0.9062, loss=0.2971]\n",
            "Training:   0%|          | 2/490 [00:07<21:49,  2.68s/it, acc=0.8750, loss=0.5231]\n",
            "Training:   1%|          | 3/490 [00:07<21:09,  2.61s/it, acc=0.8750, loss=0.5231]\n",
            "Training:   1%|          | 3/490 [00:10<21:09,  2.61s/it, acc=0.8672, loss=0.3566]\n",
            "Training:   1%|          | 4/490 [00:10<20:48,  2.57s/it, acc=0.8672, loss=0.3566]\n",
            "Training:   1%|          | 4/490 [00:12<20:48,  2.57s/it, acc=0.8500, loss=0.4752]\n",
            "Training:   1%|          | 5/490 [00:12<20:37,  2.55s/it, acc=0.8500, loss=0.4752]\n",
            "Training:   1%|          | 5/490 [00:15<20:37,  2.55s/it, acc=0.8542, loss=0.4119]\n",
            "Training:   1%|          | 6/490 [00:15<20:28,  2.54s/it, acc=0.8542, loss=0.4119]\n",
            "Training:   1%|          | 6/490 [00:18<20:28,  2.54s/it, acc=0.8616, loss=0.3027]\n",
            "Training:   1%|‚ñè         | 7/490 [00:18<20:21,  2.53s/it, acc=0.8616, loss=0.3027]\n",
            "Training:   1%|‚ñè         | 7/490 [00:20<20:21,  2.53s/it, acc=0.8594, loss=0.4508]\n",
            "Training:   2%|‚ñè         | 8/490 [00:20<20:16,  2.52s/it, acc=0.8594, loss=0.4508]\n",
            "Training:   2%|‚ñè         | 8/490 [00:23<20:16,  2.52s/it, acc=0.8542, loss=0.5406]\n",
            "Training:   2%|‚ñè         | 9/490 [00:23<20:12,  2.52s/it, acc=0.8542, loss=0.5406]\n",
            "Training:   2%|‚ñè         | 9/490 [00:25<20:12,  2.52s/it, acc=0.8406, loss=0.8015]\n",
            "Training:   2%|‚ñè         | 10/490 [00:25<20:09,  2.52s/it, acc=0.8406, loss=0.8015]\n",
            "Training:   2%|‚ñè         | 10/490 [00:28<20:09,  2.52s/it, acc=0.8438, loss=0.3088]\n",
            "Training:   2%|‚ñè         | 11/490 [00:28<20:06,  2.52s/it, acc=0.8438, loss=0.3088]\n",
            "Training:   2%|‚ñè         | 11/490 [00:30<20:06,  2.52s/it, acc=0.8490, loss=0.3448]\n",
            "Training:   2%|‚ñè         | 12/490 [00:30<20:03,  2.52s/it, acc=0.8490, loss=0.3448]\n",
            "Training:   2%|‚ñè         | 12/490 [00:33<20:03,  2.52s/it, acc=0.8510, loss=0.3200]\n",
            "Training:   3%|‚ñé         | 13/490 [00:33<20:01,  2.52s/it, acc=0.8510, loss=0.3200]\n",
            "Training:   3%|‚ñé         | 13/490 [00:35<20:01,  2.52s/it, acc=0.8438, loss=0.4586]\n",
            "Training:   3%|‚ñé         | 14/490 [00:35<19:57,  2.52s/it, acc=0.8438, loss=0.4586]\n",
            "Training:   3%|‚ñé         | 14/490 [00:38<19:57,  2.52s/it, acc=0.8500, loss=0.3392]\n",
            "Training:   3%|‚ñé         | 15/490 [00:38<19:54,  2.52s/it, acc=0.8500, loss=0.3392]\n",
            "Training:   3%|‚ñé         | 15/490 [00:40<19:54,  2.52s/it, acc=0.8496, loss=0.3850]\n",
            "Training:   3%|‚ñé         | 16/490 [00:40<19:51,  2.51s/it, acc=0.8496, loss=0.3850]\n",
            "Training:   3%|‚ñé         | 16/490 [00:43<19:51,  2.51s/it, acc=0.8474, loss=0.4929]\n",
            "Training:   3%|‚ñé         | 17/490 [00:43<19:49,  2.52s/it, acc=0.8474, loss=0.4929]\n",
            "Training:   3%|‚ñé         | 17/490 [00:45<19:49,  2.52s/it, acc=0.8385, loss=0.7169]\n",
            "Training:   4%|‚ñé         | 18/490 [00:45<19:46,  2.51s/it, acc=0.8385, loss=0.7169]\n",
            "Training:   4%|‚ñé         | 18/490 [00:48<19:46,  2.51s/it, acc=0.8405, loss=0.2228]\n",
            "Training:   4%|‚ñç         | 19/490 [00:48<19:44,  2.51s/it, acc=0.8405, loss=0.2228]\n",
            "Training:   4%|‚ñç         | 19/490 [00:50<19:44,  2.51s/it, acc=0.8406, loss=0.3187]\n",
            "Training:   4%|‚ñç         | 20/490 [00:50<19:41,  2.51s/it, acc=0.8406, loss=0.3187]\n",
            "Training:   4%|‚ñç         | 20/490 [00:53<19:41,  2.51s/it, acc=0.8393, loss=0.5894]\n",
            "Training:   4%|‚ñç         | 21/490 [00:53<19:39,  2.51s/it, acc=0.8393, loss=0.5894]\n",
            "Training:   4%|‚ñç         | 21/490 [00:55<19:39,  2.51s/it, acc=0.8395, loss=0.3831]\n",
            "Training:   4%|‚ñç         | 22/490 [00:55<19:37,  2.52s/it, acc=0.8395, loss=0.3831]\n",
            "Training:   4%|‚ñç         | 22/490 [00:58<19:37,  2.52s/it, acc=0.8356, loss=0.4885]\n",
            "Training:   5%|‚ñç         | 23/490 [00:58<19:35,  2.52s/it, acc=0.8356, loss=0.4885]\n",
            "Training:   5%|‚ñç         | 23/490 [01:00<19:35,  2.52s/it, acc=0.8333, loss=0.6061]\n",
            "Training:   5%|‚ñç         | 24/490 [01:00<19:34,  2.52s/it, acc=0.8333, loss=0.6061]\n",
            "Training:   5%|‚ñç         | 24/490 [01:03<19:34,  2.52s/it, acc=0.8325, loss=0.5065]\n",
            "Training:   5%|‚ñå         | 25/490 [01:03<19:31,  2.52s/it, acc=0.8325, loss=0.5065]\n",
            "Training:   5%|‚ñå         | 25/490 [01:05<19:31,  2.52s/it, acc=0.8365, loss=0.2242]\n",
            "Training:   5%|‚ñå         | 26/490 [01:05<19:28,  2.52s/it, acc=0.8365, loss=0.2242]\n",
            "Training:   5%|‚ñå         | 26/490 [01:08<19:28,  2.52s/it, acc=0.8333, loss=0.4494]\n",
            "Training:   6%|‚ñå         | 27/490 [01:08<19:25,  2.52s/it, acc=0.8333, loss=0.4494]\n",
            "Training:   6%|‚ñå         | 27/490 [01:10<19:25,  2.52s/it, acc=0.8270, loss=0.7997]\n",
            "Training:   6%|‚ñå         | 28/490 [01:10<19:22,  2.52s/it, acc=0.8270, loss=0.7997]\n",
            "Training:   6%|‚ñå         | 28/490 [01:13<19:22,  2.52s/it, acc=0.8297, loss=0.2748]\n",
            "Training:   6%|‚ñå         | 29/490 [01:13<19:21,  2.52s/it, acc=0.8297, loss=0.2748]\n",
            "Training:   6%|‚ñå         | 29/490 [01:15<19:21,  2.52s/it, acc=0.8271, loss=0.5422]\n",
            "Training:   6%|‚ñå         | 30/490 [01:15<19:17,  2.52s/it, acc=0.8271, loss=0.5422]\n",
            "Training:   6%|‚ñå         | 30/490 [01:18<19:17,  2.52s/it, acc=0.8286, loss=0.3066]\n",
            "Training:   6%|‚ñã         | 31/490 [01:18<19:16,  2.52s/it, acc=0.8286, loss=0.3066]\n",
            "Training:   6%|‚ñã         | 31/490 [01:20<19:16,  2.52s/it, acc=0.8281, loss=0.3858]\n",
            "Training:   7%|‚ñã         | 32/490 [01:20<19:14,  2.52s/it, acc=0.8281, loss=0.3858]\n",
            "Training:   7%|‚ñã         | 32/490 [01:23<19:14,  2.52s/it, acc=0.8277, loss=0.4471]\n",
            "Training:   7%|‚ñã         | 33/490 [01:23<19:11,  2.52s/it, acc=0.8277, loss=0.4471]\n",
            "Training:   7%|‚ñã         | 33/490 [01:25<19:11,  2.52s/it, acc=0.8309, loss=0.2983]\n",
            "Training:   7%|‚ñã         | 34/490 [01:25<19:09,  2.52s/it, acc=0.8309, loss=0.2983]\n",
            "Training:   7%|‚ñã         | 34/490 [01:28<19:09,  2.52s/it, acc=0.8304, loss=0.4607]\n",
            "Training:   7%|‚ñã         | 35/490 [01:28<19:06,  2.52s/it, acc=0.8304, loss=0.4607]\n",
            "Training:   7%|‚ñã         | 35/490 [01:31<19:06,  2.52s/it, acc=0.8307, loss=0.3493]\n",
            "Training:   7%|‚ñã         | 36/490 [01:31<19:04,  2.52s/it, acc=0.8307, loss=0.3493]\n",
            "Training:   7%|‚ñã         | 36/490 [01:33<19:04,  2.52s/it, acc=0.8319, loss=0.3090]\n",
            "Training:   8%|‚ñä         | 37/490 [01:33<19:02,  2.52s/it, acc=0.8319, loss=0.3090]\n",
            "Training:   8%|‚ñä         | 37/490 [01:36<19:02,  2.52s/it, acc=0.8331, loss=0.1815]\n",
            "Training:   8%|‚ñä         | 38/490 [01:36<18:59,  2.52s/it, acc=0.8331, loss=0.1815]\n",
            "Training:   8%|‚ñä         | 38/490 [01:38<18:59,  2.52s/it, acc=0.8325, loss=0.5031]\n",
            "Training:   8%|‚ñä         | 39/490 [01:38<18:57,  2.52s/it, acc=0.8325, loss=0.5031]\n",
            "Training:   8%|‚ñä         | 39/490 [01:41<18:57,  2.52s/it, acc=0.8313, loss=0.5887]\n",
            "Training:   8%|‚ñä         | 40/490 [01:41<18:54,  2.52s/it, acc=0.8313, loss=0.5887]\n",
            "Training:   8%|‚ñä         | 40/490 [01:43<18:54,  2.52s/it, acc=0.8308, loss=0.6059]\n",
            "Training:   8%|‚ñä         | 41/490 [01:43<18:52,  2.52s/it, acc=0.8308, loss=0.6059]\n",
            "Training:   8%|‚ñä         | 41/490 [01:46<18:52,  2.52s/it, acc=0.8318, loss=0.4447]\n",
            "Training:   9%|‚ñä         | 42/490 [01:46<18:48,  2.52s/it, acc=0.8318, loss=0.4447]\n",
            "Training:   9%|‚ñä         | 42/490 [01:48<18:48,  2.52s/it, acc=0.8328, loss=0.2800]\n",
            "Training:   9%|‚ñâ         | 43/490 [01:48<18:46,  2.52s/it, acc=0.8328, loss=0.2800]\n",
            "Training:   9%|‚ñâ         | 43/490 [01:51<18:46,  2.52s/it, acc=0.8352, loss=0.2261]\n",
            "Training:   9%|‚ñâ         | 44/490 [01:51<18:43,  2.52s/it, acc=0.8352, loss=0.2261]\n",
            "Training:   9%|‚ñâ         | 44/490 [01:53<18:43,  2.52s/it, acc=0.8326, loss=0.5798]\n",
            "Training:   9%|‚ñâ         | 45/490 [01:53<18:41,  2.52s/it, acc=0.8326, loss=0.5798]\n",
            "Training:   9%|‚ñâ         | 45/490 [01:56<18:41,  2.52s/it, acc=0.8342, loss=0.3051]\n",
            "Training:   9%|‚ñâ         | 46/490 [01:56<18:39,  2.52s/it, acc=0.8342, loss=0.3051]\n",
            "Training:   9%|‚ñâ         | 46/490 [01:58<18:39,  2.52s/it, acc=0.8338, loss=0.4832]\n",
            "Training:  10%|‚ñâ         | 47/490 [01:58<18:37,  2.52s/it, acc=0.8338, loss=0.4832]\n",
            "Training:  10%|‚ñâ         | 47/490 [02:01<18:37,  2.52s/it, acc=0.8353, loss=0.2559]\n",
            "Training:  10%|‚ñâ         | 48/490 [02:01<18:34,  2.52s/it, acc=0.8353, loss=0.2559]\n",
            "Training:  10%|‚ñâ         | 48/490 [02:03<18:34,  2.52s/it, acc=0.8348, loss=0.5968]\n",
            "Training:  10%|‚ñà         | 49/490 [02:03<18:31,  2.52s/it, acc=0.8348, loss=0.5968]\n",
            "Training:  10%|‚ñà         | 49/490 [02:06<18:31,  2.52s/it, acc=0.8344, loss=0.5172]\n",
            "Training:  10%|‚ñà         | 50/490 [02:06<18:30,  2.52s/it, acc=0.8344, loss=0.5172]\n",
            "Training:  10%|‚ñà         | 50/490 [02:08<18:30,  2.52s/it, acc=0.8352, loss=0.2406]\n",
            "Training:  10%|‚ñà         | 51/490 [02:08<18:27,  2.52s/it, acc=0.8352, loss=0.2406]\n",
            "Training:  10%|‚ñà         | 51/490 [02:11<18:27,  2.52s/it, acc=0.8383, loss=0.1428]\n",
            "Training:  11%|‚ñà         | 52/490 [02:11<18:24,  2.52s/it, acc=0.8383, loss=0.1428]\n",
            "Training:  11%|‚ñà         | 52/490 [02:13<18:24,  2.52s/it, acc=0.8390, loss=0.4373]\n",
            "Training:  11%|‚ñà         | 53/490 [02:13<18:23,  2.52s/it, acc=0.8390, loss=0.4373]\n",
            "Training:  11%|‚ñà         | 53/490 [02:16<18:23,  2.52s/it, acc=0.8403, loss=0.2880]\n",
            "Training:  11%|‚ñà         | 54/490 [02:16<18:19,  2.52s/it, acc=0.8403, loss=0.2880]\n",
            "Training:  11%|‚ñà         | 54/490 [02:18<18:19,  2.52s/it, acc=0.8409, loss=0.4262]\n",
            "Training:  11%|‚ñà         | 55/490 [02:18<18:18,  2.52s/it, acc=0.8409, loss=0.4262]\n",
            "Training:  11%|‚ñà         | 55/490 [02:21<18:18,  2.52s/it, acc=0.8421, loss=0.3425]\n",
            "Training:  11%|‚ñà‚ñè        | 56/490 [02:21<18:15,  2.52s/it, acc=0.8421, loss=0.3425]\n",
            "Training:  11%|‚ñà‚ñè        | 56/490 [02:23<18:15,  2.52s/it, acc=0.8427, loss=0.3049]\n",
            "Training:  12%|‚ñà‚ñè        | 57/490 [02:23<18:12,  2.52s/it, acc=0.8427, loss=0.3049]\n",
            "Training:  12%|‚ñà‚ñè        | 57/490 [02:26<18:12,  2.52s/it, acc=0.8416, loss=0.5613]\n",
            "Training:  12%|‚ñà‚ñè        | 58/490 [02:26<18:10,  2.52s/it, acc=0.8416, loss=0.5613]\n",
            "Training:  12%|‚ñà‚ñè        | 58/490 [02:29<18:10,  2.52s/it, acc=0.8416, loss=0.5395]\n",
            "Training:  12%|‚ñà‚ñè        | 59/490 [02:29<18:07,  2.52s/it, acc=0.8416, loss=0.5395]\n",
            "Training:  12%|‚ñà‚ñè        | 59/490 [02:31<18:07,  2.52s/it, acc=0.8401, loss=0.6122]\n",
            "Training:  12%|‚ñà‚ñè        | 60/490 [02:31<18:05,  2.52s/it, acc=0.8401, loss=0.6122]\n",
            "Training:  12%|‚ñà‚ñè        | 60/490 [02:34<18:05,  2.52s/it, acc=0.8402, loss=0.4259]\n",
            "Training:  12%|‚ñà‚ñè        | 61/490 [02:34<18:02,  2.52s/it, acc=0.8402, loss=0.4259]\n",
            "Training:  12%|‚ñà‚ñè        | 61/490 [02:36<18:02,  2.52s/it, acc=0.8402, loss=0.3923]\n",
            "Training:  13%|‚ñà‚ñé        | 62/490 [02:36<17:59,  2.52s/it, acc=0.8402, loss=0.3923]\n",
            "Training:  13%|‚ñà‚ñé        | 62/490 [02:39<17:59,  2.52s/it, acc=0.8408, loss=0.3491]\n",
            "Training:  13%|‚ñà‚ñé        | 63/490 [02:39<17:57,  2.52s/it, acc=0.8408, loss=0.3491]\n",
            "Training:  13%|‚ñà‚ñé        | 63/490 [02:41<17:57,  2.52s/it, acc=0.8418, loss=0.2733]\n",
            "Training:  13%|‚ñà‚ñé        | 64/490 [02:41<17:54,  2.52s/it, acc=0.8418, loss=0.2733]\n",
            "Training:  13%|‚ñà‚ñé        | 64/490 [02:44<17:54,  2.52s/it, acc=0.8413, loss=0.4371]\n",
            "Training:  13%|‚ñà‚ñé        | 65/490 [02:44<17:51,  2.52s/it, acc=0.8413, loss=0.4371]\n",
            "Training:  13%|‚ñà‚ñé        | 65/490 [02:46<17:51,  2.52s/it, acc=0.8395, loss=0.5952]\n",
            "Training:  13%|‚ñà‚ñé        | 66/490 [02:46<17:50,  2.53s/it, acc=0.8395, loss=0.5952]\n",
            "Training:  13%|‚ñà‚ñé        | 66/490 [02:49<17:50,  2.53s/it, acc=0.8405, loss=0.3814]\n",
            "Training:  14%|‚ñà‚ñé        | 67/490 [02:49<17:47,  2.52s/it, acc=0.8405, loss=0.3814]\n",
            "Training:  14%|‚ñà‚ñé        | 67/490 [02:51<17:47,  2.52s/it, acc=0.8405, loss=0.3845]\n",
            "Training:  14%|‚ñà‚ñç        | 68/490 [02:51<17:45,  2.52s/it, acc=0.8405, loss=0.3845]\n",
            "Training:  14%|‚ñà‚ñç        | 68/490 [02:54<17:45,  2.52s/it, acc=0.8401, loss=0.3254]\n",
            "Training:  14%|‚ñà‚ñç        | 69/490 [02:54<17:41,  2.52s/it, acc=0.8401, loss=0.3254]\n",
            "Training:  14%|‚ñà‚ñç        | 69/490 [02:56<17:41,  2.52s/it, acc=0.8411, loss=0.1841]\n",
            "Training:  14%|‚ñà‚ñç        | 70/490 [02:56<17:39,  2.52s/it, acc=0.8411, loss=0.1841]\n",
            "Training:  14%|‚ñà‚ñç        | 70/490 [02:59<17:39,  2.52s/it, acc=0.8407, loss=0.6239]\n",
            "Training:  14%|‚ñà‚ñç        | 71/490 [02:59<17:36,  2.52s/it, acc=0.8407, loss=0.6239]\n",
            "Training:  14%|‚ñà‚ñç        | 71/490 [03:01<17:36,  2.52s/it, acc=0.8416, loss=0.3204]\n",
            "Training:  15%|‚ñà‚ñç        | 72/490 [03:01<17:34,  2.52s/it, acc=0.8416, loss=0.3204]\n",
            "Training:  15%|‚ñà‚ñç        | 72/490 [03:04<17:34,  2.52s/it, acc=0.8412, loss=0.5375]\n",
            "Training:  15%|‚ñà‚ñç        | 73/490 [03:04<17:32,  2.52s/it, acc=0.8412, loss=0.5375]\n",
            "Training:  15%|‚ñà‚ñç        | 73/490 [03:06<17:32,  2.52s/it, acc=0.8421, loss=0.2293]\n",
            "Training:  15%|‚ñà‚ñå        | 74/490 [03:06<17:29,  2.52s/it, acc=0.8421, loss=0.2293]\n",
            "Training:  15%|‚ñà‚ñå        | 74/490 [03:09<17:29,  2.52s/it, acc=0.8429, loss=0.2374]\n",
            "Training:  15%|‚ñà‚ñå        | 75/490 [03:09<17:26,  2.52s/it, acc=0.8429, loss=0.2374]\n",
            "Training:  15%|‚ñà‚ñå        | 75/490 [03:11<17:26,  2.52s/it, acc=0.8438, loss=0.2758]\n",
            "Training:  16%|‚ñà‚ñå        | 76/490 [03:11<17:24,  2.52s/it, acc=0.8438, loss=0.2758]\n",
            "Training:  16%|‚ñà‚ñå        | 76/490 [03:14<17:24,  2.52s/it, acc=0.8442, loss=0.2833]\n",
            "Training:  16%|‚ñà‚ñå        | 77/490 [03:14<17:22,  2.52s/it, acc=0.8442, loss=0.2833]\n",
            "Training:  16%|‚ñà‚ñå        | 77/490 [03:16<17:22,  2.52s/it, acc=0.8454, loss=0.2065]\n",
            "Training:  16%|‚ñà‚ñå        | 78/490 [03:16<17:20,  2.52s/it, acc=0.8454, loss=0.2065]\n",
            "Training:  16%|‚ñà‚ñå        | 78/490 [03:19<17:20,  2.52s/it, acc=0.8430, loss=0.8989]\n",
            "Training:  16%|‚ñà‚ñå        | 79/490 [03:19<17:16,  2.52s/it, acc=0.8430, loss=0.8989]\n",
            "Training:  16%|‚ñà‚ñå        | 79/490 [03:22<17:16,  2.52s/it, acc=0.8438, loss=0.3255]\n",
            "Training:  16%|‚ñà‚ñã        | 80/490 [03:22<17:14,  2.52s/it, acc=0.8438, loss=0.3255]\n",
            "Training:  16%|‚ñà‚ñã        | 80/490 [03:24<17:14,  2.52s/it, acc=0.8441, loss=0.3303]\n",
            "Training:  17%|‚ñà‚ñã        | 81/490 [03:24<17:11,  2.52s/it, acc=0.8441, loss=0.3303]\n",
            "Training:  17%|‚ñà‚ñã        | 81/490 [03:27<17:11,  2.52s/it, acc=0.8438, loss=0.4942]\n",
            "Training:  17%|‚ñà‚ñã        | 82/490 [03:27<17:09,  2.52s/it, acc=0.8438, loss=0.4942]\n",
            "Training:  17%|‚ñà‚ñã        | 82/490 [03:29<17:09,  2.52s/it, acc=0.8449, loss=0.3190]\n",
            "Training:  17%|‚ñà‚ñã        | 83/490 [03:29<17:07,  2.53s/it, acc=0.8449, loss=0.3190]\n",
            "Training:  17%|‚ñà‚ñã        | 83/490 [03:32<17:07,  2.53s/it, acc=0.8445, loss=0.3973]\n",
            "Training:  17%|‚ñà‚ñã        | 84/490 [03:32<17:04,  2.52s/it, acc=0.8445, loss=0.3973]\n",
            "Training:  17%|‚ñà‚ñã        | 84/490 [03:34<17:04,  2.52s/it, acc=0.8452, loss=0.2455]\n",
            "Training:  17%|‚ñà‚ñã        | 85/490 [03:34<17:01,  2.52s/it, acc=0.8452, loss=0.2455]\n",
            "Training:  17%|‚ñà‚ñã        | 85/490 [03:37<17:01,  2.52s/it, acc=0.8441, loss=0.5439]\n",
            "Training:  18%|‚ñà‚ñä        | 86/490 [03:37<16:59,  2.52s/it, acc=0.8441, loss=0.5439]\n",
            "Training:  18%|‚ñà‚ñä        | 86/490 [03:39<16:59,  2.52s/it, acc=0.8445, loss=0.4203]\n",
            "Training:  18%|‚ñà‚ñä        | 87/490 [03:39<16:56,  2.52s/it, acc=0.8445, loss=0.4203]\n",
            "Training:  18%|‚ñà‚ñä        | 87/490 [03:42<16:56,  2.52s/it, acc=0.8438, loss=0.5225]\n",
            "Training:  18%|‚ñà‚ñä        | 88/490 [03:42<16:53,  2.52s/it, acc=0.8438, loss=0.5225]\n",
            "Training:  18%|‚ñà‚ñä        | 88/490 [03:44<16:53,  2.52s/it, acc=0.8427, loss=0.5004]\n",
            "Training:  18%|‚ñà‚ñä        | 89/490 [03:44<16:51,  2.52s/it, acc=0.8427, loss=0.5004]\n",
            "Training:  18%|‚ñà‚ñä        | 89/490 [03:47<16:51,  2.52s/it, acc=0.8431, loss=0.4773]\n",
            "Training:  18%|‚ñà‚ñä        | 90/490 [03:47<16:48,  2.52s/it, acc=0.8431, loss=0.4773]\n",
            "Training:  18%|‚ñà‚ñä        | 90/490 [03:49<16:48,  2.52s/it, acc=0.8431, loss=0.5965]\n",
            "Training:  19%|‚ñà‚ñä        | 91/490 [03:49<16:45,  2.52s/it, acc=0.8431, loss=0.5965]\n",
            "Training:  19%|‚ñà‚ñä        | 91/490 [03:52<16:45,  2.52s/it, acc=0.8424, loss=0.4718]\n",
            "Training:  19%|‚ñà‚ñâ        | 92/490 [03:52<16:42,  2.52s/it, acc=0.8424, loss=0.4718]\n",
            "Training:  19%|‚ñà‚ñâ        | 92/490 [03:54<16:42,  2.52s/it, acc=0.8411, loss=0.5409]\n",
            "Training:  19%|‚ñà‚ñâ        | 93/490 [03:54<16:40,  2.52s/it, acc=0.8411, loss=0.5409]\n",
            "Training:  19%|‚ñà‚ñâ        | 93/490 [03:57<16:40,  2.52s/it, acc=0.8414, loss=0.2804]\n",
            "Training:  19%|‚ñà‚ñâ        | 94/490 [03:57<16:36,  2.52s/it, acc=0.8414, loss=0.2804]\n",
            "Training:  19%|‚ñà‚ñâ        | 94/490 [03:59<16:36,  2.52s/it, acc=0.8418, loss=0.2652]\n",
            "Training:  19%|‚ñà‚ñâ        | 95/490 [03:59<16:34,  2.52s/it, acc=0.8418, loss=0.2652]\n",
            "Training:  19%|‚ñà‚ñâ        | 95/490 [04:02<16:34,  2.52s/it, acc=0.8428, loss=0.3767]\n",
            "Training:  20%|‚ñà‚ñâ        | 96/490 [04:02<16:32,  2.52s/it, acc=0.8428, loss=0.3767]\n",
            "Training:  20%|‚ñà‚ñâ        | 96/490 [04:04<16:32,  2.52s/it, acc=0.8434, loss=0.3439]\n",
            "Training:  20%|‚ñà‚ñâ        | 97/490 [04:04<16:29,  2.52s/it, acc=0.8434, loss=0.3439]\n",
            "Training:  20%|‚ñà‚ñâ        | 97/490 [04:07<16:29,  2.52s/it, acc=0.8444, loss=0.2730]\n",
            "Training:  20%|‚ñà‚ñà        | 98/490 [04:07<16:27,  2.52s/it, acc=0.8444, loss=0.2730]\n",
            "Training:  20%|‚ñà‚ñà        | 98/490 [04:09<16:27,  2.52s/it, acc=0.8447, loss=0.3543]\n",
            "Training:  20%|‚ñà‚ñà        | 99/490 [04:09<16:25,  2.52s/it, acc=0.8447, loss=0.3543]\n",
            "Training:  20%|‚ñà‚ñà        | 99/490 [04:12<16:25,  2.52s/it, acc=0.8450, loss=0.3745]\n",
            "Training:  20%|‚ñà‚ñà        | 100/490 [04:12<16:22,  2.52s/it, acc=0.8450, loss=0.3745]\n",
            "Training:  20%|‚ñà‚ñà        | 100/490 [04:14<16:22,  2.52s/it, acc=0.8459, loss=0.2404]\n",
            "Training:  21%|‚ñà‚ñà        | 101/490 [04:14<16:19,  2.52s/it, acc=0.8459, loss=0.2404]\n",
            "Training:  21%|‚ñà‚ñà        | 101/490 [04:17<16:19,  2.52s/it, acc=0.8462, loss=0.3563]\n",
            "Training:  21%|‚ñà‚ñà        | 102/490 [04:17<16:16,  2.52s/it, acc=0.8462, loss=0.3563]\n",
            "Training:  21%|‚ñà‚ñà        | 102/490 [04:19<16:16,  2.52s/it, acc=0.8462, loss=0.3508]\n",
            "Training:  21%|‚ñà‚ñà        | 103/490 [04:19<16:13,  2.52s/it, acc=0.8462, loss=0.3508]\n",
            "Training:  21%|‚ñà‚ñà        | 103/490 [04:22<16:13,  2.52s/it, acc=0.8462, loss=0.4041]\n",
            "Training:  21%|‚ñà‚ñà        | 104/490 [04:22<16:11,  2.52s/it, acc=0.8462, loss=0.4041]\n",
            "Training:  21%|‚ñà‚ñà        | 104/490 [04:24<16:11,  2.52s/it, acc=0.8467, loss=0.2846]\n",
            "Training:  21%|‚ñà‚ñà‚ñè       | 105/490 [04:24<16:08,  2.52s/it, acc=0.8467, loss=0.2846]\n",
            "Training:  21%|‚ñà‚ñà‚ñè       | 105/490 [04:27<16:08,  2.52s/it, acc=0.8479, loss=0.1609]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 106/490 [04:27<16:06,  2.52s/it, acc=0.8479, loss=0.1609]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 106/490 [04:30<16:06,  2.52s/it, acc=0.8481, loss=0.2060]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 107/490 [04:30<16:03,  2.52s/it, acc=0.8481, loss=0.2060]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 107/490 [04:32<16:03,  2.52s/it, acc=0.8492, loss=0.1621]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 108/490 [04:32<16:01,  2.52s/it, acc=0.8492, loss=0.1621]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 108/490 [04:35<16:01,  2.52s/it, acc=0.8498, loss=0.2861]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 109/490 [04:35<15:57,  2.51s/it, acc=0.8498, loss=0.2861]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 109/490 [04:37<15:57,  2.51s/it, acc=0.8497, loss=0.3640]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 110/490 [04:37<15:55,  2.51s/it, acc=0.8497, loss=0.3640]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 110/490 [04:40<15:55,  2.51s/it, acc=0.8499, loss=0.3573]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 111/490 [04:40<15:52,  2.51s/it, acc=0.8499, loss=0.3573]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 111/490 [04:42<15:52,  2.51s/it, acc=0.8491, loss=0.6355]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 112/490 [04:42<15:50,  2.51s/it, acc=0.8491, loss=0.6355]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 112/490 [04:45<15:50,  2.51s/it, acc=0.8493, loss=0.4211]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 113/490 [04:45<15:48,  2.52s/it, acc=0.8493, loss=0.4211]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 113/490 [04:47<15:48,  2.52s/it, acc=0.8492, loss=0.4067]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 114/490 [04:47<15:45,  2.51s/it, acc=0.8492, loss=0.4067]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 114/490 [04:50<15:45,  2.51s/it, acc=0.8492, loss=0.5877]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 115/490 [04:50<15:42,  2.51s/it, acc=0.8492, loss=0.5877]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 115/490 [04:52<15:42,  2.51s/it, acc=0.8491, loss=0.4475]\n",
            "Training:  24%|‚ñà‚ñà‚ñé       | 116/490 [04:52<15:39,  2.51s/it, acc=0.8491, loss=0.4475]\n",
            "Training:  24%|‚ñà‚ñà‚ñé       | 116/490 [04:55<15:39,  2.51s/it, acc=0.8483, loss=0.6070]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 117/490 [04:55<15:36,  2.51s/it, acc=0.8483, loss=0.6070]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 117/490 [04:57<15:36,  2.51s/it, acc=0.8490, loss=0.2540]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 118/490 [04:57<15:34,  2.51s/it, acc=0.8490, loss=0.2540]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 118/490 [05:00<15:34,  2.51s/it, acc=0.8498, loss=0.2612]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 119/490 [05:00<15:31,  2.51s/it, acc=0.8498, loss=0.2612]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 119/490 [05:02<15:31,  2.51s/it, acc=0.8500, loss=0.2312]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 120/490 [05:02<15:29,  2.51s/it, acc=0.8500, loss=0.2312]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 120/490 [05:05<15:29,  2.51s/it, acc=0.8497, loss=0.5394]\n",
            "Training:  25%|‚ñà‚ñà‚ñç       | 121/490 [05:05<15:26,  2.51s/it, acc=0.8497, loss=0.5394]\n",
            "Training:  25%|‚ñà‚ñà‚ñç       | 121/490 [05:07<15:26,  2.51s/it, acc=0.8494, loss=0.4918]\n",
            "Training:  25%|‚ñà‚ñà‚ñç       | 122/490 [05:07<15:23,  2.51s/it, acc=0.8494, loss=0.4918]\n",
            "Training:  25%|‚ñà‚ñà‚ñç       | 122/490 [05:10<15:23,  2.51s/it, acc=0.8493, loss=0.3156]\n",
            "Training:  25%|‚ñà‚ñà‚ñå       | 123/490 [05:10<15:21,  2.51s/it, acc=0.8493, loss=0.3156]\n",
            "Training:  25%|‚ñà‚ñà‚ñå       | 123/490 [05:12<15:21,  2.51s/it, acc=0.8495, loss=0.4252]\n",
            "Training:  25%|‚ñà‚ñà‚ñå       | 124/490 [05:12<15:19,  2.51s/it, acc=0.8495, loss=0.4252]\n",
            "Training:  25%|‚ñà‚ñà‚ñå       | 124/490 [05:15<15:19,  2.51s/it, acc=0.8495, loss=0.3123]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 125/490 [05:15<15:17,  2.51s/it, acc=0.8495, loss=0.3123]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 125/490 [05:17<15:17,  2.51s/it, acc=0.8495, loss=0.3473]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 126/490 [05:17<15:14,  2.51s/it, acc=0.8495, loss=0.3473]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 126/490 [05:20<15:14,  2.51s/it, acc=0.8499, loss=0.3560]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 127/490 [05:20<15:12,  2.51s/it, acc=0.8499, loss=0.3560]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 127/490 [05:22<15:12,  2.51s/it, acc=0.8501, loss=0.3080]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 128/490 [05:22<15:09,  2.51s/it, acc=0.8501, loss=0.3080]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 128/490 [05:25<15:09,  2.51s/it, acc=0.8505, loss=0.3040]\n",
            "Training:  26%|‚ñà‚ñà‚ñã       | 129/490 [05:25<15:07,  2.51s/it, acc=0.8505, loss=0.3040]\n",
            "Training:  26%|‚ñà‚ñà‚ñã       | 129/490 [05:27<15:07,  2.51s/it, acc=0.8507, loss=0.2905]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 130/490 [05:27<15:03,  2.51s/it, acc=0.8507, loss=0.2905]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 130/490 [05:30<15:03,  2.51s/it, acc=0.8509, loss=0.4204]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 131/490 [05:30<15:02,  2.51s/it, acc=0.8509, loss=0.4204]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 131/490 [05:32<15:02,  2.51s/it, acc=0.8511, loss=0.3888]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 132/490 [05:32<14:59,  2.51s/it, acc=0.8511, loss=0.3888]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 132/490 [05:35<14:59,  2.51s/it, acc=0.8510, loss=0.4649]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 133/490 [05:35<14:56,  2.51s/it, acc=0.8510, loss=0.4649]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 133/490 [05:37<14:56,  2.51s/it, acc=0.8512, loss=0.4331]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 134/490 [05:37<14:53,  2.51s/it, acc=0.8512, loss=0.4331]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 134/490 [05:40<14:53,  2.51s/it, acc=0.8509, loss=0.6621]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 135/490 [05:40<14:50,  2.51s/it, acc=0.8509, loss=0.6621]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 135/490 [05:42<14:50,  2.51s/it, acc=0.8511, loss=0.3492]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 136/490 [05:42<14:48,  2.51s/it, acc=0.8511, loss=0.3492]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 136/490 [05:45<14:48,  2.51s/it, acc=0.8506, loss=0.5648]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 137/490 [05:45<14:45,  2.51s/it, acc=0.8506, loss=0.5648]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 137/490 [05:47<14:45,  2.51s/it, acc=0.8499, loss=0.5450]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 138/490 [05:47<14:43,  2.51s/it, acc=0.8499, loss=0.5450]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 138/490 [05:50<14:43,  2.51s/it, acc=0.8494, loss=0.5061]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 139/490 [05:50<14:48,  2.53s/it, acc=0.8494, loss=0.5061]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 139/490 [05:52<14:48,  2.53s/it, acc=0.8489, loss=0.4715]\n",
            "Training:  29%|‚ñà‚ñà‚ñä       | 140/490 [05:52<14:43,  2.52s/it, acc=0.8489, loss=0.4715]\n",
            "Training:  29%|‚ñà‚ñà‚ñä       | 140/490 [05:55<14:43,  2.52s/it, acc=0.8491, loss=0.2460]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 141/490 [05:55<14:39,  2.52s/it, acc=0.8491, loss=0.2460]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 141/490 [05:57<14:39,  2.52s/it, acc=0.8488, loss=0.4446]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 142/490 [05:57<14:36,  2.52s/it, acc=0.8488, loss=0.4446]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 142/490 [06:00<14:36,  2.52s/it, acc=0.8492, loss=0.2905]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 143/490 [06:00<14:33,  2.52s/it, acc=0.8492, loss=0.2905]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 143/490 [06:03<14:33,  2.52s/it, acc=0.8492, loss=0.3484]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 144/490 [06:03<14:31,  2.52s/it, acc=0.8492, loss=0.3484]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 144/490 [06:05<14:31,  2.52s/it, acc=0.8487, loss=0.5571]\n",
            "Training:  30%|‚ñà‚ñà‚ñâ       | 145/490 [06:05<14:27,  2.52s/it, acc=0.8487, loss=0.5571]\n",
            "Training:  30%|‚ñà‚ñà‚ñâ       | 145/490 [06:08<14:27,  2.52s/it, acc=0.8482, loss=0.6037]\n",
            "Training:  30%|‚ñà‚ñà‚ñâ       | 146/490 [06:08<14:25,  2.52s/it, acc=0.8482, loss=0.6037]\n",
            "Training:  30%|‚ñà‚ñà‚ñâ       | 146/490 [06:10<14:25,  2.52s/it, acc=0.8482, loss=0.3064]\n",
            "Training:  30%|‚ñà‚ñà‚ñà       | 147/490 [06:10<14:22,  2.51s/it, acc=0.8482, loss=0.3064]\n",
            "Training:  30%|‚ñà‚ñà‚ñà       | 147/490 [06:13<14:22,  2.51s/it, acc=0.8490, loss=0.1626]\n",
            "Training:  30%|‚ñà‚ñà‚ñà       | 148/490 [06:13<14:19,  2.51s/it, acc=0.8490, loss=0.1626]\n",
            "Training:  30%|‚ñà‚ñà‚ñà       | 148/490 [06:15<14:19,  2.51s/it, acc=0.8492, loss=0.3968]\n",
            "Training:  30%|‚ñà‚ñà‚ñà       | 149/490 [06:15<14:16,  2.51s/it, acc=0.8492, loss=0.3968]\n",
            "Training:  30%|‚ñà‚ñà‚ñà       | 149/490 [06:18<14:16,  2.51s/it, acc=0.8488, loss=0.6275]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 150/490 [06:18<14:14,  2.51s/it, acc=0.8488, loss=0.6275]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 150/490 [06:20<14:14,  2.51s/it, acc=0.8485, loss=0.4567]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 151/490 [06:20<14:11,  2.51s/it, acc=0.8485, loss=0.4567]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 151/490 [06:23<14:11,  2.51s/it, acc=0.8483, loss=0.6155]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 152/490 [06:23<14:08,  2.51s/it, acc=0.8483, loss=0.6155]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 152/490 [06:25<14:08,  2.51s/it, acc=0.8484, loss=0.3367]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 153/490 [06:25<14:06,  2.51s/it, acc=0.8484, loss=0.3367]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 153/490 [06:28<14:06,  2.51s/it, acc=0.8484, loss=0.4596]\n",
            "Training:  31%|‚ñà‚ñà‚ñà‚ñè      | 154/490 [06:28<14:04,  2.51s/it, acc=0.8484, loss=0.4596]\n",
            "Training:  31%|‚ñà‚ñà‚ñà‚ñè      | 154/490 [06:30<14:04,  2.51s/it, acc=0.8484, loss=0.4164]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 155/490 [06:30<14:01,  2.51s/it, acc=0.8484, loss=0.4164]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 155/490 [06:33<14:01,  2.51s/it, acc=0.8488, loss=0.2629]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 156/490 [06:33<13:59,  2.51s/it, acc=0.8488, loss=0.2629]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 156/490 [06:35<13:59,  2.51s/it, acc=0.8489, loss=0.3284]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 157/490 [06:35<13:56,  2.51s/it, acc=0.8489, loss=0.3284]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 157/490 [06:38<13:56,  2.51s/it, acc=0.8497, loss=0.1776]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 158/490 [06:38<13:53,  2.51s/it, acc=0.8497, loss=0.1776]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 158/490 [06:40<13:53,  2.51s/it, acc=0.8496, loss=0.4237]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 159/490 [06:40<13:51,  2.51s/it, acc=0.8496, loss=0.4237]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 159/490 [06:43<13:51,  2.51s/it, acc=0.8492, loss=0.6893]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 160/490 [06:43<13:50,  2.52s/it, acc=0.8492, loss=0.6893]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 160/490 [06:45<13:50,  2.52s/it, acc=0.8498, loss=0.2464]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 161/490 [06:45<13:47,  2.52s/it, acc=0.8498, loss=0.2464]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 161/490 [06:48<13:47,  2.52s/it, acc=0.8503, loss=0.2761]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 162/490 [06:48<13:45,  2.52s/it, acc=0.8503, loss=0.2761]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 162/490 [06:50<13:45,  2.52s/it, acc=0.8507, loss=0.2114]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 163/490 [06:50<13:43,  2.52s/it, acc=0.8507, loss=0.2114]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 163/490 [06:53<13:43,  2.52s/it, acc=0.8512, loss=0.2796]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 164/490 [06:53<13:40,  2.52s/it, acc=0.8512, loss=0.2796]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 164/490 [06:55<13:40,  2.52s/it, acc=0.8513, loss=0.3194]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñé      | 165/490 [06:55<13:38,  2.52s/it, acc=0.8513, loss=0.3194]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñé      | 165/490 [06:58<13:38,  2.52s/it, acc=0.8517, loss=0.3207]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 166/490 [06:58<13:35,  2.52s/it, acc=0.8517, loss=0.3207]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 166/490 [07:00<13:35,  2.52s/it, acc=0.8512, loss=0.4007]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 167/490 [07:00<13:32,  2.52s/it, acc=0.8512, loss=0.4007]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 167/490 [07:03<13:32,  2.52s/it, acc=0.8512, loss=0.4990]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 168/490 [07:03<13:30,  2.52s/it, acc=0.8512, loss=0.4990]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 168/490 [07:05<13:30,  2.52s/it, acc=0.8511, loss=0.4479]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 169/490 [07:05<13:28,  2.52s/it, acc=0.8511, loss=0.4479]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 169/490 [07:08<13:28,  2.52s/it, acc=0.8511, loss=0.4278]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñç      | 170/490 [07:08<13:25,  2.52s/it, acc=0.8511, loss=0.4278]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñç      | 170/490 [07:10<13:25,  2.52s/it, acc=0.8514, loss=0.3421]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñç      | 171/490 [07:10<13:23,  2.52s/it, acc=0.8514, loss=0.3421]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñç      | 171/490 [07:13<13:23,  2.52s/it, acc=0.8512, loss=0.4890]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñå      | 172/490 [07:13<13:21,  2.52s/it, acc=0.8512, loss=0.4890]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñå      | 172/490 [07:15<13:21,  2.52s/it, acc=0.8515, loss=0.1670]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñå      | 173/490 [07:15<13:18,  2.52s/it, acc=0.8515, loss=0.1670]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñå      | 173/490 [07:18<13:18,  2.52s/it, acc=0.8515, loss=0.3719]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 174/490 [07:18<13:16,  2.52s/it, acc=0.8515, loss=0.3719]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 174/490 [07:20<13:16,  2.52s/it, acc=0.8514, loss=0.4376]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 175/490 [07:20<13:13,  2.52s/it, acc=0.8514, loss=0.4376]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 175/490 [07:23<13:13,  2.52s/it, acc=0.8516, loss=0.3571]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 176/490 [07:23<13:11,  2.52s/it, acc=0.8516, loss=0.3571]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 176/490 [07:26<13:11,  2.52s/it, acc=0.8513, loss=0.5295]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 177/490 [07:26<13:09,  2.52s/it, acc=0.8513, loss=0.5295]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 177/490 [07:28<13:09,  2.52s/it, acc=0.8511, loss=0.5995]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñã      | 178/490 [07:28<13:05,  2.52s/it, acc=0.8511, loss=0.5995]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñã      | 178/490 [07:31<13:05,  2.52s/it, acc=0.8513, loss=0.2791]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 179/490 [07:31<13:03,  2.52s/it, acc=0.8513, loss=0.2791]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 179/490 [07:33<13:03,  2.52s/it, acc=0.8514, loss=0.4707]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 180/490 [07:33<13:01,  2.52s/it, acc=0.8514, loss=0.4707]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 180/490 [07:36<13:01,  2.52s/it, acc=0.8513, loss=0.5621]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 181/490 [07:36<12:58,  2.52s/it, acc=0.8513, loss=0.5621]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 181/490 [07:38<12:58,  2.52s/it, acc=0.8518, loss=0.2458]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 182/490 [07:38<12:56,  2.52s/it, acc=0.8518, loss=0.2458]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 182/490 [07:41<12:56,  2.52s/it, acc=0.8523, loss=0.2446]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 183/490 [07:41<12:54,  2.52s/it, acc=0.8523, loss=0.2446]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 183/490 [07:43<12:54,  2.52s/it, acc=0.8528, loss=0.1906]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 184/490 [07:43<12:52,  2.52s/it, acc=0.8528, loss=0.1906]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 184/490 [07:46<12:52,  2.52s/it, acc=0.8527, loss=0.3868]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 185/490 [07:46<12:49,  2.52s/it, acc=0.8527, loss=0.3868]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 185/490 [07:48<12:49,  2.52s/it, acc=0.8527, loss=0.4017]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 186/490 [07:48<12:47,  2.52s/it, acc=0.8527, loss=0.4017]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 186/490 [07:51<12:47,  2.52s/it, acc=0.8533, loss=0.2129]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 187/490 [07:51<12:44,  2.52s/it, acc=0.8533, loss=0.2129]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 187/490 [07:53<12:44,  2.52s/it, acc=0.8531, loss=0.3593]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 188/490 [07:53<12:42,  2.52s/it, acc=0.8531, loss=0.3593]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 188/490 [07:56<12:42,  2.52s/it, acc=0.8537, loss=0.1688]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñä      | 189/490 [07:56<12:40,  2.53s/it, acc=0.8537, loss=0.1688]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñä      | 189/490 [07:58<12:40,  2.53s/it, acc=0.8536, loss=0.5011]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 190/490 [07:58<12:37,  2.53s/it, acc=0.8536, loss=0.5011]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 190/490 [08:01<12:37,  2.53s/it, acc=0.8537, loss=0.3737]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 191/490 [08:01<12:35,  2.53s/it, acc=0.8537, loss=0.3737]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 191/490 [08:03<12:35,  2.53s/it, acc=0.8538, loss=0.3170]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 192/490 [08:03<12:32,  2.52s/it, acc=0.8538, loss=0.3170]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 192/490 [08:06<12:32,  2.52s/it, acc=0.8540, loss=0.4266]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 193/490 [08:06<12:30,  2.53s/it, acc=0.8540, loss=0.4266]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 193/490 [08:08<12:30,  2.53s/it, acc=0.8545, loss=0.0982]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñâ      | 194/490 [08:08<12:28,  2.53s/it, acc=0.8545, loss=0.0982]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñâ      | 194/490 [08:11<12:28,  2.53s/it, acc=0.8548, loss=0.2914]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñâ      | 195/490 [08:11<12:26,  2.53s/it, acc=0.8548, loss=0.2914]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñâ      | 195/490 [08:14<12:26,  2.53s/it, acc=0.8546, loss=0.4043]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñà      | 196/490 [08:14<12:23,  2.53s/it, acc=0.8546, loss=0.4043]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñà      | 196/490 [08:16<12:23,  2.53s/it, acc=0.8547, loss=0.2966]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñà      | 197/490 [08:16<12:20,  2.53s/it, acc=0.8547, loss=0.2966]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñà      | 197/490 [08:19<12:20,  2.53s/it, acc=0.8543, loss=0.7003]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñà      | 198/490 [08:19<12:17,  2.53s/it, acc=0.8543, loss=0.7003]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñà      | 198/490 [08:21<12:17,  2.53s/it, acc=0.8544, loss=0.4899]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 199/490 [08:21<12:15,  2.53s/it, acc=0.8544, loss=0.4899]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 199/490 [08:24<12:15,  2.53s/it, acc=0.8548, loss=0.2027]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 200/490 [08:24<12:13,  2.53s/it, acc=0.8548, loss=0.2027]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 200/490 [08:26<12:13,  2.53s/it, acc=0.8551, loss=0.2300]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 201/490 [08:26<12:10,  2.53s/it, acc=0.8551, loss=0.2300]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 201/490 [08:29<12:10,  2.53s/it, acc=0.8552, loss=0.4998]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 202/490 [08:29<12:08,  2.53s/it, acc=0.8552, loss=0.4998]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 202/490 [08:31<12:08,  2.53s/it, acc=0.8551, loss=0.3632]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 203/490 [08:31<12:05,  2.53s/it, acc=0.8551, loss=0.3632]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 203/490 [08:34<12:05,  2.53s/it, acc=0.8545, loss=0.5801]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 204/490 [08:34<12:03,  2.53s/it, acc=0.8545, loss=0.5801]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 204/490 [08:36<12:03,  2.53s/it, acc=0.8544, loss=0.5070]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 205/490 [08:36<12:01,  2.53s/it, acc=0.8544, loss=0.5070]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 205/490 [08:39<12:01,  2.53s/it, acc=0.8536, loss=0.6936]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 206/490 [08:39<11:58,  2.53s/it, acc=0.8536, loss=0.6936]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 206/490 [08:41<11:58,  2.53s/it, acc=0.8537, loss=0.5075]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 207/490 [08:41<11:55,  2.53s/it, acc=0.8537, loss=0.5075]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 207/490 [08:44<11:55,  2.53s/it, acc=0.8538, loss=0.2905]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 208/490 [08:44<11:53,  2.53s/it, acc=0.8538, loss=0.2905]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 208/490 [08:46<11:53,  2.53s/it, acc=0.8538, loss=0.4313]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 209/490 [08:46<11:51,  2.53s/it, acc=0.8538, loss=0.4313]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 209/490 [08:49<11:51,  2.53s/it, acc=0.8536, loss=0.5816]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 210/490 [08:49<11:48,  2.53s/it, acc=0.8536, loss=0.5816]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 210/490 [08:51<11:48,  2.53s/it, acc=0.8538, loss=0.2986]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 211/490 [08:51<11:46,  2.53s/it, acc=0.8538, loss=0.2986]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 211/490 [08:54<11:46,  2.53s/it, acc=0.8532, loss=0.6431]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 212/490 [08:54<11:44,  2.53s/it, acc=0.8532, loss=0.6431]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 212/490 [08:57<11:44,  2.53s/it, acc=0.8528, loss=0.5429]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 213/490 [08:57<11:41,  2.53s/it, acc=0.8528, loss=0.5429]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 213/490 [08:59<11:41,  2.53s/it, acc=0.8524, loss=0.7029]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 214/490 [08:59<11:39,  2.53s/it, acc=0.8524, loss=0.7029]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 214/490 [09:02<11:39,  2.53s/it, acc=0.8523, loss=0.5184]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 215/490 [09:02<11:36,  2.53s/it, acc=0.8523, loss=0.5184]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 215/490 [09:04<11:36,  2.53s/it, acc=0.8521, loss=0.6042]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 216/490 [09:04<11:34,  2.54s/it, acc=0.8521, loss=0.6042]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 216/490 [09:07<11:34,  2.54s/it, acc=0.8521, loss=0.5427]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 217/490 [09:07<11:31,  2.53s/it, acc=0.8521, loss=0.5427]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 217/490 [09:09<11:31,  2.53s/it, acc=0.8521, loss=0.3638]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 218/490 [09:09<11:29,  2.53s/it, acc=0.8521, loss=0.3638]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 218/490 [09:12<11:29,  2.53s/it, acc=0.8520, loss=0.3929]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 219/490 [09:12<11:26,  2.53s/it, acc=0.8520, loss=0.3929]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 219/490 [09:14<11:26,  2.53s/it, acc=0.8520, loss=0.4306]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 220/490 [09:14<11:23,  2.53s/it, acc=0.8520, loss=0.4306]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 220/490 [09:17<11:23,  2.53s/it, acc=0.8520, loss=0.5820]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 221/490 [09:17<11:21,  2.53s/it, acc=0.8520, loss=0.5820]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 221/490 [09:19<11:21,  2.53s/it, acc=0.8519, loss=0.3192]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 222/490 [09:19<11:19,  2.53s/it, acc=0.8519, loss=0.3192]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 222/490 [09:22<11:19,  2.53s/it, acc=0.8520, loss=0.2841]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 223/490 [09:22<11:15,  2.53s/it, acc=0.8520, loss=0.2841]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 223/490 [09:24<11:15,  2.53s/it, acc=0.8521, loss=0.3940]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 224/490 [09:24<11:13,  2.53s/it, acc=0.8521, loss=0.3940]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 224/490 [09:27<11:13,  2.53s/it, acc=0.8518, loss=0.4591]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 225/490 [09:27<11:10,  2.53s/it, acc=0.8518, loss=0.4591]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 225/490 [09:29<11:10,  2.53s/it, acc=0.8520, loss=0.3210]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 226/490 [09:29<11:08,  2.53s/it, acc=0.8520, loss=0.3210]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 226/490 [09:32<11:08,  2.53s/it, acc=0.8520, loss=0.5412]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 227/490 [09:32<11:05,  2.53s/it, acc=0.8520, loss=0.5412]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 227/490 [09:35<11:05,  2.53s/it, acc=0.8521, loss=0.3426]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 228/490 [09:35<11:03,  2.53s/it, acc=0.8521, loss=0.3426]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 228/490 [09:37<11:03,  2.53s/it, acc=0.8522, loss=0.3284]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 229/490 [09:37<11:00,  2.53s/it, acc=0.8522, loss=0.3284]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 229/490 [09:40<11:00,  2.53s/it, acc=0.8520, loss=0.5168]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 230/490 [09:40<10:58,  2.53s/it, acc=0.8520, loss=0.5168]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 230/490 [09:42<10:58,  2.53s/it, acc=0.8520, loss=0.4386]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 231/490 [09:42<10:56,  2.53s/it, acc=0.8520, loss=0.4386]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 231/490 [09:45<10:56,  2.53s/it, acc=0.8521, loss=0.2682]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 232/490 [09:45<10:53,  2.53s/it, acc=0.8521, loss=0.2682]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 232/490 [09:47<10:53,  2.53s/it, acc=0.8523, loss=0.3220]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 233/490 [09:47<10:51,  2.54s/it, acc=0.8523, loss=0.3220]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 233/490 [09:50<10:51,  2.54s/it, acc=0.8524, loss=0.2607]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 234/490 [09:50<10:48,  2.53s/it, acc=0.8524, loss=0.2607]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 234/490 [09:52<10:48,  2.53s/it, acc=0.8525, loss=0.5857]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 235/490 [09:52<10:45,  2.53s/it, acc=0.8525, loss=0.5857]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 235/490 [09:55<10:45,  2.53s/it, acc=0.8529, loss=0.3081]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 236/490 [09:55<10:43,  2.53s/it, acc=0.8529, loss=0.3081]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 236/490 [09:57<10:43,  2.53s/it, acc=0.8528, loss=0.4969]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 237/490 [09:57<10:40,  2.53s/it, acc=0.8528, loss=0.4969]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 237/490 [10:00<10:40,  2.53s/it, acc=0.8524, loss=0.5393]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 238/490 [10:00<10:37,  2.53s/it, acc=0.8524, loss=0.5393]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 238/490 [10:02<10:37,  2.53s/it, acc=0.8522, loss=0.4607]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 239/490 [10:02<10:34,  2.53s/it, acc=0.8522, loss=0.4607]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 239/490 [10:05<10:34,  2.53s/it, acc=0.8525, loss=0.2962]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 240/490 [10:05<10:32,  2.53s/it, acc=0.8525, loss=0.2962]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 240/490 [10:07<10:32,  2.53s/it, acc=0.8530, loss=0.1563]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 241/490 [10:07<10:29,  2.53s/it, acc=0.8530, loss=0.1563]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 241/490 [10:10<10:29,  2.53s/it, acc=0.8529, loss=0.3562]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 242/490 [10:10<10:27,  2.53s/it, acc=0.8529, loss=0.3562]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 242/490 [10:12<10:27,  2.53s/it, acc=0.8534, loss=0.2239]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 243/490 [10:12<10:24,  2.53s/it, acc=0.8534, loss=0.2239]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 243/490 [10:15<10:24,  2.53s/it, acc=0.8531, loss=0.4824]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 244/490 [10:15<10:21,  2.53s/it, acc=0.8531, loss=0.4824]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 244/490 [10:18<10:21,  2.53s/it, acc=0.8532, loss=0.4449]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 245/490 [10:18<10:19,  2.53s/it, acc=0.8532, loss=0.4449]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 245/490 [10:20<10:19,  2.53s/it, acc=0.8534, loss=0.2864]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 246/490 [10:20<10:17,  2.53s/it, acc=0.8534, loss=0.2864]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 246/490 [10:23<10:17,  2.53s/it, acc=0.8532, loss=0.3610]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 247/490 [10:23<10:14,  2.53s/it, acc=0.8532, loss=0.3610]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 247/490 [10:25<10:14,  2.53s/it, acc=0.8529, loss=0.5866]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 248/490 [10:25<10:12,  2.53s/it, acc=0.8529, loss=0.5866]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 248/490 [10:28<10:12,  2.53s/it, acc=0.8522, loss=0.6823]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 249/490 [10:28<10:09,  2.53s/it, acc=0.8522, loss=0.6823]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 249/490 [10:30<10:09,  2.53s/it, acc=0.8524, loss=0.2165]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 250/490 [10:30<10:06,  2.53s/it, acc=0.8524, loss=0.2165]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 250/490 [10:33<10:06,  2.53s/it, acc=0.8522, loss=0.5282]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 251/490 [10:33<10:03,  2.53s/it, acc=0.8522, loss=0.5282]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 251/490 [10:35<10:03,  2.53s/it, acc=0.8524, loss=0.2700]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 252/490 [10:35<10:01,  2.53s/it, acc=0.8524, loss=0.2700]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 252/490 [10:38<10:01,  2.53s/it, acc=0.8519, loss=0.7248]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 253/490 [10:38<09:58,  2.53s/it, acc=0.8519, loss=0.7248]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 253/490 [10:40<09:58,  2.53s/it, acc=0.8521, loss=0.2778]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 254/490 [10:40<09:55,  2.52s/it, acc=0.8521, loss=0.2778]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 254/490 [10:43<09:55,  2.52s/it, acc=0.8523, loss=0.3420]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 255/490 [10:43<09:52,  2.52s/it, acc=0.8523, loss=0.3420]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 255/490 [10:45<09:52,  2.52s/it, acc=0.8519, loss=0.6637]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 256/490 [10:45<09:50,  2.52s/it, acc=0.8519, loss=0.6637]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 256/490 [10:48<09:50,  2.52s/it, acc=0.8523, loss=0.3846]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 257/490 [10:48<09:48,  2.52s/it, acc=0.8523, loss=0.3846]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 257/490 [10:50<09:48,  2.52s/it, acc=0.8521, loss=0.5535]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 258/490 [10:50<09:45,  2.52s/it, acc=0.8521, loss=0.5535]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 258/490 [10:53<09:45,  2.52s/it, acc=0.8521, loss=0.4726]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 259/490 [10:53<09:42,  2.52s/it, acc=0.8521, loss=0.4726]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 259/490 [10:55<09:42,  2.52s/it, acc=0.8522, loss=0.4196]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 260/490 [10:55<09:40,  2.52s/it, acc=0.8522, loss=0.4196]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 260/490 [10:58<09:40,  2.52s/it, acc=0.8521, loss=0.3569]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 261/490 [10:58<09:37,  2.52s/it, acc=0.8521, loss=0.3569]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 261/490 [11:00<09:37,  2.52s/it, acc=0.8523, loss=0.5510]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 262/490 [11:00<09:35,  2.52s/it, acc=0.8523, loss=0.5510]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 262/490 [11:03<09:35,  2.52s/it, acc=0.8522, loss=0.4116]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 263/490 [11:03<09:32,  2.52s/it, acc=0.8522, loss=0.4116]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 263/490 [11:06<09:32,  2.52s/it, acc=0.8520, loss=0.4818]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 264/490 [11:06<09:29,  2.52s/it, acc=0.8520, loss=0.4818]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 264/490 [11:08<09:29,  2.52s/it, acc=0.8521, loss=0.4409]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 265/490 [11:08<09:27,  2.52s/it, acc=0.8521, loss=0.4409]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 265/490 [11:11<09:27,  2.52s/it, acc=0.8520, loss=0.4112]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 266/490 [11:11<09:24,  2.52s/it, acc=0.8520, loss=0.4112]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 266/490 [11:13<09:24,  2.52s/it, acc=0.8521, loss=0.3295]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 267/490 [11:13<09:21,  2.52s/it, acc=0.8521, loss=0.3295]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 267/490 [11:16<09:21,  2.52s/it, acc=0.8523, loss=0.2620]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 268/490 [11:16<09:18,  2.52s/it, acc=0.8523, loss=0.2620]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 268/490 [11:18<09:18,  2.52s/it, acc=0.8526, loss=0.2507]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 269/490 [11:18<09:16,  2.52s/it, acc=0.8526, loss=0.2507]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 269/490 [11:21<09:16,  2.52s/it, acc=0.8525, loss=0.4257]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 270/490 [11:21<09:13,  2.52s/it, acc=0.8525, loss=0.4257]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 270/490 [11:23<09:13,  2.52s/it, acc=0.8525, loss=0.4354]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 271/490 [11:23<09:11,  2.52s/it, acc=0.8525, loss=0.4354]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 271/490 [11:26<09:11,  2.52s/it, acc=0.8525, loss=0.4992]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 272/490 [11:26<09:08,  2.52s/it, acc=0.8525, loss=0.4992]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 272/490 [11:28<09:08,  2.52s/it, acc=0.8528, loss=0.2608]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 273/490 [11:28<09:05,  2.52s/it, acc=0.8528, loss=0.2608]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 273/490 [11:31<09:05,  2.52s/it, acc=0.8526, loss=0.5727]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 274/490 [11:31<09:03,  2.52s/it, acc=0.8526, loss=0.5727]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 274/490 [11:33<09:03,  2.52s/it, acc=0.8525, loss=0.4866]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 275/490 [11:33<09:01,  2.52s/it, acc=0.8525, loss=0.4866]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 275/490 [11:36<09:01,  2.52s/it, acc=0.8527, loss=0.3103]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 276/490 [11:36<08:58,  2.52s/it, acc=0.8527, loss=0.3103]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 276/490 [11:38<08:58,  2.52s/it, acc=0.8525, loss=0.3953]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 277/490 [11:38<08:55,  2.51s/it, acc=0.8525, loss=0.3953]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 277/490 [11:41<08:55,  2.51s/it, acc=0.8526, loss=0.2792]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 278/490 [11:41<08:53,  2.52s/it, acc=0.8526, loss=0.2792]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 278/490 [11:43<08:53,  2.52s/it, acc=0.8524, loss=0.8426]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 279/490 [11:43<08:50,  2.51s/it, acc=0.8524, loss=0.8426]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 279/490 [11:46<08:50,  2.51s/it, acc=0.8526, loss=0.3064]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 280/490 [11:46<08:47,  2.51s/it, acc=0.8526, loss=0.3064]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 280/490 [11:48<08:47,  2.51s/it, acc=0.8522, loss=0.5428]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 281/490 [11:48<08:45,  2.51s/it, acc=0.8522, loss=0.5428]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 281/490 [11:51<08:45,  2.51s/it, acc=0.8525, loss=0.2919]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 282/490 [11:51<08:42,  2.51s/it, acc=0.8525, loss=0.2919]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 282/490 [11:53<08:42,  2.51s/it, acc=0.8525, loss=0.4685]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 283/490 [11:53<08:40,  2.52s/it, acc=0.8525, loss=0.4685]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 283/490 [11:56<08:40,  2.52s/it, acc=0.8527, loss=0.3541]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 284/490 [11:56<08:38,  2.52s/it, acc=0.8527, loss=0.3541]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 284/490 [11:58<08:38,  2.52s/it, acc=0.8527, loss=0.2781]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 285/490 [11:58<08:35,  2.52s/it, acc=0.8527, loss=0.2781]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 285/490 [12:01<08:35,  2.52s/it, acc=0.8531, loss=0.2184]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 286/490 [12:01<08:32,  2.51s/it, acc=0.8531, loss=0.2184]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 286/490 [12:03<08:32,  2.51s/it, acc=0.8533, loss=0.2659]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 287/490 [12:03<08:30,  2.51s/it, acc=0.8533, loss=0.2659]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 287/490 [12:06<08:30,  2.51s/it, acc=0.8532, loss=0.4313]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 288/490 [12:06<08:27,  2.51s/it, acc=0.8532, loss=0.4313]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 288/490 [12:08<08:27,  2.51s/it, acc=0.8529, loss=0.6639]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 289/490 [12:08<08:24,  2.51s/it, acc=0.8529, loss=0.6639]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 289/490 [12:11<08:24,  2.51s/it, acc=0.8529, loss=0.4975]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 290/490 [12:11<08:22,  2.51s/it, acc=0.8529, loss=0.4975]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 290/490 [12:13<08:22,  2.51s/it, acc=0.8533, loss=0.1221]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 291/490 [12:13<08:20,  2.51s/it, acc=0.8533, loss=0.1221]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 291/490 [12:16<08:20,  2.51s/it, acc=0.8536, loss=0.1931]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 292/490 [12:16<08:17,  2.51s/it, acc=0.8536, loss=0.1931]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 292/490 [12:18<08:17,  2.51s/it, acc=0.8538, loss=0.2712]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 293/490 [12:18<08:14,  2.51s/it, acc=0.8538, loss=0.2712]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 293/490 [12:21<08:14,  2.51s/it, acc=0.8534, loss=0.5245]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 294/490 [12:21<08:12,  2.51s/it, acc=0.8534, loss=0.5245]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 294/490 [12:23<08:12,  2.51s/it, acc=0.8535, loss=0.4146]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 295/490 [12:23<08:09,  2.51s/it, acc=0.8535, loss=0.4146]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 295/490 [12:26<08:09,  2.51s/it, acc=0.8537, loss=0.2691]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 296/490 [12:26<08:06,  2.51s/it, acc=0.8537, loss=0.2691]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 296/490 [12:28<08:06,  2.51s/it, acc=0.8539, loss=0.3328]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 297/490 [12:28<08:04,  2.51s/it, acc=0.8539, loss=0.3328]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 297/490 [12:31<08:04,  2.51s/it, acc=0.8540, loss=0.3457]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 298/490 [12:31<08:02,  2.51s/it, acc=0.8540, loss=0.3457]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 298/490 [12:33<08:02,  2.51s/it, acc=0.8541, loss=0.3476]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 299/490 [12:33<07:59,  2.51s/it, acc=0.8541, loss=0.3476]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 299/490 [12:36<07:59,  2.51s/it, acc=0.8543, loss=0.2983]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 300/490 [12:36<07:56,  2.51s/it, acc=0.8543, loss=0.2983]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 300/490 [12:39<07:56,  2.51s/it, acc=0.8541, loss=0.4109]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 301/490 [12:39<07:54,  2.51s/it, acc=0.8541, loss=0.4109]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 301/490 [12:41<07:54,  2.51s/it, acc=0.8540, loss=0.4147]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 302/490 [12:41<07:51,  2.51s/it, acc=0.8540, loss=0.4147]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 302/490 [12:44<07:51,  2.51s/it, acc=0.8542, loss=0.3124]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 303/490 [12:44<07:48,  2.51s/it, acc=0.8542, loss=0.3124]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 303/490 [12:46<07:48,  2.51s/it, acc=0.8544, loss=0.2840]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 304/490 [12:46<07:46,  2.51s/it, acc=0.8544, loss=0.2840]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 304/490 [12:49<07:46,  2.51s/it, acc=0.8543, loss=0.4581]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 305/490 [12:49<07:43,  2.51s/it, acc=0.8543, loss=0.4581]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 305/490 [12:51<07:43,  2.51s/it, acc=0.8544, loss=0.4003]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 306/490 [12:51<07:41,  2.51s/it, acc=0.8544, loss=0.4003]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 306/490 [12:54<07:41,  2.51s/it, acc=0.8543, loss=0.3572]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 307/490 [12:54<07:38,  2.51s/it, acc=0.8543, loss=0.3572]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 307/490 [12:56<07:38,  2.51s/it, acc=0.8545, loss=0.3853]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 308/490 [12:56<07:36,  2.51s/it, acc=0.8545, loss=0.3853]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 308/490 [12:59<07:36,  2.51s/it, acc=0.8547, loss=0.2775]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 309/490 [12:59<07:33,  2.51s/it, acc=0.8547, loss=0.2775]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 309/490 [13:01<07:33,  2.51s/it, acc=0.8547, loss=0.5336]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 310/490 [13:01<07:31,  2.51s/it, acc=0.8547, loss=0.5336]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 310/490 [13:04<07:31,  2.51s/it, acc=0.8549, loss=0.2533]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 311/490 [13:04<07:29,  2.51s/it, acc=0.8549, loss=0.2533]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 311/490 [13:06<07:29,  2.51s/it, acc=0.8550, loss=0.3661]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 312/490 [13:06<07:26,  2.51s/it, acc=0.8550, loss=0.3661]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 312/490 [13:09<07:26,  2.51s/it, acc=0.8550, loss=0.4385]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 313/490 [13:09<07:24,  2.51s/it, acc=0.8550, loss=0.4385]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 313/490 [13:11<07:24,  2.51s/it, acc=0.8547, loss=0.5288]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 314/490 [13:11<07:21,  2.51s/it, acc=0.8547, loss=0.5288]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 314/490 [13:14<07:21,  2.51s/it, acc=0.8549, loss=0.2643]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 315/490 [13:14<07:18,  2.51s/it, acc=0.8549, loss=0.2643]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 315/490 [13:16<07:18,  2.51s/it, acc=0.8548, loss=0.5100]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 316/490 [13:16<07:16,  2.51s/it, acc=0.8548, loss=0.5100]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 316/490 [13:19<07:16,  2.51s/it, acc=0.8548, loss=0.4177]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 317/490 [13:19<07:13,  2.51s/it, acc=0.8548, loss=0.4177]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 317/490 [13:21<07:13,  2.51s/it, acc=0.8548, loss=0.3205]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 318/490 [13:21<07:11,  2.51s/it, acc=0.8548, loss=0.3205]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 318/490 [13:24<07:11,  2.51s/it, acc=0.8544, loss=0.7354]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 319/490 [13:24<07:09,  2.51s/it, acc=0.8544, loss=0.7354]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 319/490 [13:26<07:09,  2.51s/it, acc=0.8546, loss=0.2590]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 320/490 [13:26<07:06,  2.51s/it, acc=0.8546, loss=0.2590]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 320/490 [13:29<07:06,  2.51s/it, acc=0.8547, loss=0.2829]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 321/490 [13:29<07:04,  2.51s/it, acc=0.8547, loss=0.2829]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 321/490 [13:31<07:04,  2.51s/it, acc=0.8543, loss=0.6071]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 322/490 [13:31<07:01,  2.51s/it, acc=0.8543, loss=0.6071]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 322/490 [13:34<07:01,  2.51s/it, acc=0.8545, loss=0.2892]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 323/490 [13:34<06:59,  2.51s/it, acc=0.8545, loss=0.2892]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 323/490 [13:36<06:59,  2.51s/it, acc=0.8546, loss=0.2904]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 324/490 [13:36<06:56,  2.51s/it, acc=0.8546, loss=0.2904]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 324/490 [13:39<06:56,  2.51s/it, acc=0.8545, loss=0.5690]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 325/490 [13:39<06:54,  2.51s/it, acc=0.8545, loss=0.5690]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 325/490 [13:41<06:54,  2.51s/it, acc=0.8543, loss=0.4986]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 326/490 [13:41<06:52,  2.51s/it, acc=0.8543, loss=0.4986]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 326/490 [13:44<06:52,  2.51s/it, acc=0.8539, loss=0.9103]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 327/490 [13:44<06:49,  2.51s/it, acc=0.8539, loss=0.9103]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 327/490 [13:46<06:49,  2.51s/it, acc=0.8537, loss=0.5066]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 328/490 [13:46<06:47,  2.51s/it, acc=0.8537, loss=0.5066]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 328/490 [13:49<06:47,  2.51s/it, acc=0.8534, loss=0.7211]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 329/490 [13:49<06:44,  2.51s/it, acc=0.8534, loss=0.7211]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 329/490 [13:51<06:44,  2.51s/it, acc=0.8538, loss=0.1916]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 330/490 [13:51<06:42,  2.51s/it, acc=0.8538, loss=0.1916]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 330/490 [13:54<06:42,  2.51s/it, acc=0.8539, loss=0.2803]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 331/490 [13:54<06:39,  2.52s/it, acc=0.8539, loss=0.2803]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 331/490 [13:56<06:39,  2.52s/it, acc=0.8542, loss=0.2425]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 332/490 [13:56<06:37,  2.52s/it, acc=0.8542, loss=0.2425]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 332/490 [13:59<06:37,  2.52s/it, acc=0.8544, loss=0.2224]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 333/490 [13:59<06:34,  2.52s/it, acc=0.8544, loss=0.2224]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 333/490 [14:01<06:34,  2.52s/it, acc=0.8544, loss=0.2799]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 334/490 [14:01<06:32,  2.52s/it, acc=0.8544, loss=0.2799]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 334/490 [14:04<06:32,  2.52s/it, acc=0.8546, loss=0.1906]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 335/490 [14:04<06:29,  2.52s/it, acc=0.8546, loss=0.1906]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 335/490 [14:06<06:29,  2.52s/it, acc=0.8545, loss=0.3704]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 336/490 [14:06<06:27,  2.51s/it, acc=0.8545, loss=0.3704]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 336/490 [14:09<06:27,  2.51s/it, acc=0.8543, loss=0.4461]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 337/490 [14:09<06:25,  2.52s/it, acc=0.8543, loss=0.4461]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 337/490 [14:11<06:25,  2.52s/it, acc=0.8544, loss=0.3655]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 338/490 [14:11<06:22,  2.52s/it, acc=0.8544, loss=0.3655]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 338/490 [14:14<06:22,  2.52s/it, acc=0.8544, loss=0.5433]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 339/490 [14:14<06:20,  2.52s/it, acc=0.8544, loss=0.5433]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 339/490 [14:16<06:20,  2.52s/it, acc=0.8545, loss=0.3844]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 340/490 [14:16<06:18,  2.52s/it, acc=0.8545, loss=0.3844]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 340/490 [14:19<06:18,  2.52s/it, acc=0.8547, loss=0.1831]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 341/490 [14:19<06:15,  2.52s/it, acc=0.8547, loss=0.1831]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 341/490 [14:22<06:15,  2.52s/it, acc=0.8548, loss=0.3676]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 342/490 [14:22<06:12,  2.52s/it, acc=0.8548, loss=0.3676]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 342/490 [14:24<06:12,  2.52s/it, acc=0.8546, loss=0.6490]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 343/490 [14:24<06:10,  2.52s/it, acc=0.8546, loss=0.6490]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 343/490 [14:27<06:10,  2.52s/it, acc=0.8545, loss=0.3655]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 344/490 [14:27<06:08,  2.52s/it, acc=0.8545, loss=0.3655]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 344/490 [14:29<06:08,  2.52s/it, acc=0.8543, loss=0.5183]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 345/490 [14:29<06:06,  2.52s/it, acc=0.8543, loss=0.5183]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 345/490 [14:32<06:06,  2.52s/it, acc=0.8544, loss=0.2907]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 346/490 [14:32<06:03,  2.53s/it, acc=0.8544, loss=0.2907]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 346/490 [14:34<06:03,  2.53s/it, acc=0.8540, loss=0.6653]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 347/490 [14:34<06:01,  2.53s/it, acc=0.8540, loss=0.6653]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 347/490 [14:37<06:01,  2.53s/it, acc=0.8544, loss=0.0786]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 348/490 [14:37<05:58,  2.53s/it, acc=0.8544, loss=0.0786]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 348/490 [14:39<05:58,  2.53s/it, acc=0.8544, loss=0.5130]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 349/490 [14:39<05:56,  2.53s/it, acc=0.8544, loss=0.5130]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 349/490 [14:42<05:56,  2.53s/it, acc=0.8542, loss=0.4677]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 350/490 [14:42<05:54,  2.53s/it, acc=0.8542, loss=0.4677]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 350/490 [14:44<05:54,  2.53s/it, acc=0.8540, loss=0.6534]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 351/490 [14:44<05:51,  2.53s/it, acc=0.8540, loss=0.6534]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 351/490 [14:47<05:51,  2.53s/it, acc=0.8540, loss=0.4340]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 352/490 [14:47<05:49,  2.53s/it, acc=0.8540, loss=0.4340]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 352/490 [14:49<05:49,  2.53s/it, acc=0.8543, loss=0.2728]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 353/490 [14:49<05:46,  2.53s/it, acc=0.8543, loss=0.2728]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 353/490 [14:52<05:46,  2.53s/it, acc=0.8544, loss=0.3363]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 354/490 [14:52<05:44,  2.53s/it, acc=0.8544, loss=0.3363]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 354/490 [14:54<05:44,  2.53s/it, acc=0.8546, loss=0.2657]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 355/490 [14:54<05:41,  2.53s/it, acc=0.8546, loss=0.2657]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 355/490 [14:57<05:41,  2.53s/it, acc=0.8545, loss=0.5156]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 356/490 [14:57<05:38,  2.53s/it, acc=0.8545, loss=0.5156]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 356/490 [14:59<05:38,  2.53s/it, acc=0.8544, loss=0.3729]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 357/490 [14:59<05:36,  2.53s/it, acc=0.8544, loss=0.3729]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 357/490 [15:02<05:36,  2.53s/it, acc=0.8545, loss=0.3811]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 358/490 [15:02<05:34,  2.53s/it, acc=0.8545, loss=0.3811]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 358/490 [15:05<05:34,  2.53s/it, acc=0.8545, loss=0.5476]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 359/490 [15:05<05:31,  2.53s/it, acc=0.8545, loss=0.5476]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 359/490 [15:07<05:31,  2.53s/it, acc=0.8546, loss=0.3814]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 360/490 [15:07<05:29,  2.53s/it, acc=0.8546, loss=0.3814]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 360/490 [15:10<05:29,  2.53s/it, acc=0.8547, loss=0.4164]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 361/490 [15:10<05:26,  2.53s/it, acc=0.8547, loss=0.4164]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 361/490 [15:12<05:26,  2.53s/it, acc=0.8548, loss=0.3583]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 362/490 [15:12<05:24,  2.53s/it, acc=0.8548, loss=0.3583]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 362/490 [15:15<05:24,  2.53s/it, acc=0.8546, loss=0.3705]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 363/490 [15:15<05:21,  2.53s/it, acc=0.8546, loss=0.3705]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 363/490 [15:17<05:21,  2.53s/it, acc=0.8547, loss=0.1844]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 364/490 [15:17<05:18,  2.53s/it, acc=0.8547, loss=0.1844]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 364/490 [15:20<05:18,  2.53s/it, acc=0.8547, loss=0.5352]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 365/490 [15:20<05:16,  2.53s/it, acc=0.8547, loss=0.5352]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 365/490 [15:22<05:16,  2.53s/it, acc=0.8546, loss=0.3577]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 366/490 [15:22<05:14,  2.53s/it, acc=0.8546, loss=0.3577]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 366/490 [15:25<05:14,  2.53s/it, acc=0.8547, loss=0.3094]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 367/490 [15:25<05:11,  2.53s/it, acc=0.8547, loss=0.3094]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 367/490 [15:27<05:11,  2.53s/it, acc=0.8549, loss=0.2807]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 368/490 [15:27<05:09,  2.53s/it, acc=0.8549, loss=0.2807]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 368/490 [15:30<05:09,  2.53s/it, acc=0.8548, loss=0.3958]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 369/490 [15:30<05:06,  2.54s/it, acc=0.8548, loss=0.3958]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 369/490 [15:32<05:06,  2.54s/it, acc=0.8548, loss=0.3927]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 370/490 [15:32<05:04,  2.54s/it, acc=0.8548, loss=0.3927]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 370/490 [15:35<05:04,  2.54s/it, acc=0.8548, loss=0.6522]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 371/490 [15:35<05:02,  2.54s/it, acc=0.8548, loss=0.6522]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 371/490 [15:38<05:02,  2.54s/it, acc=0.8550, loss=0.2303]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 372/490 [15:38<04:59,  2.54s/it, acc=0.8550, loss=0.2303]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 372/490 [15:40<04:59,  2.54s/it, acc=0.8551, loss=0.2798]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 373/490 [15:40<04:56,  2.54s/it, acc=0.8551, loss=0.2798]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 373/490 [15:43<04:56,  2.54s/it, acc=0.8554, loss=0.2190]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 374/490 [15:43<04:54,  2.54s/it, acc=0.8554, loss=0.2190]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 374/490 [15:45<04:54,  2.54s/it, acc=0.8553, loss=0.3538]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 375/490 [15:45<04:51,  2.54s/it, acc=0.8553, loss=0.3538]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 375/490 [15:48<04:51,  2.54s/it, acc=0.8553, loss=0.4085]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 376/490 [15:48<04:48,  2.53s/it, acc=0.8553, loss=0.4085]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 376/490 [15:50<04:48,  2.53s/it, acc=0.8553, loss=0.4732]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 377/490 [15:50<04:46,  2.54s/it, acc=0.8553, loss=0.4732]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 377/490 [15:53<04:46,  2.54s/it, acc=0.8552, loss=0.3525]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 378/490 [15:53<04:44,  2.54s/it, acc=0.8552, loss=0.3525]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 378/490 [15:55<04:44,  2.54s/it, acc=0.8553, loss=0.2872]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 379/490 [15:55<04:42,  2.54s/it, acc=0.8553, loss=0.2872]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 379/490 [15:58<04:42,  2.54s/it, acc=0.8556, loss=0.2932]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 380/490 [15:58<04:39,  2.54s/it, acc=0.8556, loss=0.2932]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 380/490 [16:00<04:39,  2.54s/it, acc=0.8558, loss=0.1289]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 381/490 [16:00<04:36,  2.54s/it, acc=0.8558, loss=0.1289]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 381/490 [16:03<04:36,  2.54s/it, acc=0.8560, loss=0.2064]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 382/490 [16:03<04:34,  2.54s/it, acc=0.8560, loss=0.2064]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 382/490 [16:05<04:34,  2.54s/it, acc=0.8562, loss=0.3077]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 383/490 [16:05<04:31,  2.54s/it, acc=0.8562, loss=0.3077]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 383/490 [16:08<04:31,  2.54s/it, acc=0.8563, loss=0.3834]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 384/490 [16:08<04:29,  2.54s/it, acc=0.8563, loss=0.3834]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 384/490 [16:11<04:29,  2.54s/it, acc=0.8563, loss=0.2971]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 385/490 [16:11<04:26,  2.54s/it, acc=0.8563, loss=0.2971]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 385/490 [16:13<04:26,  2.54s/it, acc=0.8564, loss=0.3610]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 386/490 [16:13<04:24,  2.54s/it, acc=0.8564, loss=0.3610]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 386/490 [16:16<04:24,  2.54s/it, acc=0.8565, loss=0.3136]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 387/490 [16:16<04:21,  2.54s/it, acc=0.8565, loss=0.3136]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 387/490 [16:18<04:21,  2.54s/it, acc=0.8566, loss=0.3980]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 388/490 [16:18<04:18,  2.54s/it, acc=0.8566, loss=0.3980]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 388/490 [16:21<04:18,  2.54s/it, acc=0.8565, loss=0.4694]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 389/490 [16:21<04:16,  2.54s/it, acc=0.8565, loss=0.4694]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 389/490 [16:23<04:16,  2.54s/it, acc=0.8565, loss=0.6320]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 390/490 [16:23<04:14,  2.54s/it, acc=0.8565, loss=0.6320]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 390/490 [16:26<04:14,  2.54s/it, acc=0.8566, loss=0.3044]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 391/490 [16:26<04:11,  2.54s/it, acc=0.8566, loss=0.3044]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 391/490 [16:28<04:11,  2.54s/it, acc=0.8567, loss=0.3342]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 392/490 [16:28<04:08,  2.54s/it, acc=0.8567, loss=0.3342]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 392/490 [16:31<04:08,  2.54s/it, acc=0.8569, loss=0.1546]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 393/490 [16:31<04:06,  2.54s/it, acc=0.8569, loss=0.1546]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 393/490 [16:33<04:06,  2.54s/it, acc=0.8569, loss=0.3063]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 394/490 [16:33<04:03,  2.54s/it, acc=0.8569, loss=0.3063]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 394/490 [16:36<04:03,  2.54s/it, acc=0.8568, loss=0.4158]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 395/490 [16:36<04:01,  2.54s/it, acc=0.8568, loss=0.4158]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 395/490 [16:38<04:01,  2.54s/it, acc=0.8565, loss=0.8594]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 396/490 [16:38<03:58,  2.54s/it, acc=0.8565, loss=0.8594]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 396/490 [16:41<03:58,  2.54s/it, acc=0.8564, loss=0.3847]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 397/490 [16:41<03:56,  2.54s/it, acc=0.8564, loss=0.3847]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 397/490 [16:44<03:56,  2.54s/it, acc=0.8565, loss=0.3663]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 398/490 [16:44<03:53,  2.54s/it, acc=0.8565, loss=0.3663]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 398/490 [16:46<03:53,  2.54s/it, acc=0.8568, loss=0.1783]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 399/490 [16:46<03:51,  2.54s/it, acc=0.8568, loss=0.1783]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 399/490 [16:49<03:51,  2.54s/it, acc=0.8569, loss=0.3417]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 400/490 [16:49<03:48,  2.54s/it, acc=0.8569, loss=0.3417]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 400/490 [16:51<03:48,  2.54s/it, acc=0.8566, loss=0.5493]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 401/490 [16:51<03:45,  2.54s/it, acc=0.8566, loss=0.5493]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 401/490 [16:54<03:45,  2.54s/it, acc=0.8564, loss=0.5270]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 402/490 [16:54<03:43,  2.54s/it, acc=0.8564, loss=0.5270]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 402/490 [16:56<03:43,  2.54s/it, acc=0.8565, loss=0.2768]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 403/490 [16:56<03:40,  2.54s/it, acc=0.8565, loss=0.2768]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 403/490 [16:59<03:40,  2.54s/it, acc=0.8565, loss=0.3278]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 404/490 [16:59<03:38,  2.54s/it, acc=0.8565, loss=0.3278]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 404/490 [17:01<03:38,  2.54s/it, acc=0.8566, loss=0.3371]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 405/490 [17:01<03:36,  2.54s/it, acc=0.8566, loss=0.3371]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 405/490 [17:04<03:36,  2.54s/it, acc=0.8561, loss=0.8581]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 406/490 [17:04<03:33,  2.54s/it, acc=0.8561, loss=0.8581]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 406/490 [17:06<03:33,  2.54s/it, acc=0.8561, loss=0.3397]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 407/490 [17:06<03:30,  2.54s/it, acc=0.8561, loss=0.3397]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 407/490 [17:09<03:30,  2.54s/it, acc=0.8562, loss=0.2365]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 408/490 [17:09<03:28,  2.54s/it, acc=0.8562, loss=0.2365]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 408/490 [17:11<03:28,  2.54s/it, acc=0.8559, loss=0.5667]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 409/490 [17:11<03:25,  2.54s/it, acc=0.8559, loss=0.5667]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 409/490 [17:14<03:25,  2.54s/it, acc=0.8559, loss=0.2937]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 410/490 [17:14<03:22,  2.54s/it, acc=0.8559, loss=0.2937]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 410/490 [17:17<03:22,  2.54s/it, acc=0.8559, loss=0.3390]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 411/490 [17:17<03:20,  2.53s/it, acc=0.8559, loss=0.3390]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 411/490 [17:19<03:20,  2.53s/it, acc=0.8560, loss=0.2652]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 412/490 [17:19<03:17,  2.53s/it, acc=0.8560, loss=0.2652]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 412/490 [17:22<03:17,  2.53s/it, acc=0.8562, loss=0.1470]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 413/490 [17:22<03:14,  2.53s/it, acc=0.8562, loss=0.1470]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 413/490 [17:24<03:14,  2.53s/it, acc=0.8562, loss=0.3481]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 414/490 [17:24<03:12,  2.53s/it, acc=0.8562, loss=0.3481]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 414/490 [17:27<03:12,  2.53s/it, acc=0.8563, loss=0.3440]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 415/490 [17:27<03:09,  2.53s/it, acc=0.8563, loss=0.3440]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 415/490 [17:29<03:09,  2.53s/it, acc=0.8564, loss=0.2508]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 416/490 [17:29<03:07,  2.53s/it, acc=0.8564, loss=0.2508]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 416/490 [17:32<03:07,  2.53s/it, acc=0.8563, loss=0.5317]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 417/490 [17:32<03:04,  2.53s/it, acc=0.8563, loss=0.5317]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 417/490 [17:34<03:04,  2.53s/it, acc=0.8563, loss=0.3596]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 418/490 [17:34<03:02,  2.53s/it, acc=0.8563, loss=0.3596]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 418/490 [17:37<03:02,  2.53s/it, acc=0.8562, loss=0.5386]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 419/490 [17:37<02:59,  2.53s/it, acc=0.8562, loss=0.5386]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 419/490 [17:39<02:59,  2.53s/it, acc=0.8561, loss=0.4101]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 420/490 [17:39<02:56,  2.53s/it, acc=0.8561, loss=0.4101]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 420/490 [17:42<02:56,  2.53s/it, acc=0.8561, loss=0.4532]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 421/490 [17:42<02:54,  2.53s/it, acc=0.8561, loss=0.4532]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 421/490 [17:44<02:54,  2.53s/it, acc=0.8560, loss=0.4631]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 422/490 [17:44<02:51,  2.52s/it, acc=0.8560, loss=0.4631]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 422/490 [17:47<02:51,  2.52s/it, acc=0.8559, loss=0.4167]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 423/490 [17:47<02:49,  2.53s/it, acc=0.8559, loss=0.4167]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 423/490 [17:49<02:49,  2.53s/it, acc=0.8561, loss=0.3658]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 424/490 [17:49<02:46,  2.52s/it, acc=0.8561, loss=0.3658]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 424/490 [17:52<02:46,  2.52s/it, acc=0.8559, loss=0.5323]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 425/490 [17:52<02:43,  2.52s/it, acc=0.8559, loss=0.5323]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 425/490 [17:54<02:43,  2.52s/it, acc=0.8561, loss=0.2372]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 426/490 [17:54<02:41,  2.52s/it, acc=0.8561, loss=0.2372]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 426/490 [17:57<02:41,  2.52s/it, acc=0.8562, loss=0.4368]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 427/490 [17:57<02:38,  2.52s/it, acc=0.8562, loss=0.4368]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 427/490 [17:59<02:38,  2.52s/it, acc=0.8562, loss=0.3472]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 428/490 [17:59<02:36,  2.52s/it, acc=0.8562, loss=0.3472]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 428/490 [18:02<02:36,  2.52s/it, acc=0.8563, loss=0.3667]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 429/490 [18:02<02:33,  2.52s/it, acc=0.8563, loss=0.3667]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 429/490 [18:04<02:33,  2.52s/it, acc=0.8563, loss=0.3181]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 430/490 [18:04<02:31,  2.52s/it, acc=0.8563, loss=0.3181]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 430/490 [18:07<02:31,  2.52s/it, acc=0.8561, loss=0.6348]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 431/490 [18:07<02:28,  2.52s/it, acc=0.8561, loss=0.6348]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 431/490 [18:10<02:28,  2.52s/it, acc=0.8559, loss=0.5267]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 432/490 [18:10<02:26,  2.52s/it, acc=0.8559, loss=0.5267]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 432/490 [18:12<02:26,  2.52s/it, acc=0.8562, loss=0.1810]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 433/490 [18:12<02:23,  2.52s/it, acc=0.8562, loss=0.1810]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 433/490 [18:15<02:23,  2.52s/it, acc=0.8560, loss=0.4494]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 434/490 [18:15<02:21,  2.52s/it, acc=0.8560, loss=0.4494]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 434/490 [18:17<02:21,  2.52s/it, acc=0.8558, loss=0.5421]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 435/490 [18:17<02:18,  2.52s/it, acc=0.8558, loss=0.5421]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 435/490 [18:20<02:18,  2.52s/it, acc=0.8558, loss=0.5341]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 436/490 [18:20<02:16,  2.52s/it, acc=0.8558, loss=0.5341]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 436/490 [18:22<02:16,  2.52s/it, acc=0.8557, loss=0.4418]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 437/490 [18:22<02:13,  2.52s/it, acc=0.8557, loss=0.4418]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 437/490 [18:25<02:13,  2.52s/it, acc=0.8556, loss=0.5015]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 438/490 [18:25<02:10,  2.52s/it, acc=0.8556, loss=0.5015]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 438/490 [18:27<02:10,  2.52s/it, acc=0.8556, loss=0.4708]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 439/490 [18:27<02:08,  2.52s/it, acc=0.8556, loss=0.4708]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 439/490 [18:30<02:08,  2.52s/it, acc=0.8557, loss=0.3710]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 440/490 [18:30<02:05,  2.52s/it, acc=0.8557, loss=0.3710]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 440/490 [18:32<02:05,  2.52s/it, acc=0.8558, loss=0.4049]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 441/490 [18:32<02:03,  2.52s/it, acc=0.8558, loss=0.4049]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 441/490 [18:35<02:03,  2.52s/it, acc=0.8558, loss=0.3985]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 442/490 [18:35<02:00,  2.52s/it, acc=0.8558, loss=0.3985]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 442/490 [18:37<02:00,  2.52s/it, acc=0.8558, loss=0.4183]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 443/490 [18:37<01:58,  2.52s/it, acc=0.8558, loss=0.4183]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 443/490 [18:40<01:58,  2.52s/it, acc=0.8559, loss=0.3776]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 444/490 [18:40<01:55,  2.52s/it, acc=0.8559, loss=0.3776]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 444/490 [18:42<01:55,  2.52s/it, acc=0.8559, loss=0.4080]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 445/490 [18:42<01:53,  2.52s/it, acc=0.8559, loss=0.4080]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 445/490 [18:45<01:53,  2.52s/it, acc=0.8562, loss=0.1922]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 446/490 [18:45<01:50,  2.51s/it, acc=0.8562, loss=0.1922]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 446/490 [18:47<01:50,  2.51s/it, acc=0.8562, loss=0.2641]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 447/490 [18:47<01:48,  2.52s/it, acc=0.8562, loss=0.2641]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 447/490 [18:50<01:48,  2.52s/it, acc=0.8562, loss=0.3351]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 448/490 [18:50<01:45,  2.52s/it, acc=0.8562, loss=0.3351]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 448/490 [18:52<01:45,  2.52s/it, acc=0.8561, loss=0.3806]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 449/490 [18:52<01:43,  2.51s/it, acc=0.8561, loss=0.3806]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 449/490 [18:55<01:43,  2.51s/it, acc=0.8561, loss=0.4121]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 450/490 [18:55<01:40,  2.51s/it, acc=0.8561, loss=0.4121]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 450/490 [18:57<01:40,  2.51s/it, acc=0.8563, loss=0.1968]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 451/490 [18:57<01:38,  2.51s/it, acc=0.8563, loss=0.1968]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 451/490 [19:00<01:38,  2.51s/it, acc=0.8562, loss=0.5669]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 452/490 [19:00<01:35,  2.51s/it, acc=0.8562, loss=0.5669]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 452/490 [19:02<01:35,  2.51s/it, acc=0.8563, loss=0.3769]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 453/490 [19:02<01:32,  2.51s/it, acc=0.8563, loss=0.3769]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 453/490 [19:05<01:32,  2.51s/it, acc=0.8563, loss=0.5640]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 454/490 [19:05<01:30,  2.51s/it, acc=0.8563, loss=0.5640]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 454/490 [19:07<01:30,  2.51s/it, acc=0.8562, loss=0.3705]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 455/490 [19:07<01:27,  2.51s/it, acc=0.8562, loss=0.3705]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 455/490 [19:10<01:27,  2.51s/it, acc=0.8564, loss=0.3144]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 456/490 [19:10<01:25,  2.51s/it, acc=0.8564, loss=0.3144]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 456/490 [19:12<01:25,  2.51s/it, acc=0.8564, loss=0.3670]#015Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 457/490 [19:12<01:22,  2.51s/it, acc=0.8564, loss=0.3670]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 457/490 [19:15<01:22,  2.51s/it, acc=0.8564, loss=0.2501]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 458/490 [19:15<01:20,  2.51s/it, acc=0.8564, loss=0.2501]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 458/490 [19:17<01:20,  2.51s/it, acc=0.8564, loss=0.2809]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 459/490 [19:17<01:17,  2.51s/it, acc=0.8564, loss=0.2809]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 459/490 [19:20<01:17,  2.51s/it, acc=0.8567, loss=0.1636]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 460/490 [19:20<01:15,  2.51s/it, acc=0.8567, loss=0.1636]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 460/490 [19:22<01:15,  2.51s/it, acc=0.8567, loss=0.2520]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 461/490 [19:22<01:12,  2.51s/it, acc=0.8567, loss=0.2520]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 461/490 [19:25<01:12,  2.51s/it, acc=0.8566, loss=0.4792]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 462/490 [19:25<01:10,  2.51s/it, acc=0.8566, loss=0.4792]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 462/490 [19:27<01:10,  2.51s/it, acc=0.8568, loss=0.2815]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 463/490 [19:27<01:07,  2.51s/it, acc=0.8568, loss=0.2815]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 463/490 [19:30<01:07,  2.51s/it, acc=0.8568, loss=0.3998]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 464/490 [19:30<01:05,  2.51s/it, acc=0.8568, loss=0.3998]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 464/490 [19:32<01:05,  2.51s/it, acc=0.8569, loss=0.2510]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 465/490 [19:32<01:02,  2.51s/it, acc=0.8569, loss=0.2510]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 465/490 [19:35<01:02,  2.51s/it, acc=0.8568, loss=0.4808]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 466/490 [19:35<01:00,  2.51s/it, acc=0.8568, loss=0.4808]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 466/490 [19:37<01:00,  2.51s/it, acc=0.8567, loss=0.4379]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 467/490 [19:37<00:57,  2.51s/it, acc=0.8567, loss=0.4379]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 467/490 [19:40<00:57,  2.51s/it, acc=0.8566, loss=0.5883]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 468/490 [19:40<00:55,  2.51s/it, acc=0.8566, loss=0.5883]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 468/490 [19:42<00:55,  2.51s/it, acc=0.8565, loss=0.4893]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 469/490 [19:42<00:52,  2.51s/it, acc=0.8565, loss=0.4893]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 469/490 [19:45<00:52,  2.51s/it, acc=0.8566, loss=0.3318]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 470/490 [19:45<00:50,  2.51s/it, acc=0.8566, loss=0.3318]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 470/490 [19:48<00:50,  2.51s/it, acc=0.8568, loss=0.1945]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 471/490 [19:48<00:47,  2.51s/it, acc=0.8568, loss=0.1945]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 471/490 [19:50<00:47,  2.51s/it, acc=0.8568, loss=0.2133]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 472/490 [19:50<00:45,  2.51s/it, acc=0.8568, loss=0.2133]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 472/490 [19:53<00:45,  2.51s/it, acc=0.8569, loss=0.2275]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 473/490 [19:53<00:42,  2.51s/it, acc=0.8569, loss=0.2275]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 473/490 [19:55<00:42,  2.51s/it, acc=0.8571, loss=0.2279]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 474/490 [19:55<00:40,  2.51s/it, acc=0.8571, loss=0.2279]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 474/490 [19:58<00:40,  2.51s/it, acc=0.8571, loss=0.3560]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 475/490 [19:58<00:37,  2.51s/it, acc=0.8571, loss=0.3560]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 475/490 [20:00<00:37,  2.51s/it, acc=0.8571, loss=0.3781]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 476/490 [20:00<00:35,  2.51s/it, acc=0.8571, loss=0.3781]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 476/490 [20:03<00:35,  2.51s/it, acc=0.8572, loss=0.3739]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 477/490 [20:03<00:32,  2.51s/it, acc=0.8572, loss=0.3739]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 477/490 [20:05<00:32,  2.51s/it, acc=0.8572, loss=0.3392]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 478/490 [20:05<00:30,  2.51s/it, acc=0.8572, loss=0.3392]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 478/490 [20:08<00:30,  2.51s/it, acc=0.8572, loss=0.3100]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 479/490 [20:08<00:27,  2.51s/it, acc=0.8572, loss=0.3100]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 479/490 [20:10<00:27,  2.51s/it, acc=0.8570, loss=0.6201]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 480/490 [20:10<00:25,  2.51s/it, acc=0.8570, loss=0.6201]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 480/490 [20:13<00:25,  2.51s/it, acc=0.8569, loss=0.4194]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 481/490 [20:13<00:22,  2.51s/it, acc=0.8569, loss=0.4194]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 481/490 [20:15<00:22,  2.51s/it, acc=0.8570, loss=0.3472]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 482/490 [20:15<00:20,  2.51s/it, acc=0.8570, loss=0.3472]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 482/490 [20:18<00:20,  2.51s/it, acc=0.8569, loss=0.4361]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 483/490 [20:18<00:17,  2.51s/it, acc=0.8569, loss=0.4361]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 483/490 [20:20<00:17,  2.51s/it, acc=0.8569, loss=0.3124]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 484/490 [20:20<00:15,  2.51s/it, acc=0.8569, loss=0.3124]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 484/490 [20:23<00:15,  2.51s/it, acc=0.8570, loss=0.2758]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 485/490 [20:23<00:12,  2.51s/it, acc=0.8570, loss=0.2758]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 485/490 [20:25<00:12,  2.51s/it, acc=0.8570, loss=0.2342]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 486/490 [20:25<00:10,  2.51s/it, acc=0.8570, loss=0.2342]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 486/490 [20:28<00:10,  2.51s/it, acc=0.8570, loss=0.3036]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 487/490 [20:28<00:07,  2.51s/it, acc=0.8570, loss=0.3036]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 487/490 [20:30<00:07,  2.51s/it, acc=0.8570, loss=0.2633]\n",
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 488/490 [20:30<00:05,  2.51s/it, acc=0.8570, loss=0.2633]\n",
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 488/490 [20:33<00:05,  2.51s/it, acc=0.8570, loss=0.4417]\n",
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 489/490 [20:33<00:02,  2.51s/it, acc=0.8570, loss=0.4417]\n",
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 489/490 [20:34<00:02,  2.51s/it, acc=0.8570, loss=0.4479]\n",
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 490/490 [20:34<00:00,  2.17s/it, acc=0.8570, loss=0.4479]\n",
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 490/490 [20:34<00:00,  2.52s/it, acc=0.8570, loss=0.4479]\n",
            "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2956: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "Train Acc: 0.8570, Top-3 Acc: 0.9805, Log Loss: 0.3949\n",
            "[METRICS] epoch=2 train_loss=0.3949 train_acc=0.8570\n",
            "  Top-3 Accuracy: 0.9805\n",
            "  Log Loss: 0.3949\n",
            "  Macro Avg    - F1: 0.8641, Precision: 0.8648, Recall: 0.8638\n",
            "  Weighted Avg - F1: 0.8571, Precision: 0.8576, Recall: 0.8570\n",
            "  Per-Class F1 Scores:\n",
            "    antelope_duiker     : F1=0.8011, Confidence=0.8394\n",
            "    bird                : F1=0.9004, Confidence=0.9046\n",
            "    blank               : F1=0.6901, Confidence=0.6975\n",
            "    civet_genet         : F1=0.9365, Confidence=0.9256\n",
            "hog                 : F1=0.9410, Confidence=0.9510\n",
            "    leopard             : F1=0.9603, Confidence=0.9603\n",
            "    monkey_prosimian    : F1=0.8401, Confidence=0.8423\n",
            "    rodent              : F1=0.8431, Confidence=0.8291\n",
            "After training GPU memory - Allocated: 3017.58 MB, Reserved: 14034.00 MB\n",
            "Validating:   0%|          | 0/26 [00:00<?, ?it/s]\n",
            "Validating:   0%|          | 0/26 [00:01<?, ?it/s, acc=0.7500, loss=0.5391]\n",
            "Validating:   4%|‚ñç         | 1/26 [00:01<00:27,  1.10s/it, acc=0.7500, loss=0.5391]\n",
            "Validating:   4%|‚ñç         | 1/26 [00:01<00:27,  1.10s/it, acc=0.8125, loss=0.5226]\n",
            "Validating:   8%|‚ñä         | 2/26 [00:01<00:22,  1.07it/s, acc=0.8125, loss=0.5226]\n",
            "Validating:   8%|‚ñä         | 2/26 [00:02<00:22,  1.07it/s, acc=0.8333, loss=0.3079]\n",
            "Validating:  12%|‚ñà‚ñè        | 3/26 [00:02<00:20,  1.14it/s, acc=0.8333, loss=0.3079]\n",
            "Validating:  12%|‚ñà‚ñè        | 3/26 [00:03<00:20,  1.14it/s, acc=0.8359, loss=0.7528]\n",
            "Validating:  15%|‚ñà‚ñå        | 4/26 [00:03<00:18,  1.17it/s, acc=0.8359, loss=0.7528]\n",
            "Validating:  15%|‚ñà‚ñå        | 4/26 [00:04<00:18,  1.17it/s, acc=0.8313, loss=0.6464]\n",
            "Validating:  19%|‚ñà‚ñâ        | 5/26 [00:04<00:17,  1.19it/s, acc=0.8313, loss=0.6464]\n",
            "Validating:  19%|‚ñà‚ñâ        | 5/26 [00:05<00:17,  1.19it/s, acc=0.8438, loss=0.1365]\n",
            "Validating:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:05<00:16,  1.20it/s, acc=0.8438, loss=0.1365]\n",
            "Validating:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:05<00:16,  1.20it/s, acc=0.8571, loss=0.3713]\n",
            "Validating:  27%|‚ñà‚ñà‚ñã       | 7/26 [00:05<00:15,  1.21it/s, acc=0.8571, loss=0.3713]\n",
            "Validating:  27%|‚ñà‚ñà‚ñã       | 7/26 [00:06<00:15,  1.21it/s, acc=0.8594, loss=0.3840]\n",
            "Validating:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:06<00:14,  1.21it/s, acc=0.8594, loss=0.3840]\n",
            "Validating:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:07<00:14,  1.21it/s, acc=0.8646, loss=0.1960]\n",
            "Validating:  35%|‚ñà‚ñà‚ñà‚ñç      | 9/26 [00:07<00:13,  1.22it/s, acc=0.8646, loss=0.1960]\n",
            "Validating:  35%|‚ñà‚ñà‚ñà‚ñç      | 9/26 [00:08<00:13,  1.22it/s, acc=0.8562, loss=0.6482]\n",
            "Validating:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:08<00:13,  1.22it/s, acc=0.8562, loss=0.6482]\n",
            "Validating:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:09<00:13,  1.22it/s, acc=0.8551, loss=0.5285]\n",
            "Validating:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 11/26 [00:09<00:12,  1.22it/s, acc=0.8551, loss=0.5285]\n",
            "Validating:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 11/26 [00:10<00:12,  1.22it/s, acc=0.8594, loss=0.2384]\n",
            "Validating:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:10<00:11,  1.22it/s, acc=0.8594, loss=0.2384]\n",
            "Validating:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:10<00:11,  1.22it/s, acc=0.8582, loss=0.3271]\n",
            "Validating:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 13/26 [00:10<00:10,  1.22it/s, acc=0.8582, loss=0.3271]\n",
            "Validating:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 13/26 [00:11<00:10,  1.22it/s, acc=0.8638, loss=0.1796]\n",
            "Validating:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:11<00:09,  1.22it/s, acc=0.8638, loss=0.1796]\n",
            "Validating:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:12<00:09,  1.22it/s, acc=0.8688, loss=0.1778]\n",
            "Validating:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 15/26 [00:12<00:09,  1.22it/s, acc=0.8688, loss=0.1778]\n",
            "Validating:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 15/26 [00:13<00:09,  1.22it/s, acc=0.8672, loss=0.4982]\n",
            "Validating:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:13<00:08,  1.22it/s, acc=0.8672, loss=0.4982]\n",
            "Validating:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:14<00:08,  1.22it/s, acc=0.8640, loss=0.5388]\n",
            "Validating:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 17/26 [00:14<00:07,  1.22it/s, acc=0.8640, loss=0.5388]\n",
            "Validating:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 17/26 [00:14<00:07,  1.22it/s, acc=0.8681, loss=0.2297]\n",
            "Validating:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:14<00:06,  1.22it/s, acc=0.8681, loss=0.2297]\n",
            "Validating:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:15<00:06,  1.22it/s, acc=0.8717, loss=0.3135]\n",
            "Validating:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 19/26 [00:15<00:05,  1.22it/s, acc=0.8717, loss=0.3135]\n",
            "Validating:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 19/26 [00:16<00:05,  1.22it/s, acc=0.8734, loss=0.2191]\n",
            "Validating:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:16<00:04,  1.22it/s, acc=0.8734, loss=0.2191]\n",
            "Validating:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:17<00:04,  1.22it/s, acc=0.8720, loss=0.5131]\n",
            "Validating:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 21/26 [00:17<00:04,  1.22it/s, acc=0.8720, loss=0.5131]\n",
            "Validating:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 21/26 [00:18<00:04,  1.22it/s, acc=0.8764, loss=0.1237]\n",
            "Validating:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:18<00:03,  1.22it/s, acc=0.8764, loss=0.1237]\n",
            "Validating:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:19<00:03,  1.22it/s, acc=0.8791, loss=0.3326]\n",
            "Validating:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 23/26 [00:19<00:02,  1.22it/s, acc=0.8791, loss=0.3326]\n",
            "Validating:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 23/26 [00:19<00:02,  1.22it/s, acc=0.8802, loss=0.2469]\n",
            "Validating:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:19<00:01,  1.22it/s, acc=0.8802, loss=0.2469]\n",
            "Validating:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:20<00:01,  1.22it/s, acc=0.8850, loss=0.1280]\n",
            "Validating:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 25/26 [00:20<00:00,  1.22it/s, acc=0.8850, loss=0.1280]\n",
            "Validating:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 25/26 [00:21<00:00,  1.22it/s, acc=0.8861, loss=0.3046]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [00:21<00:00,  1.30it/s, acc=0.8861, loss=0.3046]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [00:21<00:00,  1.21it/s, acc=0.8861, loss=0.3046]\n",
            "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2956: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "Validation Loss: 0.3622, Validation Acc: 0.8861, Top-3 Acc: 0.9867, Log Loss: 0.3622\n",
            "[METRICS] epoch=2 val_loss=0.3622 val_acc=0.8861\n",
            "  Top-3 Accuracy: 0.9867\n",
            "  Log Loss: 0.3622\n",
            "  Macro Avg    - F1: 0.8924, Precision: 0.8973, Recall: 0.8912\n",
            "  Weighted Avg - F1: 0.8860, Precision: 0.8897, Recall: 0.8861\n",
            "Per-Class F1 Scores:\n",
            "    antelope_duiker     : F1=0.8097, Confidence=0.8624\n",
            "    bird                : F1=0.9157, Confidence=0.9486\n",
            "    blank               : F1=0.7565, Confidence=0.7804\n",
            "civet_genet         : F1=0.9524, Confidence=0.9658\n",
            "    hog                 : F1=0.9574, Confidence=0.9559\n",
            "    leopard             : F1=0.9782, Confidence=0.9568\n",
            "    monkey_prosimian    : F1=0.8711, Confidence=0.8890\n",
            "    rodent              : F1=0.8986, Confidence=0.8832\n",
            "Learning Rate: 0.000090 ‚Üí 0.000079\n",
            "After validation GPU memory - Allocated: 3017.58 MB, Reserved: 14734.00 MB\n",
            "Saving best model to convnext-largeWeights_2_best.pth with val acc 0.8861\n",
            "‚úì Best model saved! (Val Acc: 0.8861), path: /opt/ml/model/convnext-largeWeights_2_best.pth\n",
            "Saving metrics to /opt/ml/model\n",
            "‚úì Metrics saved to /opt/ml/model\n",
            "  - /opt/ml/model/train_metrics_2.json\n",
            "  Total epochs logged: 3\n",
            "Saving metrics to /opt/ml/model\n",
            "‚úì Metrics saved to /opt/ml/model\n",
            "  - /opt/ml/model/val_metrics_2.json\n",
            "  Total epochs logged: 3\n",
            "Epoch 4/10\n",
            "Start of epoch GPU memory - Allocated: 3017.58 MB, Reserved: 3824.00 MB\n",
            "Training...\n",
            "Training:   0%|          | 0/490 [00:00<?, ?it/s]\n",
            "Training:   0%|          | 0/490 [00:03<?, ?it/s, acc=0.9375, loss=0.1831]\n",
            "Training:   0%|          | 1/490 [00:03<24:56,  3.06s/it, acc=0.9375, loss=0.1831]\n",
            "Training:   0%|          | 1/490 [00:05<24:56,  3.06s/it, acc=0.9375, loss=0.2623]\n",
            "Training:   0%|          | 2/490 [00:05<22:14,  2.73s/it, acc=0.9375, loss=0.2623]\n"
          ]
        }
      ],
      "source": [
        "estimator_3.fit(\n",
        "    {'training': S3_PREPROCESSED},\n",
        "    wait=True,      # ‚úÖ Wait for job to complete\n",
        "    logs='All'      # ‚úÖ Stream ALL logs to notebook (shows all print statements!)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fc85ee86",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<sagemaker.pytorch.estimator.PyTorch object at 0x169393750>\n"
          ]
        }
      ],
      "source": [
        "train_file = \"dss_transformer_train.py\"\n",
        "part1_my_output_path = \"s3://sagemaker-us-west-1-253490779227/animal-classification-resnet18\"\n",
        "gpu = \"ml.g4dn.2xlarge\"\n",
        "estimator = PyTorch(\n",
        "    entry_point=train_file,\n",
        "    output_path=part1_my_output_path,\n",
        "    dependencies=[\"requirements.txt\"],\n",
        "    role=ROLE_ARN,\n",
        "    framework_version='2.1',\n",
        "    py_version='py310',\n",
        "    instance_count=1,\n",
        "    instance_type=gpu,  # GPU instance with NVIDIA T4\n",
        "    hyperparameters={\n",
        "        'epochs': 10,\n",
        "        'batch-size': 64,  \n",
        "        'learning-rate': 1e-5, \n",
        "        'use-cuda': True, \n",
        "        \"image-size\": 224,\n",
        "        \"weight-decay\": 1e-8,\n",
        "        \"stochastic-depth\": 0.2,\n",
        "        \"num-cpu\": 4,\n",
        "        \"save-file\": \"resnet18_model.pth\"\n",
        "    },\n",
        "    sagemaker_session=sagemaker_session,\n",
        "    base_job_name='resnet18',    \n",
        "    # max_run=3600,   \n",
        ")\n",
        "# estimator.latest_training_job.stop()\n",
        "print(estimator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ae786a91",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<sagemaker.pytorch.estimator.PyTorch object at 0x16911e590>\n"
          ]
        }
      ],
      "source": [
        "train_file = \"dss_transformer_train.py\"\n",
        "part1_my_output_path = \"s3://sagemaker-us-west-1-253490779227/animal-classification-models_part1\"\n",
        "\n",
        "estimator = PyTorch(\n",
        "    entry_point=train_file,\n",
        "    output_path=part1_my_output_path,\n",
        "    dependencies=[\"requirements.txt\"],\n",
        "    role=ROLE_ARN,\n",
        "    framework_version='2.1',\n",
        "    py_version='py310',\n",
        "    instance_count=1,\n",
        "    instance_type='ml.g4dn.xlarge',  # GPU instance with NVIDIA T4\n",
        "    hyperparameters={\n",
        "        'epochs': 10,\n",
        "        'batch-size': 64,  \n",
        "        'learning-rate': 1e-5, \n",
        "        'use-cuda': True, \n",
        "        \"image-size\": 224,\n",
        "        \"weight-decay\": 1e-8,\n",
        "        \"stochastic-depth\": 0.2,\n",
        "        \"num-cpu\": 4,\n",
        "        \"save-file\": \"final_swin_t_model_part1.pth\"\n",
        "    },\n",
        "    sagemaker_session=sagemaker_session,\n",
        "    base_job_name='swin-stage1',    \n",
        "    # max_run=3600,   \n",
        ")\n",
        "# estimator.latest_training_job.stop()\n",
        "print(estimator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b5b92d6c",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
            "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We are training using this file:  dss_transformer_train.py  with this data:  s3://animal-classification-virgina/processed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
            "INFO:sagemaker:Creating training-job with name: swin-stage1-2026-02-02-18-45-14-523\n",
            "ERROR:sagemaker:Please check the troubleshooting guide for common errors: https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sdk-troubleshooting.html#sagemaker-python-sdk-troubleshooting-create-training-job\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Traceback </span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"We are training using this file: \"</span>, train_file, <span style=\"color: #808000; text-decoration-color: #808000\">\" with this data: \"</span>, S3_PREPROCES     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>3 <span style=\"font-weight: bold; text-decoration: underline\">estimator.fit(</span>                                                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold; text-decoration: underline\">‚îÇ   </span><span style=\"font-weight: bold; text-decoration: underline\">{</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">'training'</span><span style=\"font-weight: bold; text-decoration: underline\">: S3_PREPROCESSED},</span>                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold; text-decoration: underline\">‚îÇ   </span><span style=\"font-weight: bold; text-decoration: underline\">wait=</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">True</span><span style=\"font-weight: bold; text-decoration: underline\">,      </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold; text-decoration: underline\"># ‚úÖ Wait for job to complete</span>                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold; text-decoration: underline\">‚îÇ   </span><span style=\"font-weight: bold; text-decoration: underline\">logs=</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">'All'</span><span style=\"font-weight: bold; text-decoration: underline\">      </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold; text-decoration: underline\"># ‚úÖ Stream ALL logs to notebook (shows all print statements!)</span>           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/sagemaker</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/pytorch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">estimator.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">755</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fit</span>                                                                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 752 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"sagemaker_recipe_local_path\"</span>: <span style=\"color: #808000; text-decoration-color: #808000\">f\"/opt/ml/input/data/{</span>recipe_channel_  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 753 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>}                                                                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 754 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>)                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span> 755 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>(PyTorch, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>).fit(                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 756 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>inputs=inputs,                                                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 757 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>wait=wait,                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 758 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>logs=logs,                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/sagemaker</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/telemetry/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">telemetry_logging.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">171</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">168 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>caught_ex = e                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">169 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">finally</span>:                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">170 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> caught_ex:                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>171 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">raise</span><span style=\"font-weight: bold; text-decoration: underline\"> caught_ex</span>                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">172 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> response  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># pylint: disable=W0150</span>                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">173 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">174 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>logger.debug(                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/sagemaker</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/telemetry/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">telemetry_logging.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">142</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">139 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>start_timer = perf_counter()                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">140 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">141 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Call the original function</span>                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>142 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>response = func(*args, **kwargs)                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">143 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>stop_timer = perf_counter()                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>elapsed = stop_timer - start_timer                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">145 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>extra += <span style=\"color: #808000; text-decoration-color: #808000\">f\"&amp;x-latency={</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">round</span>(elapsed,<span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>)<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/sagemaker</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/workflow/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">pipeline_context.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">346</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">343 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>                                                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">344 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _StepArguments(retrieve_caller_name(self_instance), run_func, *args,    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">345 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>                                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>346 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"font-weight: bold; text-decoration: underline\">run_func(*args, **kwargs)</span>                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">347 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span>                                                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">348 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> wrapper                                                                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">349 </span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/sagemaker</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">estimator.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1422</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fit</span>                                                                        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1419 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._prepare_for_training(job_name=job_name)                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1420 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1421 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>experiment_config = check_and_get_run_experiment_config(experiment_config)        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>1422 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.latest_training_job = <span style=\"font-weight: bold; text-decoration: underline\">_TrainingJob.start_new(</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">self</span><span style=\"font-weight: bold; text-decoration: underline\">, inputs, experiment_confi</span>  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1423 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.jobs.append(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.latest_training_job)                                        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1424 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>forward_to_mlflow_tracking_server = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>                                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1425 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> os.environ.get(<span style=\"color: #808000; text-decoration-color: #808000\">\"MLFLOW_TRACKING_URI\"</span>) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.enable_network_isolation():     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/sagemaker</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">estimator.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2568</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">start_new</span>                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2565 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>train_args = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>._get_train_args(estimator, inputs, experiment_config)            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2566 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2567 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>logger.debug(<span style=\"color: #808000; text-decoration-color: #808000\">\"Train args after processing defaults: %s\"</span>, train_args)              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>2568 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"font-weight: bold; text-decoration: underline\">estimator.sagemaker_session.train(**train_args)</span>                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2569 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2570 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>(estimator.sagemaker_session, estimator._current_job_name)              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2571 </span>                                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/sagemaker</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">session.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1283</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                                                                        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1280 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>)                                                                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1281 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> e                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1282 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>1283 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">self</span><span style=\"font-weight: bold; text-decoration: underline\">._intercept_create_request(train_request, submit, </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">self</span><span style=\"font-weight: bold; text-decoration: underline\">.train.</span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; text-decoration: underline\">__name__</span><span style=\"font-weight: bold; text-decoration: underline\">)</span>        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1284 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span>                                                                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1285 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_train_request</span>(  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># noqa: C901</span>                                                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1286 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>,                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/sagemaker</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">session.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">7036</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_intercept_create_request</span>                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">7033 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #808000; text-decoration-color: #808000\">create (functor): a functor calls the sagemaker client create method</span>          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">7034 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #808000; text-decoration-color: #808000\">func_name (str): the name of the function needed intercepting</span>                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">7035 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>7036 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"font-weight: bold; text-decoration: underline\">create(request)</span>                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">7037 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span>                                                                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">7038 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">_create_inference_recommendations_job_request</span>(                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">7039 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>,                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/sagemaker</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">session.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1281</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">submit</span>                                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>logger.error(                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1279 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"Please check the troubleshooting guide for common errors: %s\"</span>, trou  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1280 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>)                                                                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>1281 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">raise</span><span style=\"font-weight: bold; text-decoration: underline\"> e</span>                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1282 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1283 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._intercept_create_request(train_request, submit, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.train.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span>)        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1284 </span>                                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/sagemaker</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">session.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1272</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">submit</span>                                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1269 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1270 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>logger.info(<span style=\"color: #808000; text-decoration-color: #808000\">\"Creating training-job with name: %s\"</span>, job_name)              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1271 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>logger.debug(<span style=\"color: #808000; text-decoration-color: #808000\">\"train request: %s\"</span>, json.dumps(request, indent=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>))          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>1272 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sagemaker_client.create_training_job(**request)                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1273 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">Exception</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> e:                                                        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1274 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>troubleshooting = (                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1275 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sd</span>  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/botocore/</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">client.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">602</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_api_call</span>                                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 599 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"{</span>py_operation_name<span style=\"color: #808000; text-decoration-color: #808000\">}() only accepts keyword arguments.\"</span>              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 600 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>)                                                                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 601 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># The \"self\" in this scope is referring to the BaseClient.</span>                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span> 602 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">self</span><span style=\"font-weight: bold; text-decoration: underline\">._make_api_call(operation_name, kwargs)</span>                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 603 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 604 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>_api_call.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span> = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>(py_operation_name)                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 605 </span>                                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/botocore/</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">context.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">123</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                                                                        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">120 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> start_as_current_context():                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> hook:                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">122 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>hook()                                                                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>123 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"font-weight: bold; text-decoration: underline\">func(*args, **kwargs)</span>                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">124 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>                                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">125 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> wrapper                                                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">126 </span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/botocore/</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">client.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1078</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_make_api_call</span>                                                                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1075 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #808000; text-decoration-color: #808000\">'error_code_override'</span>                                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1076 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> error_info.get(<span style=\"color: #808000; text-decoration-color: #808000\">\"Code\"</span>)                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1077 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>error_class = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.exceptions.from_code(error_code)                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>1078 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">raise</span><span style=\"font-weight: bold; text-decoration: underline\"> error_class(parsed_response, operation_name)</span>                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1079 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1080 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> parsed_response                                                        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1081 </span>                                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ResourceLimitExceeded: </span>An error occurred <span style=\"font-weight: bold\">(</span>ResourceLimitExceeded<span style=\"font-weight: bold\">)</span> when calling the CreateTrainingJob operation: The \n",
              "account-level service limit <span style=\"color: #008700; text-decoration-color: #008700\">'ml.g4dn.xlarge for training job usage'</span> is <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> Instances, with current utilization of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> \n",
              "Instances and a request delta of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> Instances. Please use AWS Service Quotas to request an increase for this quota. \n",
              "If AWS Service Quotas is not available, contact AWS support to request an increase for this quota.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[38;2;255;0;0m‚ï≠‚îÄ\u001b[0m\u001b[38;2;255;0;0m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[1;38;2;255;0;0mTraceback \u001b[0m\u001b[1;2;38;2;255;0;0m(most recent call last)\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[38;2;255;0;0m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[38;2;255;0;0m‚îÄ‚ïÆ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m3\u001b[0m                                                                                    \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1 \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mWe are training using this file: \u001b[0m\u001b[33m\"\u001b[0m, train_file, \u001b[33m\"\u001b[0m\u001b[33m with this data: \u001b[0m\u001b[33m\"\u001b[0m, S3_PREPROCES     \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m3 \u001b[1;4mestimator.fit(\u001b[0m                                                                               \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m4 \u001b[0m\u001b[1;2;4m‚îÇ   \u001b[0m\u001b[1;4m{\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33mtraining\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4m: S3_PREPROCESSED},\u001b[0m                                                           \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m5 \u001b[0m\u001b[1;2;4m‚îÇ   \u001b[0m\u001b[1;4mwait=\u001b[0m\u001b[1;4;94mTrue\u001b[0m\u001b[1;4m,      \u001b[0m\u001b[1;2;4m# ‚úÖ Wait for job to complete\u001b[0m                                            \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m6 \u001b[0m\u001b[1;2;4m‚îÇ   \u001b[0m\u001b[1;4mlogs=\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33mAll\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4m      \u001b[0m\u001b[1;2;4m# ‚úÖ Stream ALL logs to notebook (shows all print statements!)\u001b[0m           \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2;33m/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/sagemaker\u001b[0m \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2;33m/pytorch/\u001b[0m\u001b[1;33mestimator.py\u001b[0m:\u001b[94m755\u001b[0m in \u001b[92mfit\u001b[0m                                                                 \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m 752 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33msagemaker_recipe_local_path\u001b[0m\u001b[33m\"\u001b[0m: \u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m/opt/ml/input/data/\u001b[0m\u001b[33m{\u001b[0mrecipe_channel_  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m 753 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m}                                                                         \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m 754 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m)                                                                             \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m 755 \u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96msuper\u001b[0m(PyTorch, \u001b[96mself\u001b[0m).fit(                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m 756 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0minputs=inputs,                                                                \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m 757 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mwait=wait,                                                                    \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m 758 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mlogs=logs,                                                                    \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2;33m/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/sagemaker\u001b[0m \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2;33m/telemetry/\u001b[0m\u001b[1;33mtelemetry_logging.py\u001b[0m:\u001b[94m171\u001b[0m in \u001b[92mwrapper\u001b[0m                                                   \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m168 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mcaught_ex = e                                                          \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m169 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mfinally\u001b[0m:                                                                   \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m170 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mif\u001b[0m caught_ex:                                                          \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m171 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[1;4;94mraise\u001b[0m\u001b[1;4m caught_ex\u001b[0m                                                    \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m172 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m response  \u001b[2m# pylint: disable=W0150\u001b[0m                               \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m173 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94melse\u001b[0m:                                                                          \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m174 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mlogger.debug(                                                              \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2;33m/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/sagemaker\u001b[0m \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2;33m/telemetry/\u001b[0m\u001b[1;33mtelemetry_logging.py\u001b[0m:\u001b[94m142\u001b[0m in \u001b[92mwrapper\u001b[0m                                                   \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m139 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mstart_timer = perf_counter()                                               \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m140 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mtry\u001b[0m:                                                                       \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m141 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[2m# Call the original function\u001b[0m                                           \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m142 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mresponse = func(*args, **kwargs)                                       \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m143 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mstop_timer = perf_counter()                                            \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m144 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0melapsed = stop_timer - start_timer                                     \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m145 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mextra += \u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m&x-latency=\u001b[0m\u001b[33m{\u001b[0m\u001b[96mround\u001b[0m(elapsed,\u001b[90m \u001b[0m\u001b[94m2\u001b[0m)\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m                             \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2;33m/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/sagemaker\u001b[0m \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2;33m/workflow/\u001b[0m\u001b[1;33mpipeline_context.py\u001b[0m:\u001b[94m346\u001b[0m in \u001b[92mwrapper\u001b[0m                                                     \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m343 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m                                                                               \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m344 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m _StepArguments(retrieve_caller_name(self_instance), run_func, *args,    \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m345 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m                                                                                   \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m346 \u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4mrun_func(*args, **kwargs)\u001b[0m                                                   \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m347 \u001b[0m\u001b[2m‚îÇ   \u001b[0m                                                                                       \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m348 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m wrapper                                                                         \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m349 \u001b[0m                                                                                           \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2;33m/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/sagemaker\u001b[0m \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2;33m/\u001b[0m\u001b[1;33mestimator.py\u001b[0m:\u001b[94m1422\u001b[0m in \u001b[92mfit\u001b[0m                                                                        \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1419 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[96mself\u001b[0m._prepare_for_training(job_name=job_name)                                     \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1420 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1421 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0mexperiment_config = check_and_get_run_experiment_config(experiment_config)        \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m1422 \u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[96mself\u001b[0m.latest_training_job = \u001b[1;4m_TrainingJob.start_new(\u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m, inputs, experiment_confi\u001b[0m  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1423 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[96mself\u001b[0m.jobs.append(\u001b[96mself\u001b[0m.latest_training_job)                                        \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1424 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0mforward_to_mlflow_tracking_server = \u001b[94mFalse\u001b[0m                                         \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1425 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mif\u001b[0m os.environ.get(\u001b[33m\"\u001b[0m\u001b[33mMLFLOW_TRACKING_URI\u001b[0m\u001b[33m\"\u001b[0m) \u001b[95mand\u001b[0m \u001b[96mself\u001b[0m.enable_network_isolation():     \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2;33m/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/sagemaker\u001b[0m \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2;33m/\u001b[0m\u001b[1;33mestimator.py\u001b[0m:\u001b[94m2568\u001b[0m in \u001b[92mstart_new\u001b[0m                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m2565 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0mtrain_args = \u001b[96mcls\u001b[0m._get_train_args(estimator, inputs, experiment_config)            \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m2566 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m2567 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0mlogger.debug(\u001b[33m\"\u001b[0m\u001b[33mTrain args after processing defaults: \u001b[0m\u001b[33m%s\u001b[0m\u001b[33m\"\u001b[0m, train_args)              \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m2568 \u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[1;4mestimator.sagemaker_session.train(**train_args)\u001b[0m                                   \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m2569 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m2570 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mcls\u001b[0m(estimator.sagemaker_session, estimator._current_job_name)              \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m2571 \u001b[0m                                                                                          \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2;33m/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/sagemaker\u001b[0m \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2;33m/\u001b[0m\u001b[1;33msession.py\u001b[0m:\u001b[94m1283\u001b[0m in \u001b[92mtrain\u001b[0m                                                                        \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1280 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m)                                                                         \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1281 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mraise\u001b[0m e                                                                   \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1282 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m1283 \u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m._intercept_create_request(train_request, submit, \u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m.train.\u001b[0m\u001b[1;4;91m__name__\u001b[0m\u001b[1;4m)\u001b[0m        \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1284 \u001b[0m\u001b[2m‚îÇ   \u001b[0m                                                                                      \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1285 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92m_get_train_request\u001b[0m(  \u001b[2m# noqa: C901\u001b[0m                                                 \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1286 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[96mself\u001b[0m,                                                                             \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2;33m/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/sagemaker\u001b[0m \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2;33m/\u001b[0m\u001b[1;33msession.py\u001b[0m:\u001b[94m7036\u001b[0m in \u001b[92m_intercept_create_request\u001b[0m                                                    \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m7033 \u001b[0m\u001b[2;33m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[33mcreate (functor): a functor calls the sagemaker client create method\u001b[0m          \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m7034 \u001b[0m\u001b[2;33m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[33mfunc_name (str): the name of the function needed intercepting\u001b[0m                 \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m7035 \u001b[0m\u001b[2;33m‚îÇ   ‚îÇ   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m7036 \u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4mcreate(request)\u001b[0m                                                            \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m7037 \u001b[0m\u001b[2m‚îÇ   \u001b[0m                                                                                      \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m7038 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92m_create_inference_recommendations_job_request\u001b[0m(                                    \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m7039 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[96mself\u001b[0m,                                                                             \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2;33m/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/sagemaker\u001b[0m \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2;33m/\u001b[0m\u001b[1;33msession.py\u001b[0m:\u001b[94m1281\u001b[0m in \u001b[92msubmit\u001b[0m                                                                       \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1278 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mlogger.error(                                                             \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1279 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mPlease check the troubleshooting guide for common errors: \u001b[0m\u001b[33m%s\u001b[0m\u001b[33m\"\u001b[0m, trou  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1280 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m)                                                                         \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m1281 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[1;4;94mraise\u001b[0m\u001b[1;4m e\u001b[0m                                                                   \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1282 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1283 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[96mself\u001b[0m._intercept_create_request(train_request, submit, \u001b[96mself\u001b[0m.train.\u001b[91m__name__\u001b[0m)        \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1284 \u001b[0m                                                                                          \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2;33m/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/sagemaker\u001b[0m \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2;33m/\u001b[0m\u001b[1;33msession.py\u001b[0m:\u001b[94m1272\u001b[0m in \u001b[92msubmit\u001b[0m                                                                       \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1269 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mtry\u001b[0m:                                                                          \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1270 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mlogger.info(\u001b[33m\"\u001b[0m\u001b[33mCreating training-job with name: \u001b[0m\u001b[33m%s\u001b[0m\u001b[33m\"\u001b[0m, job_name)              \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1271 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mlogger.debug(\u001b[33m\"\u001b[0m\u001b[33mtrain request: \u001b[0m\u001b[33m%s\u001b[0m\u001b[33m\"\u001b[0m, json.dumps(request, indent=\u001b[94m4\u001b[0m))          \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m1272 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[96mself\u001b[0m.sagemaker_client.create_training_job(**request)                      \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1273 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m \u001b[94mas\u001b[0m e:                                                        \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1274 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mtroubleshooting = (                                                       \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1275 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mhttps://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sd\u001b[0m  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2;33m/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/botocore/\u001b[0m \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[1;33mclient.py\u001b[0m:\u001b[94m602\u001b[0m in \u001b[92m_api_call\u001b[0m                                                                       \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m 599 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m{\u001b[0mpy_operation_name\u001b[33m}\u001b[0m\u001b[33m() only accepts keyword arguments.\u001b[0m\u001b[33m\"\u001b[0m              \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m 600 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m)                                                                         \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m 601 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[2m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m                    \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m 602 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4;96mself\u001b[0m\u001b[1;4m._make_api_call(operation_name, kwargs)\u001b[0m                            \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m 603 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m 604 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m_api_call.\u001b[91m__name__\u001b[0m = \u001b[96mstr\u001b[0m(py_operation_name)                                       \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m 605 \u001b[0m                                                                                          \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2;33m/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/botocore/\u001b[0m \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[1;33mcontext.py\u001b[0m:\u001b[94m123\u001b[0m in \u001b[92mwrapper\u001b[0m                                                                        \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m120 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mwith\u001b[0m start_as_current_context():                                               \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m121 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mif\u001b[0m hook:                                                                   \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m122 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mhook()                                                                 \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m123 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4mfunc(*args, **kwargs)\u001b[0m                                               \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m124 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m                                                                                   \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m125 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m wrapper                                                                     \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m126 \u001b[0m                                                                                           \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2;33m/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/botocore/\u001b[0m \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[1;33mclient.py\u001b[0m:\u001b[94m1078\u001b[0m in \u001b[92m_make_api_call\u001b[0m                                                                 \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1075 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[33m'\u001b[0m\u001b[33merror_code_override\u001b[0m\u001b[33m'\u001b[0m                                                     \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1076 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m) \u001b[95mor\u001b[0m error_info.get(\u001b[33m\"\u001b[0m\u001b[33mCode\u001b[0m\u001b[33m\"\u001b[0m)                                                   \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1077 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0merror_class = \u001b[96mself\u001b[0m.exceptions.from_code(error_code)                           \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m1078 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[1;4;94mraise\u001b[0m\u001b[1;4m error_class(parsed_response, operation_name)\u001b[0m                            \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1079 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1080 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m parsed_response                                                        \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1081 \u001b[0m                                                                                          \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n",
              "\u001b[1;91mResourceLimitExceeded: \u001b[0mAn error occurred \u001b[1m(\u001b[0mResourceLimitExceeded\u001b[1m)\u001b[0m when calling the CreateTrainingJob operation: The \n",
              "account-level service limit \u001b[38;2;0;135;0m'ml.g4dn.xlarge for training job usage'\u001b[0m is \u001b[1;36m0\u001b[0m Instances, with current utilization of \u001b[1;36m0\u001b[0m \n",
              "Instances and a request delta of \u001b[1;36m1\u001b[0m Instances. Please use AWS Service Quotas to request an increase for this quota. \n",
              "If AWS Service Quotas is not available, contact AWS support to request an increase for this quota.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"We are training using this file: \", train_file, \" with this data: \", S3_PREPROCESSED)\n",
        "\n",
        "estimator.fit(\n",
        "    {'training': S3_PREPROCESSED},\n",
        "    wait=True,      # ‚úÖ Wait for job to complete\n",
        "    logs='All'      # ‚úÖ Stream ALL logs to notebook (shows all print statements!)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63a55d5b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Traceback </span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>1 <span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"font-weight: bold; text-decoration: underline\">estimator.model_data</span>)                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/sagemaker</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">estimator.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1938</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">model_data</span>                                                                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1935 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>job_details = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sagemaker_session.sagemaker_client.describe_training_job(  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1936 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>TrainingJobName=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.latest_training_job.name                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1937 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>)                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>1938 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>model_uri = <span style=\"font-weight: bold; text-decoration: underline\">job_details[</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">\"ModelArtifacts\"</span><span style=\"font-weight: bold; text-decoration: underline\">]</span>[<span style=\"color: #808000; text-decoration-color: #808000\">\"S3ModelArtifacts\"</span>]                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1939 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>compression_type = job_details.get(<span style=\"color: #808000; text-decoration-color: #808000\">\"OutputDataConfig\"</span>, {}).get(               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1940 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"CompressionType\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"GZIP\"</span>                                                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1941 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>)                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyError: </span><span style=\"color: #008700; text-decoration-color: #008700\">'ModelArtifacts'</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[38;2;255;0;0m‚ï≠‚îÄ\u001b[0m\u001b[38;2;255;0;0m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[1;38;2;255;0;0mTraceback \u001b[0m\u001b[1;2;38;2;255;0;0m(most recent call last)\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[38;2;255;0;0m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[38;2;255;0;0m‚îÄ‚ïÆ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m1 \u001b[96mprint\u001b[0m(\u001b[1;4mestimator.model_data\u001b[0m)                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2;33m/Users/amannindra/Projects/DSS-Image-Classification/.venv/lib/python3.11/site-packages/sagemaker\u001b[0m \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2;33m/\u001b[0m\u001b[1;33mestimator.py\u001b[0m:\u001b[94m1938\u001b[0m in \u001b[92mmodel_data\u001b[0m                                                                 \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1935 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mjob_details = \u001b[96mself\u001b[0m.sagemaker_session.sagemaker_client.describe_training_job(  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1936 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mTrainingJobName=\u001b[96mself\u001b[0m.latest_training_job.name                             \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1937 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m)                                                                             \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m1938 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mmodel_uri = \u001b[1;4mjob_details[\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33mModelArtifacts\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4m]\u001b[0m[\u001b[33m\"\u001b[0m\u001b[33mS3ModelArtifacts\u001b[0m\u001b[33m\"\u001b[0m]                 \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1939 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mcompression_type = job_details.get(\u001b[33m\"\u001b[0m\u001b[33mOutputDataConfig\u001b[0m\u001b[33m\"\u001b[0m, {}).get(               \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1940 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mCompressionType\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mGZIP\u001b[0m\u001b[33m\"\u001b[0m                                                 \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1941 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m)                                                                             \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
              "\u001b[38;2;255;0;0m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n",
              "\u001b[1;91mKeyError: \u001b[0m\u001b[38;2;0;135;0m'ModelArtifacts'\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(estimator.model_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6e6b9532",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'REGION' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mboto3\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m sagemaker_client = boto3.client(\u001b[33m'\u001b[39m\u001b[33msagemaker\u001b[39m\u001b[33m'\u001b[39m, region_name=\u001b[43mREGION\u001b[49m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Get recent training jobs\u001b[39;00m\n\u001b[32m     11\u001b[39m jobs = sagemaker_client.list_training_jobs(\n\u001b[32m     12\u001b[39m     MaxResults=\u001b[32m10\u001b[39m, \n\u001b[32m     13\u001b[39m     SortBy=\u001b[33m'\u001b[39m\u001b[33mCreationTime\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m     14\u001b[39m     SortOrder=\u001b[33m'\u001b[39m\u001b[33mDescending\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     15\u001b[39m )\n",
            "\u001b[31mNameError\u001b[39m: name 'REGION' is not defined"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# RUN THIS CELL TO LIST ALL RECENT JOBS\n",
        "# ========================================\n",
        "\n",
        "import boto3\n",
        "from datetime import datetime\n",
        "\n",
        "sagemaker_client = boto3.client('sagemaker', region_name=REGION)\n",
        "\n",
        "# Get recent training jobs\n",
        "jobs = sagemaker_client.list_training_jobs(\n",
        "    MaxResults=10, \n",
        "    SortBy='CreationTime', \n",
        "    SortOrder='Descending'\n",
        ")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"RECENT TRAINING JOBS\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\n{'#':<4} {'Job Name':<50} {'Status':<15}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for i, job in enumerate(jobs['TrainingJobSummaries']):\n",
        "    job_name = job['TrainingJobName']\n",
        "    status = job['TrainingJobStatus']\n",
        "    created = job['CreationTime'].strftime('%Y-%m-%d %H:%M')\n",
        "    \n",
        "    # Color code status\n",
        "    status_symbol = {\n",
        "        'InProgress': 'üîÑ',\n",
        "        'Completed': '‚úÖ',\n",
        "        'Failed': '‚ùå',\n",
        "        'Stopped': '‚è∏Ô∏è'\n",
        "    }.get(status, '‚ùì')\n",
        "    \n",
        "    print(f\"{i:<4} {job_name:<50} {status_symbol} {status}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üí° Copy a job name above and paste it in the next cell to view its logs\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "85c6869b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ÑπÔ∏è  No job name specified, using most recent: animal-classification-training-2025-12-28-01-43-07-396\n",
            "\n",
            "================================================================================\n",
            "üìã TRAINING LOGS: animal-classification-training-2025-12-28-01-43-07-396\n",
            "================================================================================\n",
            "Total log lines: 2583\n",
            "Showing first 500 lines (set max_lines=None for all)\n",
            "================================================================================\n",
            "\n",
            "bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
            "bash: no job control in this shell\n",
            "/opt/conda/lib/python3.10/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
            "  \"cipher\": algorithms.TripleDES,\n",
            "/opt/conda/lib/python3.10/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
            "  \"class\": algorithms.TripleDES,\n",
            "2025-12-28 01:48:40,138 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
            "2025-12-28 01:48:40,157 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
            "2025-12-28 01:48:40,168 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
            "2025-12-28 01:48:40,174 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
            "2025-12-28 01:48:42,199 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
            "2025-12-28 01:48:42,230 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
            "2025-12-28 01:48:42,260 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
            "2025-12-28 01:48:42,271 sagemaker-training-toolkit INFO     Invoking user script\n",
            "Training Env:\n",
            "{\n",
            "    \"additional_framework_parameters\": {},\n",
            "    \"channel_input_dirs\": {\n",
            "        \"training\": \"/opt/ml/input/data/training\"\n",
            "    },\n",
            "    \"current_host\": \"algo-1\",\n",
            "    \"current_instance_group\": \"homogeneousCluster\",\n",
            "    \"current_instance_group_hosts\": [\n",
            "        \"algo-1\"\n",
            "    ],\n",
            "    \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
            "    \"distribution_hosts\": [],\n",
            "    \"distribution_instance_groups\": [],\n",
            "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
            "    \"hosts\": [\n",
            "        \"algo-1\"\n",
            "    ],\n",
            "    \"hyperparameters\": {\n",
            "        \"batch-size\": 64,\n",
            "        \"epochs\": 5,\n",
            "        \"learning-rate\": 0.001,\n",
            "        \"use-cuda\": true\n",
            "    },\n",
            "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
            "    \"input_data_config\": {\n",
            "        \"training\": {\n",
            "            \"TrainingInputMode\": \"File\",\n",
            "            \"S3DistributionType\": \"FullyReplicated\",\n",
            "            \"RecordWrapperType\": \"None\"\n",
            "        }\n",
            "    },\n",
            "    \"input_dir\": \"/opt/ml/input\",\n",
            "    \"instance_groups\": [\n",
            "        \"homogeneousCluster\"\n",
            "    ],\n",
            "    \"instance_groups_dict\": {\n",
            "        \"homogeneousCluster\": {\n",
            "            \"instance_group_name\": \"homogeneousCluster\",\n",
            "            \"instance_type\": \"ml.g4dn.xlarge\",\n",
            "            \"hosts\": [\n",
            "                \"algo-1\"\n",
            "            ]\n",
            "        }\n",
            "    },\n",
            "    \"is_hetero\": false,\n",
            "    \"is_master\": true,\n",
            "    \"is_modelparallel_enabled\": null,\n",
            "    \"is_smddpmprun_installed\": false,\n",
            "    \"is_smddprun_installed\": true,\n",
            "    \"job_name\": \"animal-classification-training-2025-12-28-01-43-07-396\",\n",
            "    \"log_level\": 20,\n",
            "    \"master_hostname\": \"algo-1\",\n",
            "    \"model_dir\": \"/opt/ml/model\",\n",
            "    \"module_dir\": \"s3://sagemaker-us-west-1-253490779227/animal-classification-training-2025-12-28-01-43-07-396/source/sourcedir.tar.gz\",\n",
            "    \"module_name\": \"dss_train\",\n",
            "    \"network_interface_name\": \"eth0\",\n",
            "    \"num_cpus\": 4,\n",
            "    \"num_gpus\": 1,\n",
            "    \"num_neurons\": 0,\n",
            "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
            "    \"output_dir\": \"/opt/ml/output\",\n",
            "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
            "    \"resource_config\": {\n",
            "        \"current_host\": \"algo-1\",\n",
            "        \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
            "        \"current_group_name\": \"homogeneousCluster\",\n",
            "        \"hosts\": [\n",
            "            \"algo-1\"\n",
            "        ],\n",
            "        \"instance_groups\": [\n",
            "            {\n",
            "                \"instance_group_name\": \"homogeneousCluster\",\n",
            "                \"instance_type\": \"ml.g4dn.xlarge\",\n",
            "                \"hosts\": [\n",
            "                    \"algo-1\"\n",
            "                ]\n",
            "            }\n",
            "        ],\n",
            "        \"network_interface_name\": \"eth0\",\n",
            "        \"topology\": null\n",
            "    },\n",
            "    \"user_entry_point\": \"dss_train.py\"\n",
            "}\n",
            "Environment variables:\n",
            "SM_HOSTS=[\"algo-1\"]\n",
            "SM_NETWORK_INTERFACE_NAME=eth0\n",
            "SM_HPS={\"batch-size\":64,\"epochs\":5,\"learning-rate\":0.001,\"use-cuda\":true}\n",
            "SM_USER_ENTRY_POINT=dss_train.py\n",
            "SM_FRAMEWORK_PARAMS={}\n",
            "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\n",
            "SM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
            "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
            "SM_CHANNELS=[\"training\"]\n",
            "SM_CURRENT_HOST=algo-1\n",
            "SM_CURRENT_INSTANCE_TYPE=ml.g4dn.xlarge\n",
            "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
            "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\n",
            "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
            "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}}\n",
            "SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
            "SM_IS_HETERO=false\n",
            "SM_MODULE_NAME=dss_train\n",
            "SM_LOG_LEVEL=20\n",
            "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
            "SM_INPUT_DIR=/opt/ml/input\n",
            "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
            "SM_OUTPUT_DIR=/opt/ml/output\n",
            "SM_NUM_CPUS=4\n",
            "SM_NUM_GPUS=1\n",
            "SM_NUM_NEURONS=0\n",
            "SM_MODEL_DIR=/opt/ml/model\n",
            "SM_MODULE_DIR=s3://sagemaker-us-west-1-253490779227/animal-classification-training-2025-12-28-01-43-07-396/source/sourcedir.tar.gz\n",
            "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g4dn.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":64,\"epochs\":5,\"learning-rate\":0.001,\"use-cuda\":true},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":true,\"job_name\":\"animal-classification-training-2025-12-28-01-43-07-396\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-1-253490779227/animal-classification-training-2025-12-28-01-43-07-396/source/sourcedir.tar.gz\",\"module_name\":\"dss_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"user_entry_point\":\"dss_train.py\"}\n",
            "SM_USER_ARGS=[\"--batch-size\",\"64\",\"--epochs\",\"5\",\"--learning-rate\",\"0.001\",\"--use-cuda\",\"True\"]\n",
            "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
            "SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
            "SM_HP_BATCH-SIZE=64\n",
            "SM_HP_EPOCHS=5\n",
            "SM_HP_LEARNING-RATE=0.001\n",
            "SM_HP_USE-CUDA=true\n",
            "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\n",
            "Invoking script with the following command:\n",
            "/opt/conda/bin/python3.10 dss_train.py --batch-size 64 --epochs 5 --learning-rate 0.001 --use-cuda True\n",
            "2025-12-28 01:48:42,272 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\n",
            "2025-12-28 01:48:42,272 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\n",
            "Starting training...\n",
            "Arguments: Namespace(epochs=5, batch_size=64, learning_rate=0.001, use_cuda=True, model_dir='/opt/ml/model', data_dir='/opt/ml/input/data/training')\n",
            "Initial RAM usage: 527.82 MB\n",
            "Using device: cuda\n",
            "Base path: /opt/ml/input/data/training\n",
            "After loading data RAM usage: 536.33 MB\n",
            "DataframeLoaded 16488 training samples\n",
            "Dataframe Columns: ['id', 'antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent']\n",
            "Dataframe sample:\n",
            "         id  antelope_duiker  bird  ...  leopard  monkey_prosimian  rodent\n",
            "0  ZJ000000              0.0   1.0  ...      0.0               0.0     0.0\n",
            "1  ZJ000001              0.0   0.0  ...      0.0               1.0     0.0\n",
            "2  ZJ000002              0.0   1.0  ...      0.0               0.0     0.0\n",
            "3  ZJ000003              0.0   0.0  ...      0.0               1.0     0.0\n",
            "4  ZJ000004              0.0   0.0  ...      1.0               0.0     0.0\n",
            "[5 rows x 9 columns]\n",
            "Dataframe shape: (16488, 9)\n",
            "Train DataFrame sample:\n",
            "             id  antelope_duiker  bird  ...  leopard  monkey_prosimian  rodent\n",
            "16129  ZJ016129              0.0   0.0  ...      1.0               0.0     0.0\n",
            "12284  ZJ012284              0.0   0.0  ...      0.0               0.0     1.0\n",
            "16416  ZJ016416              0.0   0.0  ...      0.0               0.0     1.0\n",
            "7487   ZJ007487              0.0   0.0  ...      0.0               0.0     0.0\n",
            "13491  ZJ013491              0.0   0.0  ...      0.0               0.0     0.0\n",
            "[5 rows x 9 columns]\n",
            "Train DataFrame shape: (12366, 9)\n",
            "Validation DataFrame sample:\n",
            "             id  antelope_duiker  bird  ...  leopard  monkey_prosimian  rodent\n",
            "2537   ZJ002537              0.0   0.0  ...      0.0               0.0     0.0\n",
            "284    ZJ000284              0.0   1.0  ...      0.0               0.0     0.0\n",
            "14561  ZJ014561              0.0   0.0  ...      0.0               0.0     0.0\n",
            "14723  ZJ014723              0.0   0.0  ...      0.0               0.0     0.0\n",
            "2950   ZJ002950              0.0   0.0  ...      0.0               1.0     0.0\n",
            "[5 rows x 9 columns]\n",
            "Validation DataFrame shape: (4122, 9)\n",
            "Training samples: 12366\n",
            "Validation samples: 4122\n",
            "Batch size: 64\n",
            "Train batches: 194\n",
            "Val batches: 65\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "0%|          | 0.00/44.7M [00:00<?, ?B/s]\n",
            "48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 21.2M/44.7M [00:00<00:00, 223MB/s]\n",
            "97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 43.2M/44.7M [00:00<00:00, 227MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44.7M/44.7M [00:00<00:00, 226MB/s]\n",
            "Model: ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=8, bias=True)\n",
            ")\n",
            "Epoch 1/5\n",
            "Training:   0%|          | 0/194 [00:00<?, ?it/s]\n",
            "Training:   0%|          | 0/194 [00:01<?, ?it/s, acc=0.0625, loss=2.2790]\n",
            "Training:   1%|          | 1/194 [00:01<03:56,  1.23s/it, acc=0.0625, loss=2.2790]\n",
            "Training:   1%|          | 1/194 [00:01<03:56,  1.23s/it, acc=0.2188, loss=1.8882]\n",
            "Training:   1%|          | 2/194 [00:01<01:56,  1.65it/s, acc=0.2188, loss=1.8882]\n",
            "Training:   1%|          | 2/194 [00:01<01:56,  1.65it/s, acc=0.2448, loss=2.0964]\n",
            "Training:   2%|‚ñè         | 3/194 [00:01<01:18,  2.42it/s, acc=0.2448, loss=2.0964]\n",
            "Training:   2%|‚ñè         | 3/194 [00:01<01:18,  2.42it/s, acc=0.2539, loss=2.0979]\n",
            "Training:   2%|‚ñè         | 4/194 [00:01<01:00,  3.12it/s, acc=0.2539, loss=2.0979]\n",
            "Training:   2%|‚ñè         | 4/194 [00:01<01:00,  3.12it/s, acc=0.2687, loss=1.8275]\n",
            "Training:   3%|‚ñé         | 5/194 [00:01<00:51,  3.70it/s, acc=0.2687, loss=1.8275]\n",
            "Training:   3%|‚ñé         | 5/194 [00:02<00:51,  3.70it/s, acc=0.2708, loss=2.0057]\n",
            "Training:   3%|‚ñé         | 6/194 [00:02<00:44,  4.18it/s, acc=0.2708, loss=2.0057]\n",
            "Training:   3%|‚ñé         | 6/194 [00:02<00:44,  4.18it/s, acc=0.2857, loss=1.6518]\n",
            "Training:   4%|‚ñé         | 7/194 [00:02<00:55,  3.39it/s, acc=0.2857, loss=1.6518]\n",
            "Training:   4%|‚ñé         | 7/194 [00:02<00:55,  3.39it/s, acc=0.3027, loss=1.6673]\n",
            "Training:   4%|‚ñç         | 8/194 [00:02<00:47,  3.88it/s, acc=0.3027, loss=1.6673]\n",
            "Training:   4%|‚ñç         | 8/194 [00:03<00:47,  3.88it/s, acc=0.3073, loss=1.7010]\n",
            "Training:   5%|‚ñç         | 9/194 [00:03<00:50,  3.64it/s, acc=0.3073, loss=1.7010]\n",
            "Training:   5%|‚ñç         | 9/194 [00:03<00:50,  3.64it/s, acc=0.3109, loss=2.0589]\n",
            "Training:   5%|‚ñå         | 10/194 [00:03<00:45,  4.07it/s, acc=0.3109, loss=2.0589]\n",
            "Training:   5%|‚ñå         | 10/194 [00:03<00:45,  4.07it/s, acc=0.3026, loss=1.7232]\n",
            "Training:   6%|‚ñå         | 11/194 [00:03<00:48,  3.75it/s, acc=0.3026, loss=1.7232]\n",
            "Training:   6%|‚ñå         | 11/194 [00:03<00:48,  3.75it/s, acc=0.2995, loss=1.9317]\n",
            "Training:   6%|‚ñå         | 12/194 [00:03<00:47,  3.84it/s, acc=0.2995, loss=1.9317]\n",
            "Training:   6%|‚ñå         | 12/194 [00:04<00:47,  3.84it/s, acc=0.2993, loss=1.8916]\n",
            "Training:   7%|‚ñã         | 13/194 [00:04<00:46,  3.90it/s, acc=0.2993, loss=1.8916]\n",
            "Training:   7%|‚ñã         | 13/194 [00:04<00:46,  3.90it/s, acc=0.3069, loss=1.5777]\n",
            "Training:   7%|‚ñã         | 14/194 [00:04<00:49,  3.66it/s, acc=0.3069, loss=1.5777]\n",
            "Training:   7%|‚ñã         | 14/194 [00:04<00:49,  3.66it/s, acc=0.3083, loss=1.6522]\n",
            "Training:   8%|‚ñä         | 15/194 [00:04<00:50,  3.56it/s, acc=0.3083, loss=1.6522]\n",
            "Training:   8%|‚ñä         | 15/194 [00:04<00:50,  3.56it/s, acc=0.3037, loss=1.7447]\n",
            "Training:   8%|‚ñä         | 16/194 [00:04<00:48,  3.64it/s, acc=0.3037, loss=1.7447]\n",
            "Training:   8%|‚ñä         | 16/194 [00:05<00:48,  3.64it/s, acc=0.3079, loss=1.6370]\n",
            "Training:   9%|‚ñâ         | 17/194 [00:05<00:46,  3.81it/s, acc=0.3079, loss=1.6370]\n",
            "Training:   9%|‚ñâ         | 17/194 [00:05<00:46,  3.81it/s, acc=0.3160, loss=1.6171]\n",
            "Training:   9%|‚ñâ         | 18/194 [00:05<00:49,  3.57it/s, acc=0.3160, loss=1.6171]\n",
            "Training:   9%|‚ñâ         | 18/194 [00:05<00:49,  3.57it/s, acc=0.3183, loss=1.7535]\n",
            "Training:  10%|‚ñâ         | 19/194 [00:05<00:45,  3.81it/s, acc=0.3183, loss=1.7535]\n",
            "Training:  10%|‚ñâ         | 19/194 [00:06<00:45,  3.81it/s, acc=0.3187, loss=1.7791]\n",
            "Training:  10%|‚ñà         | 20/194 [00:06<00:50,  3.42it/s, acc=0.3187, loss=1.7791]\n",
            "Training:  10%|‚ñà         | 20/194 [00:06<00:50,  3.42it/s, acc=0.3229, loss=1.7792]\n",
            "Training:  11%|‚ñà         | 21/194 [00:06<00:49,  3.53it/s, acc=0.3229, loss=1.7792]\n",
            "Training:  11%|‚ñà         | 21/194 [00:06<00:49,  3.53it/s, acc=0.3246, loss=1.6728]\n",
            "Training:  11%|‚ñà‚ñè        | 22/194 [00:06<00:47,  3.66it/s, acc=0.3246, loss=1.6728]\n",
            "Training:  11%|‚ñà‚ñè        | 22/194 [00:06<00:47,  3.66it/s, acc=0.3179, loss=1.8376]\n",
            "Training:  12%|‚ñà‚ñè        | 23/194 [00:06<00:48,  3.55it/s, acc=0.3179, loss=1.8376]\n",
            "Training:  12%|‚ñà‚ñè        | 23/194 [00:07<00:48,  3.55it/s, acc=0.3190, loss=1.6313]\n",
            "Training:  12%|‚ñà‚ñè        | 24/194 [00:07<00:45,  3.74it/s, acc=0.3190, loss=1.6313]\n",
            "Training:  12%|‚ñà‚ñè        | 24/194 [00:07<00:45,  3.74it/s, acc=0.3250, loss=1.4881]\n",
            "Training:  13%|‚ñà‚ñé        | 25/194 [00:07<00:50,  3.36it/s, acc=0.3250, loss=1.4881]\n",
            "Training:  13%|‚ñà‚ñé        | 25/194 [00:07<00:50,  3.36it/s, acc=0.3263, loss=1.6169]\n",
            "Training:  13%|‚ñà‚ñé        | 26/194 [00:07<00:44,  3.81it/s, acc=0.3263, loss=1.6169]\n",
            "Training:  13%|‚ñà‚ñé        | 26/194 [00:08<00:44,  3.81it/s, acc=0.3310, loss=1.5193]\n",
            "Training:  14%|‚ñà‚ñç        | 27/194 [00:08<00:51,  3.23it/s, acc=0.3310, loss=1.5193]\n",
            "Training:  14%|‚ñà‚ñç        | 27/194 [00:08<00:51,  3.23it/s, acc=0.3315, loss=1.7164]\n",
            "Training:  14%|‚ñà‚ñç        | 28/194 [00:08<00:44,  3.69it/s, acc=0.3315, loss=1.7164]\n",
            "Training:  14%|‚ñà‚ñç        | 28/194 [00:08<00:44,  3.69it/s, acc=0.3314, loss=1.5855]\n",
            "Training:  15%|‚ñà‚ñç        | 29/194 [00:08<00:51,  3.18it/s, acc=0.3314, loss=1.5855]\n",
            "Training:  15%|‚ñà‚ñç        | 29/194 [00:08<00:51,  3.18it/s, acc=0.3276, loss=1.7397]#015Training:  15%|‚ñà‚ñå        | 30/194 [00:08<00:44,  3.67it/s, acc=0.3276, loss=1.7397]\n",
            "Training:  15%|‚ñà‚ñå        | 30/194 [00:09<00:44,  3.67it/s, acc=0.3296, loss=1.5832]\n",
            "Training:  16%|‚ñà‚ñå        | 31/194 [00:09<00:53,  3.03it/s, acc=0.3296, loss=1.5832]\n",
            "Training:  16%|‚ñà‚ñå        | 31/194 [00:09<00:53,  3.03it/s, acc=0.3320, loss=1.4210]\n",
            "Training:  16%|‚ñà‚ñã        | 32/194 [00:09<00:45,  3.53it/s, acc=0.3320, loss=1.4210]\n",
            "Training:  16%|‚ñà‚ñã        | 32/194 [00:09<00:45,  3.53it/s, acc=0.3314, loss=1.4979]\n",
            "Training:  17%|‚ñà‚ñã        | 33/194 [00:09<00:54,  2.96it/s, acc=0.3314, loss=1.4979]\n",
            "Training:  17%|‚ñà‚ñã        | 33/194 [00:10<00:54,  2.96it/s, acc=0.3323, loss=1.4249]\n",
            "Training:  18%|‚ñà‚ñä        | 34/194 [00:10<00:46,  3.45it/s, acc=0.3323, loss=1.4249]\n",
            "Training:  18%|‚ñà‚ñä        | 34/194 [00:10<00:46,  3.45it/s, acc=0.3362, loss=1.4199]\n",
            "Training:  18%|‚ñà‚ñä        | 35/194 [00:10<00:52,  3.04it/s, acc=0.3362, loss=1.4199]\n",
            "Training:  18%|‚ñà‚ñä        | 35/194 [00:10<00:52,  3.04it/s, acc=0.3372, loss=1.4591]\n",
            "Training:  19%|‚ñà‚ñä        | 36/194 [00:10<00:44,  3.55it/s, acc=0.3372, loss=1.4591]\n",
            "Training:  19%|‚ñà‚ñä        | 36/194 [00:11<00:44,  3.55it/s, acc=0.3366, loss=1.6521]\n",
            "Training:  19%|‚ñà‚ñâ        | 37/194 [00:11<00:52,  3.01it/s, acc=0.3366, loss=1.6521]\n",
            "Training:  19%|‚ñà‚ñâ        | 37/194 [00:11<00:52,  3.01it/s, acc=0.3372, loss=1.5945]\n",
            "Training:  20%|‚ñà‚ñâ        | 38/194 [00:11<00:44,  3.49it/s, acc=0.3372, loss=1.5945]\n",
            "Training:  20%|‚ñà‚ñâ        | 38/194 [00:11<00:44,  3.49it/s, acc=0.3373, loss=1.6520]\n",
            "Training:  20%|‚ñà‚ñà        | 39/194 [00:11<00:49,  3.14it/s, acc=0.3373, loss=1.6520]\n",
            "Training:  20%|‚ñà‚ñà        | 39/194 [00:11<00:49,  3.14it/s, acc=0.3402, loss=1.4759]\n",
            "Training:  21%|‚ñà‚ñà        | 40/194 [00:11<00:42,  3.62it/s, acc=0.3402, loss=1.4759]\n",
            "Training:  21%|‚ñà‚ñà        | 40/194 [00:12<00:42,  3.62it/s, acc=0.3399, loss=1.5520]\n",
            "Training:  21%|‚ñà‚ñà        | 41/194 [00:12<00:49,  3.06it/s, acc=0.3399, loss=1.5520]\n",
            "Training:  21%|‚ñà‚ñà        | 41/194 [00:12<00:49,  3.06it/s, acc=0.3415, loss=1.5048]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 42/194 [00:12<00:42,  3.55it/s, acc=0.3415, loss=1.5048]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 42/194 [00:12<00:42,  3.55it/s, acc=0.3412, loss=1.5745]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 43/194 [00:12<00:46,  3.23it/s, acc=0.3412, loss=1.5745]\n",
            "Training:  22%|‚ñà‚ñà‚ñè       | 43/194 [00:13<00:46,  3.23it/s, acc=0.3420, loss=1.6822]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 44/194 [00:13<00:40,  3.69it/s, acc=0.3420, loss=1.6822]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 44/194 [00:13<00:40,  3.69it/s, acc=0.3451, loss=1.4059]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 45/194 [00:13<00:48,  3.09it/s, acc=0.3451, loss=1.4059]\n",
            "Training:  23%|‚ñà‚ñà‚ñé       | 45/194 [00:13<00:48,  3.09it/s, acc=0.3451, loss=1.6987]\n",
            "Training:  24%|‚ñà‚ñà‚ñé       | 46/194 [00:13<00:41,  3.57it/s, acc=0.3451, loss=1.6987]\n",
            "Training:  24%|‚ñà‚ñà‚ñé       | 46/194 [00:14<00:41,  3.57it/s, acc=0.3431, loss=1.6536]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 47/194 [00:14<00:44,  3.33it/s, acc=0.3431, loss=1.6536]\n",
            "Training:  24%|‚ñà‚ñà‚ñç       | 47/194 [00:14<00:44,  3.33it/s, acc=0.3447, loss=1.4496]\n",
            "Training:  25%|‚ñà‚ñà‚ñç       | 48/194 [00:14<00:38,  3.79it/s, acc=0.3447, loss=1.4496]\n",
            "Training:  25%|‚ñà‚ñà‚ñç       | 48/194 [00:14<00:38,  3.79it/s, acc=0.3460, loss=1.4337]\n",
            "Training:  25%|‚ñà‚ñà‚ñå       | 49/194 [00:14<00:48,  3.00it/s, acc=0.3460, loss=1.4337]\n",
            "Training:  25%|‚ñà‚ñà‚ñå       | 49/194 [00:14<00:48,  3.00it/s, acc=0.3488, loss=1.5158]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 50/194 [00:14<00:41,  3.50it/s, acc=0.3488, loss=1.5158]\n",
            "Training:  26%|‚ñà‚ñà‚ñå       | 50/194 [00:15<00:41,  3.50it/s, acc=0.3487, loss=1.6052]\n",
            "Training:  26%|‚ñà‚ñà‚ñã       | 51/194 [00:15<00:48,  2.94it/s, acc=0.3487, loss=1.6052]\n",
            "Training:  26%|‚ñà‚ñà‚ñã       | 51/194 [00:15<00:48,  2.94it/s, acc=0.3495, loss=1.5067]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 52/194 [00:15<00:41,  3.43it/s, acc=0.3495, loss=1.5067]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 52/194 [00:15<00:41,  3.43it/s, acc=0.3488, loss=1.5918]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 53/194 [00:15<00:45,  3.07it/s, acc=0.3488, loss=1.5918]\n",
            "Training:  27%|‚ñà‚ñà‚ñã       | 53/194 [00:16<00:45,  3.07it/s, acc=0.3510, loss=1.4117]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 54/194 [00:16<00:39,  3.55it/s, acc=0.3510, loss=1.4117]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 54/194 [00:16<00:39,  3.55it/s, acc=0.3531, loss=1.5658]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 55/194 [00:16<00:43,  3.18it/s, acc=0.3531, loss=1.5658]\n",
            "Training:  28%|‚ñà‚ñà‚ñä       | 55/194 [00:16<00:43,  3.18it/s, acc=0.3541, loss=1.5161]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 56/194 [00:16<00:37,  3.65it/s, acc=0.3541, loss=1.5161]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 56/194 [00:17<00:37,  3.65it/s, acc=0.3547, loss=1.5252]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 57/194 [00:17<00:42,  3.21it/s, acc=0.3547, loss=1.5252]\n",
            "Training:  29%|‚ñà‚ñà‚ñâ       | 57/194 [00:17<00:42,  3.21it/s, acc=0.3561, loss=1.5180]\n",
            "Training:  30%|‚ñà‚ñà‚ñâ       | 58/194 [00:17<00:36,  3.68it/s, acc=0.3561, loss=1.5180]\n",
            "Training:  30%|‚ñà‚ñà‚ñâ       | 58/194 [00:17<00:36,  3.68it/s, acc=0.3567, loss=1.5405]\n",
            "Training:  30%|‚ñà‚ñà‚ñà       | 59/194 [00:17<00:41,  3.23it/s, acc=0.3567, loss=1.5405]\n",
            "Training:  30%|‚ñà‚ñà‚ñà       | 59/194 [00:17<00:41,  3.23it/s, acc=0.3591, loss=1.4116]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 60/194 [00:17<00:36,  3.72it/s, acc=0.3591, loss=1.4116]\n",
            "Training:  31%|‚ñà‚ñà‚ñà       | 60/194 [00:18<00:36,  3.72it/s, acc=0.3622, loss=1.3768]\n",
            "Training:  31%|‚ñà‚ñà‚ñà‚ñè      | 61/194 [00:18<00:42,  3.16it/s, acc=0.3622, loss=1.3768]\n",
            "Training:  31%|‚ñà‚ñà‚ñà‚ñè      | 61/194 [00:18<00:42,  3.16it/s, acc=0.3616, loss=1.5909]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 62/194 [00:18<00:36,  3.63it/s, acc=0.3616, loss=1.5909]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 62/194 [00:18<00:36,  3.63it/s, acc=0.3586, loss=1.8926]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 63/194 [00:18<00:38,  3.43it/s, acc=0.3586, loss=1.8926]\n",
            "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 63/194 [00:18<00:38,  3.43it/s, acc=0.3591, loss=1.5116]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 64/194 [00:18<00:33,  3.88it/s, acc=0.3591, loss=1.5116]\n",
            "Training:  33%|‚ñà‚ñà‚ñà‚ñé      | 64/194 [00:19<00:33,  3.88it/s, acc=0.3601, loss=1.4385]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñé      | 65/194 [00:19<00:35,  3.60it/s, acc=0.3601, loss=1.4385]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñé      | 65/194 [00:19<00:35,  3.60it/s, acc=0.3603, loss=1.4242]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 66/194 [00:19<00:31,  4.03it/s, acc=0.3603, loss=1.4242]\n",
            "Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 66/194 [00:19<00:31,  4.03it/s, acc=0.3617, loss=1.4617]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñç      | 67/194 [00:19<00:33,  3.74it/s, acc=0.3617, loss=1.4617]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñç      | 67/194 [00:19<00:33,  3.74it/s, acc=0.3633, loss=1.3308]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñå      | 68/194 [00:19<00:30,  4.14it/s, acc=0.3633, loss=1.3308]\n",
            "Training:  35%|‚ñà‚ñà‚ñà‚ñå      | 68/194 [00:20<00:30,  4.14it/s, acc=0.3650, loss=1.3223]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 69/194 [00:20<00:32,  3.80it/s, acc=0.3650, loss=1.3223]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 69/194 [00:20<00:32,  3.80it/s, acc=0.3654, loss=1.4794]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 70/194 [00:20<00:32,  3.84it/s, acc=0.3654, loss=1.4794]\n",
            "Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 70/194 [00:20<00:32,  3.84it/s, acc=0.3662, loss=1.4739]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 71/194 [00:20<00:31,  3.85it/s, acc=0.3662, loss=1.4739]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 71/194 [00:21<00:31,  3.85it/s, acc=0.3663, loss=1.5031]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 72/194 [00:21<00:34,  3.56it/s, acc=0.3663, loss=1.5031]\n",
            "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 72/194 [00:21<00:34,  3.56it/s, acc=0.3669, loss=1.5538]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 73/194 [00:21<00:30,  3.98it/s, acc=0.3669, loss=1.5538]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 73/194 [00:21<00:30,  3.98it/s, acc=0.3676, loss=1.5520]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 74/194 [00:21<00:34,  3.45it/s, acc=0.3676, loss=1.5520]\n",
            "Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 74/194 [00:21<00:34,  3.45it/s, acc=0.3683, loss=1.5681]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñä      | 75/194 [00:21<00:30,  3.89it/s, acc=0.3683, loss=1.5681]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñä      | 75/194 [00:22<00:30,  3.89it/s, acc=0.3692, loss=1.4616]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 76/194 [00:22<00:34,  3.39it/s, acc=0.3692, loss=1.4616]\n",
            "Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 76/194 [00:22<00:34,  3.39it/s, acc=0.3699, loss=1.4351]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñâ      | 77/194 [00:22<00:30,  3.83it/s, acc=0.3699, loss=1.4351]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñâ      | 77/194 [00:22<00:30,  3.83it/s, acc=0.3720, loss=1.3007]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñà      | 78/194 [00:22<00:36,  3.20it/s, acc=0.3720, loss=1.3007]\n",
            "Training:  40%|‚ñà‚ñà‚ñà‚ñà      | 78/194 [00:23<00:36,  3.20it/s, acc=0.3736, loss=1.2829]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 79/194 [00:23<00:31,  3.67it/s, acc=0.3736, loss=1.2829]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 79/194 [00:23<00:31,  3.67it/s, acc=0.3750, loss=1.3961]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 80/194 [00:23<00:36,  3.14it/s, acc=0.3750, loss=1.3961]\n",
            "Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 80/194 [00:23<00:36,  3.14it/s, acc=0.3767, loss=1.3519]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 81/194 [00:23<00:31,  3.61it/s, acc=0.3767, loss=1.3519]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 81/194 [00:24<00:31,  3.61it/s, acc=0.3775, loss=1.5235]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 82/194 [00:24<00:36,  3.08it/s, acc=0.3775, loss=1.5235]\n",
            "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 82/194 [00:24<00:36,  3.08it/s, acc=0.3788, loss=1.3465]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 83/194 [00:24<00:31,  3.56it/s, acc=0.3788, loss=1.3465]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 83/194 [00:24<00:31,  3.56it/s, acc=0.3800, loss=1.1850]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 84/194 [00:24<00:36,  2.98it/s, acc=0.3800, loss=1.1850]\n",
            "Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 84/194 [00:24<00:36,  2.98it/s, acc=0.3809, loss=1.3872]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 85/194 [00:24<00:31,  3.47it/s, acc=0.3809, loss=1.3872]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 85/194 [00:25<00:31,  3.47it/s, acc=0.3823, loss=1.3150]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 86/194 [00:25<00:32,  3.30it/s, acc=0.3823, loss=1.3150]\n",
            "Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 86/194 [00:25<00:32,  3.30it/s, acc=0.3833, loss=1.3029]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 87/194 [00:25<00:28,  3.76it/s, acc=0.3833, loss=1.3029]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 87/194 [00:25<00:28,  3.76it/s, acc=0.3833, loss=1.5694]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 88/194 [00:25<00:29,  3.65it/s, acc=0.3833, loss=1.5694]\n",
            "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 88/194 [00:25<00:29,  3.65it/s, acc=0.3841, loss=1.4383]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 89/194 [00:25<00:25,  4.08it/s, acc=0.3841, loss=1.4383]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 89/194 [00:26<00:25,  4.08it/s, acc=0.3844, loss=1.4522]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 90/194 [00:26<00:29,  3.50it/s, acc=0.3844, loss=1.4522]\n",
            "Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 90/194 [00:26<00:29,  3.50it/s, acc=0.3843, loss=1.6913]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 91/194 [00:26<00:26,  3.93it/s, acc=0.3843, loss=1.6913]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 91/194 [00:26<00:26,  3.93it/s, acc=0.3854, loss=1.3144]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 92/194 [00:26<00:31,  3.22it/s, acc=0.3854, loss=1.3144]\n",
            "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 92/194 [00:27<00:31,  3.22it/s, acc=0.3866, loss=1.2573]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 93/194 [00:27<00:27,  3.70it/s, acc=0.3866, loss=1.2573]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 93/194 [00:27<00:27,  3.70it/s, acc=0.3878, loss=1.3033]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 94/194 [00:27<00:33,  3.01it/s, acc=0.3878, loss=1.3033]\n",
            "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 94/194 [00:27<00:33,  3.01it/s, acc=0.3891, loss=1.0970]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 95/194 [00:27<00:28,  3.48it/s, acc=0.3891, loss=1.0970]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 95/194 [00:28<00:28,  3.48it/s, acc=0.3900, loss=1.2681]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 96/194 [00:28<00:28,  3.39it/s, acc=0.3900, loss=1.2681]\n",
            "Training:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 96/194 [00:28<00:28,  3.39it/s, acc=0.3908, loss=1.4501]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 97/194 [00:28<00:25,  3.84it/s, acc=0.3908, loss=1.4501]\n",
            "Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 97/194 [00:28<00:25,  3.84it/s, acc=0.3916, loss=1.3848]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 98/194 [00:28<00:26,  3.66it/s, acc=0.3916, loss=1.3848]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 98/194 [00:28<00:26,  3.66it/s, acc=0.3924, loss=1.2897]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 99/194 [00:28<00:23,  4.08it/s, acc=0.3924, loss=1.2897]\n",
            "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 99/194 [00:28<00:23,  4.08it/s, acc=0.3934, loss=1.3610]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 100/194 [00:28<00:25,  3.72it/s, acc=0.3934, loss=1.3610]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 100/194 [00:29<00:25,  3.72it/s, acc=0.3945, loss=1.3004]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 101/194 [00:29<00:22,  4.12it/s, acc=0.3945, loss=1.3004]\n",
            "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 101/194 [00:29<00:22,  4.12it/s, acc=0.3948, loss=1.5936]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 102/194 [00:29<00:25,  3.61it/s, acc=0.3948, loss=1.5936]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 102/194 [00:29<00:25,  3.61it/s, acc=0.3947, loss=1.5205]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 103/194 [00:29<00:22,  4.03it/s, acc=0.3947, loss=1.5205]\n",
            "Training:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 103/194 [00:30<00:22,  4.03it/s, acc=0.3956, loss=1.3361]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 104/194 [00:30<00:24,  3.73it/s, acc=0.3956, loss=1.3361]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 104/194 [00:30<00:24,  3.73it/s, acc=0.3960, loss=1.5428]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 105/194 [00:30<00:22,  4.02it/s, acc=0.3960, loss=1.5428]\n",
            "Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 105/194 [00:30<00:22,  4.02it/s, acc=0.3962, loss=1.4006]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 106/194 [00:30<00:26,  3.27it/s, acc=0.3962, loss=1.4006]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 106/194 [00:30<00:26,  3.27it/s, acc=0.3969, loss=1.4430]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 107/194 [00:30<00:23,  3.69it/s, acc=0.3969, loss=1.4430]\n",
            "Training:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 107/194 [00:31<00:23,  3.69it/s, acc=0.3979, loss=1.3038]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 108/194 [00:31<00:25,  3.38it/s, acc=0.3979, loss=1.3038]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 108/194 [00:31<00:25,  3.38it/s, acc=0.3978, loss=1.4191]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 109/194 [00:31<00:22,  3.77it/s, acc=0.3978, loss=1.4191]\n",
            "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 109/194 [00:31<00:22,  3.77it/s, acc=0.3986, loss=1.3371]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 110/194 [00:31<00:26,  3.20it/s, acc=0.3986, loss=1.3371]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 110/194 [00:32<00:26,  3.20it/s, acc=0.3986, loss=1.5871]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 111/194 [00:32<00:22,  3.68it/s, acc=0.3986, loss=1.5871]\n",
            "Training:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 111/194 [00:32<00:22,  3.68it/s, acc=0.4001, loss=1.2969]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 112/194 [00:32<00:25,  3.27it/s, acc=0.4001, loss=1.2969]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 112/194 [00:32<00:25,  3.27it/s, acc=0.4004, loss=1.4734]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 113/194 [00:32<00:21,  3.74it/s, acc=0.4004, loss=1.4734]\n",
            "Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 113/194 [00:33<00:21,  3.74it/s, acc=0.4017, loss=1.2105]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 114/194 [00:33<00:25,  3.08it/s, acc=0.4017, loss=1.2105]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 114/194 [00:33<00:25,  3.08it/s, acc=0.4019, loss=1.3386]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 115/194 [00:33<00:22,  3.55it/s, acc=0.4019, loss=1.3386]\n",
            "Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 115/194 [00:33<00:22,  3.55it/s, acc=0.4032, loss=1.3493]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 116/194 [00:33<00:22,  3.39it/s, acc=0.4032, loss=1.3493]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 116/194 [00:33<00:22,  3.39it/s, acc=0.4041, loss=1.1829]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 117/194 [00:33<00:20,  3.83it/s, acc=0.4041, loss=1.1829]\n",
            "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 117/194 [00:34<00:20,  3.83it/s, acc=0.4049, loss=1.3063]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 118/194 [00:34<00:23,  3.25it/s, acc=0.4049, loss=1.3063]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 118/194 [00:34<00:23,  3.25it/s, acc=0.4061, loss=1.3394]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 119/194 [00:34<00:20,  3.71it/s, acc=0.4061, loss=1.3394]\n",
            "Training:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 119/194 [00:34<00:20,  3.71it/s, acc=0.4065, loss=1.5777]#015Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 120/194 [00:34<00:24,  3.00it/s, acc=0.4065, loss=1.5777]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 120/194 [00:34<00:24,  3.00it/s, acc=0.4062, loss=1.4048]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 121/194 [00:34<00:21,  3.47it/s, acc=0.4062, loss=1.4048]\n",
            "Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 121/194 [00:35<00:21,  3.47it/s, acc=0.4071, loss=1.5080]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 122/194 [00:35<00:23,  3.04it/s, acc=0.4071, loss=1.5080]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 122/194 [00:35<00:23,  3.04it/s, acc=0.4088, loss=1.1507]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 123/194 [00:35<00:20,  3.53it/s, acc=0.4088, loss=1.1507]\n",
            "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 123/194 [00:36<00:20,  3.53it/s, acc=0.4091, loss=1.4062]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 124/194 [00:36<00:23,  2.95it/s, acc=0.4091, loss=1.4062]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 124/194 [00:36<00:23,  2.95it/s, acc=0.4090, loss=1.5240]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 125/194 [00:36<00:20,  3.43it/s, acc=0.4090, loss=1.5240]\n",
            "Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 125/194 [00:36<00:20,  3.43it/s, acc=0.4086, loss=1.6075]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 126/194 [00:36<00:22,  2.97it/s, acc=0.4086, loss=1.6075]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 126/194 [00:36<00:22,  2.97it/s, acc=0.4088, loss=1.4309]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 127/194 [00:36<00:19,  3.45it/s, acc=0.4088, loss=1.4309]\n",
            "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 127/194 [00:37<00:19,  3.45it/s, acc=0.4089, loss=1.5838]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 128/194 [00:37<00:21,  3.03it/s, acc=0.4089, loss=1.5838]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 128/194 [00:37<00:21,  3.03it/s, acc=0.4100, loss=1.2003]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 129/194 [00:37<00:18,  3.50it/s, acc=0.4100, loss=1.2003]\n",
            "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 129/194 [00:37<00:18,  3.50it/s, acc=0.4102, loss=1.4157]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 130/194 [00:37<00:21,  3.02it/s, acc=0.4102, loss=1.4157]\n",
            "Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 130/194 [00:38<00:21,  3.02it/s, acc=0.4107, loss=1.3291]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 131/194 [00:38<00:17,  3.50it/s, acc=0.4107, loss=1.3291]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 131/194 [00:38<00:17,  3.50it/s, acc=0.4116, loss=1.3210]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 132/194 [00:38<00:18,  3.41it/s, acc=0.4116, loss=1.3210]\n",
            "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 132/194 [00:38<00:18,  3.41it/s, acc=0.4124, loss=1.3147]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 133/194 [00:38<00:15,  3.88it/s, acc=0.4124, loss=1.3147]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 133/194 [00:38<00:15,  3.88it/s, acc=0.4127, loss=1.5362]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 134/194 [00:38<00:18,  3.29it/s, acc=0.4127, loss=1.5362]\n",
            "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 134/194 [00:39<00:18,  3.29it/s, acc=0.4127, loss=1.5291]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 135/194 [00:39<00:15,  3.75it/s, acc=0.4127, loss=1.5291]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 135/194 [00:39<00:15,  3.75it/s, acc=0.4134, loss=1.2516]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 136/194 [00:39<00:16,  3.51it/s, acc=0.4134, loss=1.2516]\n",
            "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 136/194 [00:39<00:16,  3.51it/s, acc=0.4142, loss=1.1636]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 137/194 [00:39<00:14,  3.95it/s, acc=0.4142, loss=1.1636]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 137/194 [00:40<00:14,  3.95it/s, acc=0.4150, loss=1.3289]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 138/194 [00:40<00:17,  3.24it/s, acc=0.4150, loss=1.3289]\n",
            "Training:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 138/194 [00:40<00:17,  3.24it/s, acc=0.4155, loss=1.2622]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 139/194 [00:40<00:14,  3.72it/s, acc=0.4155, loss=1.2622]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 139/194 [00:40<00:14,  3.72it/s, acc=0.4164, loss=1.2131]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 140/194 [00:40<00:19,  2.74it/s, acc=0.4164, loss=1.2131]\n",
            "Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 140/194 [00:41<00:19,  2.74it/s, acc=0.4170, loss=1.2944]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 141/194 [00:41<00:16,  3.24it/s, acc=0.4170, loss=1.2944]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 141/194 [00:41<00:16,  3.24it/s, acc=0.4179, loss=1.2354]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 142/194 [00:41<00:18,  2.79it/s, acc=0.4179, loss=1.2354]\n",
            "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 142/194 [00:41<00:18,  2.79it/s, acc=0.4182, loss=1.2592]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 143/194 [00:41<00:15,  3.28it/s, acc=0.4182, loss=1.2592]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 143/194 [00:41<00:15,  3.28it/s, acc=0.4192, loss=1.2333]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 144/194 [00:41<00:15,  3.29it/s, acc=0.4192, loss=1.2333]\n",
            "Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 144/194 [00:42<00:15,  3.29it/s, acc=0.4200, loss=1.2513]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 145/194 [00:42<00:13,  3.75it/s, acc=0.4200, loss=1.2513]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 145/194 [00:42<00:13,  3.75it/s, acc=0.4210, loss=1.1883]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 146/194 [00:42<00:13,  3.60it/s, acc=0.4210, loss=1.1883]\n",
            "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 146/194 [00:42<00:13,  3.60it/s, acc=0.4212, loss=1.4645]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 147/194 [00:42<00:11,  4.02it/s, acc=0.4212, loss=1.4645]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 147/194 [00:43<00:11,  4.02it/s, acc=0.4221, loss=1.2036]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 148/194 [00:43<00:14,  3.25it/s, acc=0.4221, loss=1.2036]\n",
            "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 148/194 [00:43<00:14,  3.25it/s, acc=0.4227, loss=1.3962]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 149/194 [00:43<00:12,  3.71it/s, acc=0.4227, loss=1.3962]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 149/194 [00:43<00:12,  3.71it/s, acc=0.4234, loss=1.3031]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 150/194 [00:43<00:12,  3.49it/s, acc=0.4234, loss=1.3031]\n",
            "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 150/194 [00:43<00:12,  3.49it/s, acc=0.4229, loss=1.5671]#015Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 151/194 [00:43<00:10,  3.93it/s, acc=0.4229, loss=1.5671]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 151/194 [00:44<00:10,  3.93it/s, acc=0.4227, loss=1.4410]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 152/194 [00:44<00:11,  3.75it/s, acc=0.4227, loss=1.4410]\n",
            "Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 152/194 [00:44<00:11,  3.75it/s, acc=0.4227, loss=1.3963]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 153/194 [00:44<00:09,  4.17it/s, acc=0.4227, loss=1.3963]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 153/194 [00:44<00:09,  4.17it/s, acc=0.4238, loss=1.1325]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 154/194 [00:44<00:12,  3.23it/s, acc=0.4238, loss=1.1325]\n",
            "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 154/194 [00:44<00:12,  3.23it/s, acc=0.4245, loss=1.2920]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 155/194 [00:44<00:10,  3.69it/s, acc=0.4245, loss=1.2920]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 155/194 [00:45<00:10,  3.69it/s, acc=0.4247, loss=1.2348]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 156/194 [00:45<00:10,  3.49it/s, acc=0.4247, loss=1.2348]\n",
            "Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 156/194 [00:45<00:10,  3.49it/s, acc=0.4255, loss=1.2993]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 157/194 [00:45<00:09,  3.92it/s, acc=0.4255, loss=1.2993]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 157/194 [00:45<00:09,  3.92it/s, acc=0.4253, loss=1.4898]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 158/194 [00:45<00:09,  3.67it/s, acc=0.4253, loss=1.4898]\n",
            "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 158/194 [00:46<00:09,  3.67it/s, acc=0.4248, loss=1.5373]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 159/194 [00:46<00:09,  3.70it/s, acc=0.4248, loss=1.5373]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 159/194 [00:46<00:09,  3.70it/s, acc=0.4254, loss=1.2995]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 160/194 [00:46<00:08,  3.90it/s, acc=0.4254, loss=1.2995]\n",
            "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 160/194 [00:46<00:08,  3.90it/s, acc=0.4260, loss=1.3297]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 161/194 [00:46<00:09,  3.47it/s, acc=0.4260, loss=1.3297]\n",
            "Training:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 161/194 [00:46<00:09,  3.47it/s, acc=0.4260, loss=1.4570]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 162/194 [00:46<00:08,  3.89it/s, acc=0.4260, loss=1.4570]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 162/194 [00:47<00:08,  3.89it/s, acc=0.4266, loss=1.3096]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 163/194 [00:47<00:09,  3.38it/s, acc=0.4266, loss=1.3096]\n",
            "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 163/194 [00:47<00:09,  3.38it/s, acc=0.4273, loss=1.2159]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 164/194 [00:47<00:07,  3.81it/s, acc=0.4273, loss=1.2159]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 164/194 [00:47<00:07,  3.81it/s, acc=0.4279, loss=1.1980]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 165/194 [00:47<00:08,  3.26it/s, acc=0.4279, loss=1.1980]\n",
            "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 165/194 [00:47<00:08,  3.26it/s, acc=0.4280, loss=1.2858]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 166/194 [00:47<00:07,  3.70it/s, acc=0.4280, loss=1.2858]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 166/194 [00:48<00:07,  3.70it/s, acc=0.4286, loss=1.2398]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 167/194 [00:48<00:08,  3.25it/s, acc=0.4286, loss=1.2398]\n",
            "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 167/194 [00:48<00:08,  3.25it/s, acc=0.4295, loss=1.1210]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 168/194 [00:48<00:07,  3.70it/s, acc=0.4295, loss=1.1210]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 168/194 [00:48<00:07,  3.70it/s, acc=0.4302, loss=1.1698]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 169/194 [00:48<00:07,  3.34it/s, acc=0.4302, loss=1.1698]\n",
            "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 169/194 [00:49<00:07,  3.34it/s, acc=0.4302, loss=1.4734]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 170/194 [00:49<00:06,  3.78it/s, acc=0.4302, loss=1.4734]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 170/194 [00:49<00:06,  3.78it/s, acc=0.4306, loss=1.3471]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 171/194 [00:49<00:07,  3.24it/s, acc=0.4306, loss=1.3471]\n",
            "Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 171/194 [00:49<00:07,  3.24it/s, acc=0.4304, loss=1.5746]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 172/194 [00:49<00:05,  3.70it/s, acc=0.4304, loss=1.5746]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 172/194 [00:50<00:05,  3.70it/s, acc=0.4309, loss=1.1276]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 173/194 [00:50<00:06,  3.20it/s, acc=0.4309, loss=1.1276]\n",
            "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 173/194 [00:50<00:06,  3.20it/s, acc=0.4315, loss=1.3726]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 174/194 [00:50<00:05,  3.68it/s, acc=0.4315, loss=1.3726]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 174/194 [00:50<00:05,  3.68it/s, acc=0.4321, loss=1.1435]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 175/194 [00:50<00:06,  3.00it/s, acc=0.4321, loss=1.1435]\n",
            "Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 175/194 [00:50<00:06,  3.00it/s, acc=0.4329, loss=1.2699]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 176/194 [00:50<00:05,  3.50it/s, acc=0.4329, loss=1.2699]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 176/194 [00:51<00:05,  3.50it/s, acc=0.4334, loss=1.1538]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 177/194 [00:51<00:05,  3.02it/s, acc=0.4334, loss=1.1538]\n",
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 177/194 [00:51<00:05,  3.02it/s, acc=0.4342, loss=1.2243]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 178/194 [00:51<00:04,  3.49it/s, acc=0.4342, loss=1.2243]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 178/194 [00:51<00:04,  3.49it/s, acc=0.4353, loss=1.1525]#015Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 179/194 [00:51<00:04,  3.50it/s, acc=0.4353, loss=1.1525]\n",
            "Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 179/194 [00:51<00:04,  3.50it/s, acc=0.4359, loss=1.2372]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 180/194 [00:51<00:03,  3.90it/s, acc=0.4359, loss=1.2372]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 180/194 [00:52<00:03,  3.90it/s, acc=0.4366, loss=1.1928]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 181/194 [00:52<00:03,  3.43it/s, acc=0.4366, loss=1.1928]\n",
            "Training:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 181/194 [00:52<00:03,  3.43it/s, acc=0.4369, loss=1.3874]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 182/194 [00:52<00:03,  3.86it/s, acc=0.4369, loss=1.3874]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 182/194 [00:52<00:03,  3.86it/s, acc=0.4368, loss=1.3145]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 183/194 [00:52<00:03,  3.32it/s, acc=0.4368, loss=1.3145]\n",
            "Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 183/194 [00:53<00:03,  3.32it/s, acc=0.4372, loss=1.2307]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 184/194 [00:53<00:02,  3.76it/s, acc=0.4372, loss=1.2307]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 184/194 [00:53<00:02,  3.76it/s, acc=0.4383, loss=1.1042]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 185/194 [00:53<00:02,  3.17it/s, acc=0.4383, loss=1.1042]\n",
            "Training:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 185/194 [00:53<00:02,  3.17it/s, acc=0.4384, loss=1.3515]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 186/194 [00:53<00:02,  3.65it/s, acc=0.4384, loss=1.3515]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 186/194 [00:54<00:02,  3.65it/s, acc=0.4388, loss=1.2969]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 187/194 [00:54<00:02,  3.15it/s, acc=0.4388, loss=1.2969]\n",
            "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 187/194 [00:54<00:02,  3.15it/s, acc=0.4392, loss=1.2532]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 188/194 [00:54<00:01,  3.61it/s, acc=0.4392, loss=1.2532]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 188/194 [00:54<00:01,  3.61it/s, acc=0.4397, loss=1.2361]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 189/194 [00:54<00:01,  3.27it/s, acc=0.4397, loss=1.2361]\n",
            "Training:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 189/194 [00:54<00:01,  3.27it/s, acc=0.4396, loss=1.4313]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 190/194 [00:54<00:01,  3.72it/s, acc=0.4396, loss=1.4313]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 190/194 [00:55<00:01,  3.72it/s, acc=0.4397, loss=1.3151]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 191/194 [00:55<00:00,  3.14it/s, acc=0.4397, loss=1.3151]\n",
            "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 191/194 [00:55<00:00,  3.14it/s, acc=0.4405, loss=1.1736]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 192/194 [00:55<00:00,  3.63it/s, acc=0.4405, loss=1.1736]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 192/194 [00:55<00:00,  3.63it/s, acc=0.4410, loss=1.2829]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 193/194 [00:55<00:00,  3.55it/s, acc=0.4410, loss=1.2829]\n",
            "Training:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 193/194 [00:55<00:00,  3.55it/s, acc=0.4413, loss=1.3295]\n",
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 194/194 [00:55<00:00,  3.47it/s, acc=0.4413, loss=1.3295]\n",
            "Train Loss: 1.4480, Train Acc: 0.4413\n",
            "Validating:   0%|          | 0/65 [00:00<?, ?it/s]\n",
            "Validating:   0%|          | 0/65 [00:00<?, ?it/s, acc=0.4688, loss=1.5879]\n",
            "Validating:   2%|‚ñè         | 1/65 [00:00<00:32,  1.98it/s, acc=0.4688, loss=1.5879]\n",
            "Validating:   2%|‚ñè         | 1/65 [00:00<00:32,  1.98it/s, acc=0.4609, loss=1.4040]\n",
            "Validating:   2%|‚ñè         | 1/65 [00:00<00:32,  1.98it/s, acc=0.4167, loss=1.6490]\n",
            "Validating:   5%|‚ñç         | 3/65 [00:00<00:17,  3.54it/s, acc=0.4167, loss=1.6490]\n",
            "Validating:   5%|‚ñç         | 3/65 [00:00<00:17,  3.54it/s, acc=0.4570, loss=1.3650]\n",
            "Validating:   5%|‚ñç         | 3/65 [00:01<00:17,  3.54it/s, acc=0.4844, loss=1.1109]\n",
            "Validating:   8%|‚ñä         | 5/65 [00:01<00:13,  4.34it/s, acc=0.4844, loss=1.1109]\n",
            "Validating:   8%|‚ñä         | 5/65 [00:01<00:13,  4.34it/s, acc=0.4792, loss=1.6423]\n",
            "Validating:   8%|‚ñä         | 5/65 [00:01<00:13,  4.34it/s, acc=0.4643, loss=1.6700]\n",
            "Validating:  11%|‚ñà         | 7/65 [00:01<00:12,  4.70it/s, acc=0.4643, loss=1.6700]\n",
            "\n",
            "================================================================================\n",
            "‚ö†Ô∏è  Showing 500 of 2583 total lines\n",
            "   Run: get_training_logs('animal-classification-training-2025-12-28-01-43-07-396', max_lines=None) to see all\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# RUN THIS CELL TO VIEW LOGS FROM A JOB\n",
        "# Paste the job name from above, or it will use the most recent job\n",
        "# ========================================\n",
        "\n",
        "import boto3\n",
        "\n",
        "def get_training_logs(job_name, region='us-west-1', max_lines=None):\n",
        "    \"\"\"\n",
        "    Get all CloudWatch logs for a SageMaker training job\n",
        "    \n",
        "    Args:\n",
        "        job_name: Name of the training job\n",
        "        region: AWS region\n",
        "        max_lines: Maximum number of log lines to show (None = all)\n",
        "    \"\"\"\n",
        "    logs_client = boto3.client('logs', region_name=region)\n",
        "    \n",
        "    log_group = '/aws/sagemaker/TrainingJobs'\n",
        "    \n",
        "    try:\n",
        "        # List all log streams for this job\n",
        "        streams = logs_client.describe_log_streams(\n",
        "            logGroupName=log_group,\n",
        "            logStreamNamePrefix=job_name,\n",
        "            orderBy='LogStreamName'\n",
        "        )\n",
        "        \n",
        "        if not streams['logStreams']:\n",
        "            print(f\"‚ùå No logs found for job: {job_name}\")\n",
        "            print(\"   Job might still be starting, or name is incorrect\")\n",
        "            return\n",
        "        \n",
        "        all_logs = []\n",
        "        for stream in streams['logStreams']:\n",
        "            stream_name = stream['logStreamName']\n",
        "            \n",
        "            # Get all events from this stream\n",
        "            next_token = None\n",
        "            while True:\n",
        "                kwargs = {\n",
        "                    'logGroupName': log_group,\n",
        "                    'logStreamName': stream_name,\n",
        "                    'startFromHead': True\n",
        "                }\n",
        "                if next_token:\n",
        "                    kwargs['nextToken'] = next_token\n",
        "                \n",
        "                response = logs_client.get_log_events(**kwargs)\n",
        "                \n",
        "                for event in response['events']:\n",
        "                    all_logs.append(event['message'])\n",
        "                \n",
        "                # Check if there are more logs\n",
        "                next_token = response.get('nextForwardToken')\n",
        "                if not response['events'] or next_token == kwargs.get('nextToken'):\n",
        "                    break\n",
        "        \n",
        "        # Print logs\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"üìã TRAINING LOGS: {job_name}\")\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"Total log lines: {len(all_logs)}\")\n",
        "        if max_lines:\n",
        "            print(f\"Showing first {max_lines} lines (set max_lines=None for all)\")\n",
        "        print(\"=\" * 80)\n",
        "        print()\n",
        "        \n",
        "        logs_to_show = all_logs[:max_lines] if max_lines else all_logs\n",
        "        for log in logs_to_show:\n",
        "            print(log)\n",
        "        \n",
        "        if max_lines and len(all_logs) > max_lines:\n",
        "            print()\n",
        "            print(\"=\" * 80)\n",
        "            print(f\"‚ö†Ô∏è  Showing {max_lines} of {len(all_logs)} total lines\")\n",
        "            print(f\"   Run: get_training_logs('{job_name}', max_lines=None) to see all\")\n",
        "            print(\"=\" * 80)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error retrieving logs: {e}\")\n",
        "        print(f\"   Make sure the job name is correct\")\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# PASTE JOB NAME HERE (or leave empty for most recent)\n",
        "# ========================================\n",
        "JOB_NAME = ''  # Example: 'animal-classification-training-2024-12-21-12-34-56-789'\n",
        "\n",
        "# If no job name provided, use most recent\n",
        "if not JOB_NAME:\n",
        "    sagemaker_client = boto3.client('sagemaker', region_name=REGION)\n",
        "    jobs = sagemaker_client.list_training_jobs(MaxResults=1, SortBy='CreationTime', SortOrder='Descending')\n",
        "    if jobs['TrainingJobSummaries']:\n",
        "        JOB_NAME = jobs['TrainingJobSummaries'][0]['TrainingJobName']\n",
        "        print(f\"‚ÑπÔ∏è  No job name specified, using most recent: {JOB_NAME}\\n\")\n",
        "    else:\n",
        "        print(\"‚ùå No training jobs found\")\n",
        "\n",
        "# View logs (showing first 500 lines by default)\n",
        "if JOB_NAME:\n",
        "    get_training_logs(JOB_NAME, REGION, max_lines=500)\n",
        "    \n",
        "# üí° To see ALL logs without limit:\n",
        "# get_training_logs(JOB_NAME, REGION, max_lines=None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9480565",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìñ Quick Reference: Which Cells to Run\n",
        "\n",
        "### **To Start Training (First Time):**\n",
        "1. ‚úÖ Run **Cells 0-3** (Setup & Config)\n",
        "2. ‚úÖ Run **Cell 4-5** (Preprocessing) - Only once needed\n",
        "3. ‚úÖ Run **Cell 6** (Create Estimator)\n",
        "4. ‚úÖ Run **Cell 7** (Start Training) - **SEE ALL LOGS HERE!**\n",
        "\n",
        "### **To View Logs After Closing Computer:**\n",
        "1. ‚úÖ Run **Cells 0-3** (Setup & Config)\n",
        "2. ‚úÖ Run **Cell 9** (List all recent jobs)\n",
        "3. ‚úÖ Run **Cell 10** (View logs fromselected job)\n",
        "\n",
        "### **Tips:**\n",
        "- **Cell 7** shows ALL your `print()` statements from `dss_train.py` in real-time\n",
        "- Logs are automatically saved to CloudWatch (accessible anytime!)\n",
        "- Safe to close computer during training - logs persist in CloudWatch\n",
        "- **Cell 10** retrieves logs from CloudWatch whenever you need them\n",
        "\n",
        "---\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.11.6)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
