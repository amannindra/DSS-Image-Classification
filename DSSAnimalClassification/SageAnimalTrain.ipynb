{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ec31aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.pytorch.processing import PyTorchProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4423240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "REGION = 'us-west-1'\n",
    "ROLE_ARN = \"arn:aws:iam::253490779227:role/service-role/AmazonSageMakerAdminIAMExecutionRole\"\n",
    "BUCKET = 'animal-classification-dss-works'\n",
    "S3_INPUT_DATA = f's3://{BUCKET}/data/'\n",
    "S3_PREPROCESSED = f's3://{BUCKET}/preprocessed/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f2986b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "boto_session = boto3.Session(region_name=REGION)\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto_session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "964cd10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region: us-west-1\n",
      "S3 Bucket: animal-classification-dss-works\n",
      "Input data: s3://animal-classification-dss-works/data/\n",
      "Preprocessed output: s3://animal-classification-dss-works/preprocessed/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Region: {sagemaker_session.boto_region_name}\")\n",
    "print(f\"S3 Bucket: {BUCKET}\")\n",
    "print(f\"Input data: {S3_INPUT_DATA}\")\n",
    "print(f\"Preprocessed output: {S3_PREPROCESSED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c98a32a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    }
   ],
   "source": [
    "processor = PyTorchProcessor(\n",
    "    framework_version='2.1',\n",
    "    py_version='py310',\n",
    "    role=ROLE_ARN,\n",
    "    instance_type='ml.m5.2xlarge',  # CPU instance: $0.23/hour\n",
    "    instance_count=1,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    base_job_name='animal-preprocessing'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355fc9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:Uploaded None to s3://sagemaker-us-west-1-253490779227/animal-preprocessing-2025-12-24-23-45-53-325/source/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sagemaker-us-west-1-253490779227/animal-preprocessing-2025-12-24-23-45-53-325/source/runproc.sh\n",
      "INFO:sagemaker:Creating processing-job with name animal-preprocessing-2025-12-24-23-45-53-325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........Input Directory: {INPUT_DIR}\n",
      "Output Directory: {OUTPUT_DIR}\n",
      "Initial RAM usage: 142.44 MB\n",
      "============================================================\n",
      "IMAGE PREPROCESSING FOR SAGEMAKER TRAINING\n",
      "============================================================\n",
      "1. Processing TRAINING images...\n",
      "Getting image list from s3://animal-classification-dss-works/data/train_features/\n",
      "Found 16488 images\n",
      "Getting image list from s3://animal-classification-dss-works/data/test_features/\n",
      "Found 4464 images\n",
      "Processing 16488 images...\n",
      "Image data/train_features/ZJ000007.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000032.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000041.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000042.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000046.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000051.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000052.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000059.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000072.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000084.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000096.jpg is grayscale, converting to RGB\n",
      "Processing 100 of 16488 images, RAM usage: 151.82 MB\n",
      "Image data/train_features/ZJ000101.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000102.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000104.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000123.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000130.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000131.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000135.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000137.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000141.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000148.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000161.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000173.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000180.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000185.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000189.jpg is grayscale, converting to RGB\n",
      "Processing 200 of 16488 images, RAM usage: 152.08 MB\n",
      "Image data/train_features/ZJ000200.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000221.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000226.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000232.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000235.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000237.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000241.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000245.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000253.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000285.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000296.jpg is grayscale, converting to RGB\n",
      "Processing 300 of 16488 images, RAM usage: 152.20 MB\n",
      "Image data/train_features/ZJ000301.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000322.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000331.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000342.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000348.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000359.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000362.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000364.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000368.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000370.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000384.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000392.jpg is grayscale, converting to RGB\n",
      "Processing 400 of 16488 images, RAM usage: 154.14 MB\n",
      "Image data/train_features/ZJ000399.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000414.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000422.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000426.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000428.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000437.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000441.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000447.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000454.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000468.jpg is grayscale, converting to RGB\n",
      "Processing 500 of 16488 images, RAM usage: 152.14 MB\n",
      "Image data/train_features/ZJ000504.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000517.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000519.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000524.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000540.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000556.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000561.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000564.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000568.jpg is grayscale, converting to RGB\n",
      "Processing 600 of 16488 images, RAM usage: 152.21 MB\n",
      "Image data/train_features/ZJ000605.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000618.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000620.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000623.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000625.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000634.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000637.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000649.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000652.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000662.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000668.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000679.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000681.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000694.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000698.jpg is grayscale, converting to RGB\n",
      "Processing 700 of 16488 images, RAM usage: 152.21 MB\n",
      "Image data/train_features/ZJ000701.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000709.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000722.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000723.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000731.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000733.jpg is grayscale, converting to RGB\n",
      "Image data/train_features/ZJ000746.jpg is grayscale, converting to RGB\n"
     ]
    }
   ],
   "source": [
    "# processor.latest_job.stop()\n",
    "\n",
    "###### RUN THIS CELL ONLY ONCE ######\n",
    "\n",
    "processor.run(\n",
    "    code='preprocess.py',\n",
    "    # inputs=[\n",
    "    #     ProcessingInput(\n",
    "    #         source=S3_INPUT_DATA,           # Your S3 data folder\n",
    "    #         destination='/opt/ml/processing/input'  # Where it appears in container\n",
    "    #     )\n",
    "    # ],\n",
    "    # outputs=[\n",
    "    #     ProcessingOutput(\n",
    "    #         source='/opt/ml/processing/output',     # Where script saves results\n",
    "    #         destination=S3_PREPROCESSED              # Upload results here\n",
    "    #     )\n",
    "    # ],\n",
    "    # arguments=[\n",
    "    #     '--input-dir', '/opt/ml/processing/input',\n",
    "    #     '--output-dir', '/opt/ml/processing/output'\n",
    "    # ]\n",
    ")\n",
    "print(f\"Preprocessed data saved to: {S3_PREPROCESSED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ae786a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point='dss_train.py',\n",
    "    source_dir='.',\n",
    "    role=ROLE_ARN,\n",
    "    framework_version='2.1',\n",
    "    py_version='py310',\n",
    "    instance_count=1,\n",
    "    instance_type='ml.g4dn.xlarge',  # GPU instance with NVIDIA T4\n",
    "    hyperparameters={\n",
    "        'epochs': 10,\n",
    "        'batch-size': 64,  # Larger batch size with GPU\n",
    "        'learning-rate': 0.001,\n",
    "    },\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    base_job_name='animal-classification-training',\n",
    "    # Use Spot instances to save 70% (optional)\n",
    "    # use_spot_instances=True,\n",
    "    # max_wait=7200,  # 2 hours\n",
    "    # max_run=3600,   # 1 hour\n",
    ")\n",
    "# estimator.latest_training_job.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b92d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# RUN THIS CELL TO START TRAINING\n",
    "# You'll see ALL logs stream in real-time\n",
    "# ========================================\n",
    "\n",
    "# print(\"Created PyTorch Estimator:\")\n",
    "# print(f\"  Instance: ml.g4dn.xlarge (4 vCPUs, 16GB RAM, 1x NVIDIA T4 GPU)\")\n",
    "# print(f\"  Cost: ~$0.94/hour (~$2 for full training)\")\n",
    "# print(f\"  Expected time: 1-2 hours\")\n",
    "# print(f\"  Speed: 10-50x faster than CPU!\")\n",
    "\n",
    "# # Start training with PREPROCESSED data\n",
    "# print(\"\\nüöÄ Starting training job with GPU...\")\n",
    "# print(\"All print statements from dss_train.py will stream below...\")\n",
    "# print(\"(Safe to close computer - logs saved to CloudWatch)\")\n",
    "# print(\"=\"*70)\n",
    "\n",
    "estimator.fit(\n",
    "    {'training': S3_PREPROCESSED},\n",
    "    wait=True,      # ‚úÖ Wait for job to complete\n",
    "    logs='All'      # ‚úÖ Stream ALL logs to notebook (shows all print statements!)\n",
    ")\n",
    "\n",
    "# print(\"\\n\" + \"=\"*70)\n",
    "# print(\"‚úÖ PIPELINE COMPLETE!\")\n",
    "# print(\"=\"*70)\n",
    "# print(f\"\\nJob Name: {estimator.latest_training_job.name}\")\n",
    "# print(f\"Model saved to: {estimator.model_data}\")\n",
    "# print(f\"\\nTotal cost estimate:\")\n",
    "# print(f\"  Preprocessing (ml.m5.xlarge): ~$0.50\")\n",
    "# print(f\"  Training (ml.g4dn.xlarge):    ~$2.00\")\n",
    "# print(f\"  TOTAL:                        ~$2.50\")\n",
    "# print(f\"\\nVs running on CPU locally: 20-30 hours!\")\n",
    "# print(\"\\nüìã To view logs again later, run the cells below ‚¨áÔ∏è\")\n",
    "# print(\"=\"*70)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a883bd0",
   "metadata": {},
   "source": [
    "# üìã View Training Logs Anytime\n",
    "\n",
    "**Use the cells below to view logs after closing/reopening your computer**\n",
    "\n",
    "- **Cell below**: List all recent training jobs\n",
    "- **Next cell**: View complete logs from any job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6b9532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# RUN THIS CELL TO LIST ALL RECENT JOBS\n",
    "# ========================================\n",
    "\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "\n",
    "sagemaker_client = boto3.client('sagemaker', region_name=REGION)\n",
    "\n",
    "# Get recent training jobs\n",
    "jobs = sagemaker_client.list_training_jobs(\n",
    "    MaxResults=10, \n",
    "    SortBy='CreationTime', \n",
    "    SortOrder='Descending'\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RECENT TRAINING JOBS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n{'#':<4} {'Job Name':<50} {'Status':<15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, job in enumerate(jobs['TrainingJobSummaries']):\n",
    "    job_name = job['TrainingJobName']\n",
    "    status = job['TrainingJobStatus']\n",
    "    created = job['CreationTime'].strftime('%Y-%m-%d %H:%M')\n",
    "    \n",
    "    # Color code status\n",
    "    status_symbol = {\n",
    "        'InProgress': 'üîÑ',\n",
    "        'Completed': '‚úÖ',\n",
    "        'Failed': '‚ùå',\n",
    "        'Stopped': '‚è∏Ô∏è'\n",
    "    }.get(status, '‚ùì')\n",
    "    \n",
    "    print(f\"{i:<4} {job_name:<50} {status_symbol} {status}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üí° Copy a job name above and paste it in the next cell to view its logs\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c6869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# RUN THIS CELL TO VIEW LOGS FROM A JOB\n",
    "# Paste the job name from above, or it will use the most recent job\n",
    "# ========================================\n",
    "\n",
    "import boto3\n",
    "\n",
    "def get_training_logs(job_name, region='us-west-1', max_lines=None):\n",
    "    \"\"\"\n",
    "    Get all CloudWatch logs for a SageMaker training job\n",
    "    \n",
    "    Args:\n",
    "        job_name: Name of the training job\n",
    "        region: AWS region\n",
    "        max_lines: Maximum number of log lines to show (None = all)\n",
    "    \"\"\"\n",
    "    logs_client = boto3.client('logs', region_name=region)\n",
    "    \n",
    "    log_group = '/aws/sagemaker/TrainingJobs'\n",
    "    \n",
    "    try:\n",
    "        # List all log streams for this job\n",
    "        streams = logs_client.describe_log_streams(\n",
    "            logGroupName=log_group,\n",
    "            logStreamNamePrefix=job_name,\n",
    "            orderBy='LogStreamName'\n",
    "        )\n",
    "        \n",
    "        if not streams['logStreams']:\n",
    "            print(f\"‚ùå No logs found for job: {job_name}\")\n",
    "            print(\"   Job might still be starting, or name is incorrect\")\n",
    "            return\n",
    "        \n",
    "        all_logs = []\n",
    "        for stream in streams['logStreams']:\n",
    "            stream_name = stream['logStreamName']\n",
    "            \n",
    "            # Get all events from this stream\n",
    "            next_token = None\n",
    "            while True:\n",
    "                kwargs = {\n",
    "                    'logGroupName': log_group,\n",
    "                    'logStreamName': stream_name,\n",
    "                    'startFromHead': True\n",
    "                }\n",
    "                if next_token:\n",
    "                    kwargs['nextToken'] = next_token\n",
    "                \n",
    "                response = logs_client.get_log_events(**kwargs)\n",
    "                \n",
    "                for event in response['events']:\n",
    "                    all_logs.append(event['message'])\n",
    "                \n",
    "                # Check if there are more logs\n",
    "                next_token = response.get('nextForwardToken')\n",
    "                if not response['events'] or next_token == kwargs.get('nextToken'):\n",
    "                    break\n",
    "        \n",
    "        # Print logs\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"üìã TRAINING LOGS: {job_name}\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"Total log lines: {len(all_logs)}\")\n",
    "        if max_lines:\n",
    "            print(f\"Showing first {max_lines} lines (set max_lines=None for all)\")\n",
    "        print(\"=\" * 80)\n",
    "        print()\n",
    "        \n",
    "        logs_to_show = all_logs[:max_lines] if max_lines else all_logs\n",
    "        for log in logs_to_show:\n",
    "            print(log)\n",
    "        \n",
    "        if max_lines and len(all_logs) > max_lines:\n",
    "            print()\n",
    "            print(\"=\" * 80)\n",
    "            print(f\"‚ö†Ô∏è  Showing {max_lines} of {len(all_logs)} total lines\")\n",
    "            print(f\"   Run: get_training_logs('{job_name}', max_lines=None) to see all\")\n",
    "            print(\"=\" * 80)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error retrieving logs: {e}\")\n",
    "        print(f\"   Make sure the job name is correct\")\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# PASTE JOB NAME HERE (or leave empty for most recent)\n",
    "# ========================================\n",
    "JOB_NAME = ''  # Example: 'animal-classification-training-2024-12-21-12-34-56-789'\n",
    "\n",
    "# If no job name provided, use most recent\n",
    "if not JOB_NAME:\n",
    "    sagemaker_client = boto3.client('sagemaker', region_name=REGION)\n",
    "    jobs = sagemaker_client.list_training_jobs(MaxResults=1, SortBy='CreationTime', SortOrder='Descending')\n",
    "    if jobs['TrainingJobSummaries']:\n",
    "        JOB_NAME = jobs['TrainingJobSummaries'][0]['TrainingJobName']\n",
    "        print(f\"‚ÑπÔ∏è  No job name specified, using most recent: {JOB_NAME}\\n\")\n",
    "    else:\n",
    "        print(\"‚ùå No training jobs found\")\n",
    "\n",
    "# View logs (showing first 500 lines by default)\n",
    "if JOB_NAME:\n",
    "    get_training_logs(JOB_NAME, REGION, max_lines=500)\n",
    "    \n",
    "# üí° To see ALL logs without limit:\n",
    "# get_training_logs(JOB_NAME, REGION, max_lines=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9480565",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìñ Quick Reference: Which Cells to Run\n",
    "\n",
    "### **To Start Training (First Time):**\n",
    "1. ‚úÖ Run **Cells 0-3** (Setup & Config)\n",
    "2. ‚úÖ Run **Cell 4-5** (Preprocessing) - Only once needed\n",
    "3. ‚úÖ Run **Cell 6** (Create Estimator)\n",
    "4. ‚úÖ Run **Cell 7** (Start Training) - **SEE ALL LOGS HERE!**\n",
    "\n",
    "### **To View Logs After Closing Computer:**\n",
    "1. ‚úÖ Run **Cells 0-3** (Setup & Config)\n",
    "2. ‚úÖ Run **Cell 9** (List all recent jobs)\n",
    "3. ‚úÖ Run **Cell 10** (View logs fromselected job)\n",
    "\n",
    "### **Tips:**\n",
    "- **Cell 7** shows ALL your `print()` statements from `dss_train.py` in real-time\n",
    "- Logs are automatically saved to CloudWatch (accessible anytime!)\n",
    "- Safe to close computer during training - logs persist in CloudWatch\n",
    "- **Cell 10** retrieves logs from CloudWatch whenever you need them\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
